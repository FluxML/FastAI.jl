{"attributes":{"kind":"function","backlinks":[{"tag":"document","title":"Quickstart","docid":"FastAI@pr-262/doc/docs/notebooks/quickstart.ipynb"},{"tag":"document","title":"How to train a model","docid":"FastAI@pr-262/doc/docs/notebooks/training.ipynb"},{"tag":"document","title":"fastai API comparison","docid":"FastAI@pr-262/doc/docs/fastai_api_comparison.md"},{"tag":"document","title":"Performant data pipelines","docid":"FastAI@pr-262/doc/docs/background/datapipelines.md"},{"tag":"document","title":"Discovery","docid":"FastAI@pr-262/doc/docs/discovery.md"},{"tag":"documentation","title":"tasklearner","docid":"FastAI@pr-262/ref/FastAI.tasklearner"},{"tag":"document","title":"New visualization tools for FastAI.jl","docid":"FastAI@pr-262/doc/docs/notebooks/10_26_showblock.ipynb"},{"tag":"document","title":"FastAI.jl","docid":"FastAI@pr-262/doc/README.md"},{"tag":"sourcefile","title":"FastVision/tasks/classification.jl","docid":"FastVision@0.1.0/src/tasks/classification.jl"},{"tag":"documentation","title":"showsample","docid":"FastAI@pr-262/ref/FastAI.showsample"},{"tag":"document","title":"Introduction","docid":"FastAI@pr-262/doc/docs/introduction.md"},{"tag":"documentation","title":"showsamples","docid":"FastAI@pr-262/ref/FastAI.showsamples"},{"tag":"document","title":"Blocks and encodings","docid":"FastAI@pr-262/doc/docs/background/blocksencodings.md"},{"tag":"documentation","title":"ImageClassificationMulti","docid":"FastVision@0.1.0/ref/FastVision.ImageClassificationMulti"},{"tag":"sourcefile","title":"FastVision/FastVision.jl","docid":"FastVision@0.1.0/src/FastVision.jl"}],"methods":[{"symbol_id":"FastVision.ImageClassificationSingle","module_id":"FastVision","file":"tasks/classification.jl","line":2,"signature":"(::Signature)"},{"symbol_id":"FastVision.ImageClassificationSingle","module_id":"FastVision","file":"tasks/classification.jl","line":36,"signature":"(::Signature)"}],"package_id":"FastVision@0.1.0","title":"ImageClassificationSingle","symbol_id":"FastVision.ImageClassificationSingle","exported":true,"module_id":"FastVision"},"tag":"documentation","children":[{"attributes":{"symbol":"FastVision.ImageClassificationSingle","line":16,"module":"FastVision","file":"tasks/classification.jl"},"tag":"docstring","children":[{"attributes":{},"tag":"md","children":[{"attributes":{"lang":""},"tag":"codeblock","children":["ImageClassificationSingle(size, classes; kwargs...)\nImageClassificationSingle(blocks[, data]; kwargs...)\n"],"type":"node"},{"attributes":{},"tag":"p","children":["Learning task for single-label image classification. Images are resized to ",{"attributes":{},"tag":"code","children":["size"],"type":"node"}," and classified into one of ",{"attributes":{},"tag":"code","children":["classes"],"type":"node"},"."],"type":"node"},{"attributes":{},"tag":"p","children":["Use ",{"attributes":{"reftype":"symbol","href":"#","title":"","document_id":"FastVision@0.1.0/ref/FastVision.ImageClassificationMulti"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["ImageClassificationMulti"],"type":"node"}],"type":"node"}," for the multi-class setting."],"type":"node"},{"attributes":{},"tag":"h2","children":["Keyword arguments"],"type":"node"},{"attributes":{},"tag":"ul","children":[{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["computestats = false"],"type":"node"},": Whether to compute image statistics on dataset ",{"attributes":{},"tag":"code","children":["data"],"type":"node"}," or use default ImageNet stats."],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["aug_projections = "],"type":"node"},{"attributes":{"reftype":"symbol","href":"#","title":"","document_id":"DataAugmentation@0.2.10/ref/DataAugmentation.Identity"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["DataAugmentation.Identity"],"type":"node"}],"type":"node"},": augmentation to apply during ",{"attributes":{"reftype":"symbol","href":"#","title":"","document_id":"FastVision@0.1.0/ref/FastVision.ProjectiveTransforms"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["ProjectiveTransforms"],"type":"node"}],"type":"node"}," (resizing and cropping)"],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["aug_image = "],"type":"node"},{"attributes":{"reftype":"symbol","href":"#","title":"","document_id":"DataAugmentation@0.2.10/ref/DataAugmentation.Identity"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["DataAugmentation.Identity"],"type":"node"}],"type":"node"},": pixel-level augmentation to apply during ",{"attributes":{"reftype":"symbol","href":"#","title":"","document_id":"FastVision@0.1.0/ref/FastVision.ImagePreprocessing"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["ImagePreprocessing"],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["C = RGB{N0f8}"],"type":"node"},": Color type images are converted to before further processing. Use ",{"attributes":{},"tag":"code","children":["Gray{N0f8}"],"type":"node"}," for grayscale images."],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"}