{"attributes":{"kind":"function","backlinks":[{"tag":"sourcefile","title":"Flux/utils.jl","docid":"Flux@0.13.11/src/utils.jl"}],"methods":[{"symbol_id":"Flux.identity_init","module_id":"Flux","file":"utils.jl","line":467,"signature":"(::Signature)"},{"symbol_id":"Flux.identity_init","module_id":"Flux","file":"utils.jl","line":449,"signature":"(::Signature)"},{"symbol_id":"Flux.identity_init","module_id":"Flux","file":"utils.jl","line":452,"signature":"(::Signature)"},{"symbol_id":"Flux.identity_init","module_id":"Flux","file":"utils.jl","line":466,"signature":"(::Signature)"},{"symbol_id":"Flux.identity_init","module_id":"Flux","file":"utils.jl","line":455,"signature":"(::Signature)"}],"package_id":"Flux@0.13.11","title":"identity_init","symbol_id":"Flux.identity_init","exported":false,"module_id":"Flux"},"tag":"documentation","children":[{"attributes":{"symbol":"Flux.identity_init","line":381,"module":"Flux","file":"utils.jl"},"tag":"docstring","children":[{"attributes":{},"tag":"md","children":[{"attributes":{"lang":""},"tag":"codeblock","children":["identity_init(size...; gain=1, shift=0) -> Array\nidentity_init(; kw...) -> Function\n"],"type":"node"},{"attributes":{},"tag":"p","children":["Return an ",{"attributes":{},"tag":"code","children":["Array{Float32}"],"type":"node"}," of the given ",{"attributes":{},"tag":"code","children":["size"],"type":"node"}," which yields an identity mapping when used as parameters in most Flux layers. Use ",{"attributes":{},"tag":"code","children":["gain"],"type":"node"}," to scale the identity by a constant."],"type":"node"},{"attributes":{},"tag":"p","children":["Often useful in the context of transfer learning, i.e when one wants to add more capacity to a model but start from the same mapping."],"type":"node"},{"attributes":{},"tag":"p","children":["Has the following behaviour"],"type":"node"},{"attributes":{},"tag":"ul","children":[{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":["1D: A ",{"attributes":{},"tag":"code","children":["Vector"],"type":"node"}," of ",{"attributes":{},"tag":"code","children":["zeros"],"type":"node"}," (useful for an identity bias)"],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":["2D: An identity matrix (useful for an identity matrix multiplication)"],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":["More than 2D: A dense block array of center tap spatial filters (useful for an identity convolution)"],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"p","children":["Some caveats:"],"type":"node"},{"attributes":{},"tag":"ul","children":[{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":["Not all layers will be identity mapping when used with this init. Exceptions include recurrent layers and normalization layers."],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":["Layers must have ",{"attributes":{},"tag":"code","children":["input_size == output_size"],"type":"node"}," for identity mapping to be possible. When this is not the case, extra dimensions of the array are padded with zeros."],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":["For convolutional layers, in addition to the above, the kernel sizes must also be odd and padding must be applied so that output feature maps have the same size as input feature maps, e.g by using ",{"attributes":{"reftype":"symbol","href":"@ref","title":"","document_id":"Flux@0.13.11/ref/Flux.SamePad"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["SamePad"],"type":"node"}],"type":"node"},"."],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"p","children":["Use keyword ",{"attributes":{},"tag":"code","children":["shift"],"type":"node"}," (integer or tuple) to apply circular shift to the output, equivalent to ",{"attributes":{},"tag":"code","children":["Base.circshift(identity_init(size...), shift)"],"type":"node"},"."],"type":"node"},{"attributes":{},"tag":"p","children":["For consistency with other initialisers, it accepts ",{"attributes":{},"tag":"code","children":["rng::AbstractRNG"],"type":"node"}," as an optional first argument. But this is ignored, since the result is not random."],"type":"node"},{"attributes":{},"tag":"h1","children":["Examples"],"type":"node"},{"attributes":{"lang":"jldoctest"},"tag":"codeblock","children":["julia> Flux.identity_init(3,5)\n3×5 Matrix{Float32}:\n 1.0  0.0  0.0  0.0  0.0\n 0.0  1.0  0.0  0.0  0.0\n 0.0  0.0  1.0  0.0  0.0\n\njulia> Dense(5 => 3, relu, init=Flux.identity_init)([1,-2,3,-4,5])\n3-element Vector{Float32}:\n 1.0\n 0.0\n 3.0\n\njulia> Flux.identity_init(3,3,2; gain=100)\n3×3×2 Array{Float32, 3}:\n[:, :, 1] =\n   0.0  0.0  0.0\n 100.0  0.0  0.0\n   0.0  0.0  0.0\n\n[:, :, 2] =\n 0.0    0.0  0.0\n 0.0  100.0  0.0\n 0.0    0.0  0.0\n\njulia> x4 = cat([1 2 3; 4 5 6; 7 8 9]; dims=4);\n\njulia> Conv((2,2), 1 => 1, init=Flux.identity_init(gain=10), pad=SamePad())(x4)\n3×3×1×1 Array{Float32, 4}:\n[:, :, 1, 1] =\n 10.0  20.0  30.0\n 40.0  50.0  60.0\n 70.0  80.0  90.0\n"],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"}