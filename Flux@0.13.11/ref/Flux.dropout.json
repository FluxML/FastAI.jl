{"attributes":{"kind":"function","backlinks":[{"tag":"documentation","title":"Dropout","docid":"Flux@0.13.11/ref/Flux.Dropout"},{"tag":"sourcefile","title":"FastVision/models/blocks.jl","docid":"FastVision@0.1.1/src/models/blocks.jl"},{"tag":"sourcefile","title":"Flux/layers/normalise.jl","docid":"Flux@0.13.11/src/layers/normalise.jl"}],"methods":[{"symbol_id":"Flux.dropout","module_id":"Flux","file":"layers/normalise.jl","line":37,"signature":"(::Signature)"},{"symbol_id":"Flux.dropout","module_id":"Flux","file":"layers/normalise.jl","line":32,"signature":"(::Signature)"}],"package_id":"Flux@0.13.11","title":"dropout","symbol_id":"Flux.dropout","exported":true,"module_id":"Flux"},"tag":"documentation","children":[{"attributes":{"symbol":"Flux.dropout","line":12,"module":"Flux","file":"layers/normalise.jl"},"tag":"docstring","children":[{"attributes":{},"tag":"md","children":[{"attributes":{"lang":""},"tag":"codeblock","children":["dropout([rng = rng_from_array(x)], x, p; dims=:, active=true)\n"],"type":"node"},{"attributes":{},"tag":"p","children":["The dropout function. If ",{"attributes":{},"tag":"code","children":["active"],"type":"node"}," is ",{"attributes":{},"tag":"code","children":["true"],"type":"node"},", for each input, either sets that input to ",{"attributes":{},"tag":"code","children":["0"],"type":"node"}," (with probability ",{"attributes":{},"tag":"code","children":["p"],"type":"node"},") or scales it by ",{"attributes":{},"tag":"code","children":["1 / (1 - p)"],"type":"node"},". ",{"attributes":{},"tag":"code","children":["dims"],"type":"node"}," specifies the unbroadcasted dimensions, e.g. ",{"attributes":{},"tag":"code","children":["dims=1"],"type":"node"}," applies dropout along columns and ",{"attributes":{},"tag":"code","children":["dims=2"],"type":"node"}," along rows. If ",{"attributes":{},"tag":"code","children":["active"],"type":"node"}," is ",{"attributes":{},"tag":"code","children":["false"],"type":"node"},", it just returns the input ",{"attributes":{},"tag":"code","children":["x"],"type":"node"},"."],"type":"node"},{"attributes":{},"tag":"p","children":["Specify ",{"attributes":{},"tag":"code","children":["rng"],"type":"node"}," for custom RNGs instead of the default RNG. Note that custom RNGs are only supported on the CPU."],"type":"node"},{"attributes":{},"tag":"p","children":["Warning: when using this function, you have to manually manage the activation state. Usually in fact, dropout is used while training but is deactivated in the inference phase. This can be automatically managed using the ",{"attributes":{"reftype":"symbol","href":"@ref","title":"","document_id":"Flux@0.13.11/ref/Flux.Dropout"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["Dropout"],"type":"node"}],"type":"node"}," layer instead of the ",{"attributes":{},"tag":"code","children":["dropout"],"type":"node"}," function."],"type":"node"},{"attributes":{},"tag":"p","children":["The ",{"attributes":{"reftype":"symbol","href":"@ref","title":"","document_id":"Flux@0.13.11/ref/Flux.Dropout"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["Dropout"],"type":"node"}],"type":"node"}," layer is what you should use in most scenarios."],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"}