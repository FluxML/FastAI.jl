{"attributes":{"kind":"function","backlinks":[{"tag":"sourcefile","title":"Flux/train.jl","docid":"Flux@0.13.11/src/train.jl"},{"tag":"sourcefile","title":"Flux/deprecations.jl","docid":"Flux@0.13.11/src/deprecations.jl"},{"tag":"sourcefile","title":"Flux/optimise/Optimise.jl","docid":"Flux@0.13.11/src/optimise/Optimise.jl"},{"tag":"sourcefile","title":"Flux/optimise/train.jl","docid":"Flux@0.13.11/src/optimise/train.jl"}],"methods":[{"symbol_id":"Flux.Optimise.train!","module_id":"Flux.Optimise","file":"optimise/train.jl","line":136,"signature":"(::Signature)"},{"symbol_id":"Flux.Optimise.train!","module_id":"Flux","file":"deprecations.jl","line":107,"signature":"(::Signature)"},{"symbol_id":"Flux.Optimise.train!","module_id":"Flux.Train","file":"train.jl","line":117,"signature":"(::Signature)"},{"symbol_id":"Flux.Optimise.train!","module_id":"Flux","file":"deprecations.jl","line":101,"signature":"(::Signature)"},{"symbol_id":"Flux.Optimise.train!","module_id":"Flux","file":"deprecations.jl","line":113,"signature":"(::Signature)"},{"symbol_id":"Flux.Optimise.train!","module_id":"Flux.Train","file":"train.jl","line":102,"signature":"(::Signature)"}],"package_id":"Flux@0.13.11","title":"train!","symbol_id":"Flux.Optimise.train!","exported":true,"module_id":"Flux.Optimise"},"tag":"documentation","children":[{"attributes":{"symbol":"Flux.Optimise.train!","line":92,"module":"Flux.Optimise","file":"optimise/train.jl"},"tag":"docstring","children":[{"attributes":{},"tag":"md","children":[{"attributes":{"lang":""},"tag":"codeblock","children":["train!(loss, pars::Params, data, opt::AbstractOptimiser; [cb])\n"],"type":"node"},{"attributes":{},"tag":"p","children":["Uses a ",{"attributes":{},"tag":"code","children":["loss"],"type":"node"}," function and training ",{"attributes":{},"tag":"code","children":["data"],"type":"node"}," to improve the model's parameters according to a particular optimisation rule ",{"attributes":{},"tag":"code","children":["opt"],"type":"node"},"."],"type":"node"},{"attributes":{"class":"compat"},"tag":"admonition","children":[{"attributes":{},"tag":"admonitiontitle","children":["Deprecated"],"type":"node"},{"attributes":{},"tag":"admonitionbody","children":[{"attributes":{},"tag":"p","children":["This method with implicit ",{"attributes":{},"tag":"code","children":["Params"],"type":"node"}," will be removed from Flux 0.14. It should be replaced with the explicit method ",{"attributes":{},"tag":"code","children":["train!(loss, model, data, opt)"],"type":"node"},"."],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"p","children":["For each ",{"attributes":{},"tag":"code","children":["d in data"],"type":"node"},", first the gradient of the ",{"attributes":{},"tag":"code","children":["loss"],"type":"node"}," is computed like this:"],"type":"node"},{"attributes":{"lang":""},"tag":"codeblock","children":["    gradient(() -> loss(d...), pars)  # if d isa Tuple\n    gradient(() -> loss(d), pars)     # otherwise\n"],"type":"node"},{"attributes":{},"tag":"p","children":["Here ",{"attributes":{},"tag":"code","children":["pars"],"type":"node"}," is produced by calling ",{"attributes":{"reftype":"symbol","href":"@ref","title":"","document_id":"Flux@0.13.11/ref/Flux.params"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["Flux.params"],"type":"node"}],"type":"node"}," on your model. (Or just on the layers you want to train, like ",{"attributes":{},"tag":"code","children":["train!(loss, params(model[1:end-2]), data, opt)"],"type":"node"},".) This is the \"implicit\" style of parameter handling."],"type":"node"},{"attributes":{},"tag":"p","children":["This gradient is then used by optimizer ",{"attributes":{},"tag":"code","children":["opt"],"type":"node"}," to update the parameters:"],"type":"node"},{"attributes":{"lang":""},"tag":"codeblock","children":["    update!(opt, pars, grads)\n"],"type":"node"},{"attributes":{},"tag":"p","children":["The optimiser should be from the ",{"attributes":{},"tag":"code","children":["Flux.Optimise"],"type":"node"}," module (see ",{"attributes":{"href":"@ref","title":"","document_id":"@ref"},"tag":"reference","children":["Optimisers"],"type":"node"},"). Different optimisers can be combined using [",{"attributes":{},"tag":"code","children":["Flux.Optimise.Optimiser"],"type":"node"},"](",{"attributes":{"id":"ref"},"tag":"citation","children":[],"type":"node"}," Flux.Optimiser)."],"type":"node"},{"attributes":{},"tag":"p","children":["This training loop iterates through ",{"attributes":{},"tag":"code","children":["data"],"type":"node"}," once. It will stop with a ",{"attributes":{},"tag":"code","children":["DomainError"],"type":"node"}," if the loss is ",{"attributes":{},"tag":"code","children":["NaN"],"type":"node"}," or infinite."],"type":"node"},{"attributes":{},"tag":"p","children":["You can use ",{"attributes":{"href":"@ref","title":""},"tag":"a","children":[{"attributes":{},"tag":"code","children":["@epochs"],"type":"node"}],"type":"node"}," to do this several times, or use for instance ",{"attributes":{},"tag":"code","children":["Itertools.ncycle"],"type":"node"}," to make a longer ",{"attributes":{},"tag":"code","children":["data"],"type":"node"}," iterator."],"type":"node"},{"attributes":{},"tag":"h2","children":["Callbacks"],"type":"node"},{"attributes":{},"tag":"p","children":[{"attributes":{"href":"@ref","title":"","document_id":"@ref"},"tag":"reference","children":["Callbacks"],"type":"node"}," are given with the keyword argument ",{"attributes":{},"tag":"code","children":["cb"],"type":"node"},". For example, this will print \"training\" every 10 seconds (using ",{"attributes":{"reftype":"symbol","href":"@ref","title":"","document_id":"Flux@0.13.11/ref/Flux.throttle"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["Flux.throttle"],"type":"node"}],"type":"node"},"):"],"type":"node"},{"attributes":{"lang":""},"tag":"codeblock","children":["    train!(loss, params, data, opt, cb = throttle(() -> println(\"training\"), 10))\n"],"type":"node"},{"attributes":{},"tag":"p","children":["The callback can call ",{"attributes":{"href":"@ref","title":""},"tag":"a","children":[{"attributes":{},"tag":"code","children":["Flux.stop"],"type":"node"}],"type":"node"}," to interrupt the training loop."],"type":"node"},{"attributes":{},"tag":"p","children":["Multiple callbacks can be passed to ",{"attributes":{},"tag":"code","children":["cb"],"type":"node"}," as array."],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"}