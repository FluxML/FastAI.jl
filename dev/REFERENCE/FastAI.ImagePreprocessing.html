<HTML><head><title>FastAI.ImagePreprocessing</title><script src=../template/highlight.min.js ></script><script src=../template/julia.min.js ></script><script src=../template/loadhighlightjs.js ></script><link href=../template/ansi.css rel=stylesheet ></link><link href=../template/hugobook.css rel=stylesheet ></link><meta content=Type=text/html; charset=utf-8 http-equiv=Content-Type ></meta><meta name=viewport content=width=device-width, initial-scale=1 ></meta></head><body><input onclick=toggleMenu() id=menu-control class=hidden toggle type=checkbox ></input><input id=toc-control type=checkbox class=hidden toggle ></input><main class=container flex ><aside id=menu-container class=book-menu ><nav class=book-menu-content ><h2 id=title >FastAI.jl</h2><div id=sidebar ><div class=doctree ><body><ul><li><p><a href=../README.md.html title= >README</a></p></li><li><p><a href=../docs/setup.md.html title= >Setup</a></p></li><li><p><a href=../notebooks/quickstart.ipynb.html title= >Quickstart</a></p></li><li><p>Tutorials</p><ul><li><p>Beginner</p><ul><li><p><a href=../docs/introduction.md.html title= >Introduction</a></p></li><li><p><a href=../docs/discovery.md.html title= >Discovery</a></p></li></ul></li><li><p>Intermediate</p><ul><li><p><a href=../notebooks/imagesegmentation.ipynb.html title= >Image segmentation</a></p></li><li><p><a href=../notebooks/keypointregression.ipynb.html title= >Keypoint regression</a></p></li><li><p><a href=../notebooks/tabularclassification.ipynb.html title= >Tabular classification</a></p></li><li><p><a href=../docs/data_containers.md.html title= >Data containers</a></p></li><li><p><a href=../notebooks/serialization.ipynb.html title= >Saving and loading models</a></p></li></ul></li><li><p>Advanced</p><ul><li><p><a href=../notebooks/presizing.ipynb.html title= >Presizing vision datasets</a></p></li><li><p><a href=../docs/learning_methods.md.html title= >Custom Learning methods</a></p></li></ul></li></ul></li><li><p>How To</p><ul><li><p><a href=../notebooks/training.ipynb.html title= >Train your model</a></p></li><li><p><a href=../docs/howto/augmentvision.md.html title= >Augment vision data</a></p></li><li><p><a href=../docs/howto/logtensorboard.md.html title= >Log to TensorBoard</a></p></li></ul></li><li><p>Reference</p><ul><li><p><a href=../REFERENCE.html title= >Docstrings</a></p></li><li><p><a href=../docs/fastai_api_comparison.md.html title= >fastai API comparison</a></p></li><li><p><a href=../docs/interfaces.md.html title= >Extension APIs</a></p></li><li><p><a href=../docs/glossary.md.html title= >Glossary</a></p></li></ul></li><li><p>Background</p><ul><li><p><a href=../docs/background/blocksencodings.md.html title= >Blocks and encodings</a></p></li><li><p><a href=../docs/background/datapipelines.md.html title= >Performant data pipelines</a></p></li></ul></li></ul></body></div></div></nav></aside><div class=book-page ><header class=book-header ></header><article><article><h1 id=fastaiimagepreprocessing ><code>FastAI.ImagePreprocessing</code></h1><div class=docs ><div typesig=Union{} module=FastAI linenumber=24 binding=FastAI.ImagePreprocessing path=/home/runner/work/FastAI.jl/FastAI.jl/src/encodings/imagepreprocessing.jl class=doc fields=Dict{Symbol, Any}() ><pre lang= ><code>ImagePreprocessing([; kwargs...]) &lt;: Encoding
</code></pre><p>Encodes <code>Image</code>s by converting them to a common color type <code>C</code>,
expanding the color channels and normalizing the channel values.
Additionally, apply pixel-level augmentations passed in as <code>augmentations</code>
during <code>Training</code>.</p><p>Currently works with 2D images only, but this constraint will be
removed in the future.</p><p>Encodes</p><ul><li><p><code>Image{2}</code> -&gt; <code>ImageTensor{3}</code></p></li></ul><h2 id=keyword-arguments >Keyword arguments</h2><ul><li><p><code>augmentations::</code><a href=DataAugmentation.Transform.html ><code>Transform</code></a>: Augmentation to apply to every image
before preprocessing. See <a href=FastAI.augs_lighting.html ><code>augs_lighting</code></a></p></li><li><p><code>buffered = true</code>: Whether to use inplace transformations. Reduces memory usage.</p></li><li><p><code>means::SVector = IMAGENET_MEANS</code>: mean value of each color channel.</p></li><li><p><code>stds::SVector = IMAGENET_STDS</code>: standard deviation of each color channel.</p></li><li><p><code>C::Type{&lt;:Colorant} = RGB{N0f8}</code>: color type to convert images to.</p></li><li><p><code>T::Type{&lt;:Real} = Float32</code>: element type of output</p></li></ul></div></div></article></article><footer class=book-footer ></footer></div><aside class=book-toc ><nav id=toc class=book-toc-content ><ul><li><a href=#fastaiimagepreprocessing >FastAI.ImagePreprocessing</a><ul></ul></li></ul></nav></aside></main></body></HTML>