<HTML><head><title>FastAI.Vision.Models.UNetDynamic</title><script src=../template/highlight.min.js ></script><script src=../template/julia.min.js ></script><script src=../template/loadhighlightjs.js ></script><link href=../template/ansi.css rel=stylesheet ></link><link href=../template/hugobook.css rel=stylesheet ></link><meta content=Type=text/html; charset=utf-8 http-equiv=Content-Type ></meta><meta name=viewport content=width=device-width, initial-scale=1 ></meta></head><body><input onclick=toggleMenu() id=menu-control class=hidden toggle type=checkbox ></input><input id=toc-control type=checkbox class=hidden toggle ></input><main class=container flex ><aside id=menu-container class=book-menu ><nav class=book-menu-content ><h2 id=title >FastAI.jl</h2><div id=sidebar ><div class=doctree ><body><ul><li><p><a href=../README.md.html title= >README</a></p></li><li><p><a href=../docs/setup.md.html title= >Setup</a></p></li><li><p><a href=../notebooks/quickstart.ipynb.html title= >Quickstart</a></p></li><li><p>Tutorials</p><ul><li><p>Beginner</p><ul><li><p><a href=../docs/introduction.md.html title= >Introduction</a></p></li><li><p><a href=../docs/discovery.md.html title= >Discovery</a></p></li></ul></li><li><p>Intermediate</p><ul><li><p><a href=../notebooks/imagesegmentation.ipynb.html title= >Image segmentation</a></p></li><li><p><a href=../notebooks/keypointregression.ipynb.html title= >Keypoint regression</a></p></li><li><p><a href=../notebooks/tabularclassification.ipynb.html title= >Tabular classification</a></p></li><li><p><a href=../docs/data_containers.md.html title= >Data containers</a></p></li><li><p><a href=../notebooks/serialization.ipynb.html title= >Saving and loading models</a></p></li></ul></li><li><p>Advanced</p><ul><li><p><a href=../notebooks/presizing.ipynb.html title= >Presizing vision datasets</a></p></li><li><p><a href=../notebooks/vae.ipynb.html title= >Unsupervised learning</a></p></li><li><p><a href=../docs/learning_tasks.md.html title= >Custom Learning tasks</a></p></li></ul></li></ul></li><li><p>How To</p><ul><li><p><a href=../notebooks/training.ipynb.html title= >Train your model</a></p></li><li><p><a href=../docs/howto/augmentvision.md.html title= >Augment vision data</a></p></li><li><p><a href=../docs/howto/logtensorboard.md.html title= >Log to TensorBoard</a></p></li></ul></li><li><p>Reference</p><ul><li><p><a href=../REFERENCE.html title= >Docstrings</a></p></li><li><p><a href=../docs/fastai_api_comparison.md.html title= >fastai API comparison</a></p></li><li><p><a href=../docs/interfaces.md.html title= >Extension APIs</a></p></li><li><p><a href=../docs/glossary.md.html title= >Glossary</a></p></li></ul></li><li><p>Background</p><ul><li><p><a href=../docs/background/blocksencodings.md.html title= >Blocks and encodings</a></p></li><li><p><a href=../docs/background/datapipelines.md.html title= >Performant data pipelines</a></p></li></ul></li></ul></body></div></div></nav></aside><div class=book-page ><header class=book-header ></header><article><article><h1 id=fastaivisionmodelsunetdynamic ><code>FastAI.Vision.Models.UNetDynamic</code></h1><div class=docs ><div typesig=Tuple{Any, Any, Int64} module=FastAI.Vision.Models linenumber=1 binding=FastAI.Vision.Models.UNetDynamic path=/home/runner/work/FastAI.jl/FastAI.jl/src/Vision/models/unet.jl class=doc ><pre lang= ><code>UNetDynamic(backbone, inputsize, k_out[; kwargs...])
</code></pre><p>Create a U-Net model from convolutional <code>backbone</code> architecture. After every
downsampling layer (i.e. pooling or strided convolution), a skip connection and
an upsampling block are inserted, resulting in a convolutional network with
the same spatial output dimensions as its input. Outputs an array with <code>k_out</code>
channels.</p><h2 id=keyword-arguments >Keyword arguments</h2><ul><li><p><code>upsample</code>: A <em>constructor</em> for an upsampling block callable with <code>upsample(insize, k_out)</code>.
If <code>insize</code> is <code>(h, w, k, b)</code>, then the output should have size <code>(2h, 2w, k_out, b)</code>.
Defaults to <a href=# title= ><code>FastAI.Models.upsample_block_small</code></a>.</p></li><li><p><code>agg</code>: Aggregation function for skip connection. Default concatenates in the
channel dimension. Use <code>+</code> for summing and see <a href=Flux.SkipConnection.html ><code>Flux.SkipConnection</code></a> for more
details.</p></li><li><p><code>fdownscale = 0</code>: Number of upsampling steps to leave out. By default there will be one
upsampling step for every downsampling step in <code>backbone</code>. Hence if the input spatial
size is <code>(h, w)</code>, the output size will be <code>(h/2^fdownscale, w/2^fdownscale)</code>, i.e.
to get outputs at half the resolution, set <code>fdownscale = 1</code>.</p></li><li><p><code>kwargs...</code>: Other keyword arguments are passed through to <code>upsample</code>.</p></li></ul><h2 id=examples >Examples</h2><pre lang=julia ><code>using FastAI, Metalhead

backbone = Metalhead.ResNet50(pretrain=true).layers[1][1:end-1]
unet = UNetDynamic(backbone, (256, 256, 3, 1); k_out = 10)
Flux.outputsize(unet, (256, 256, 3, 1)) == (256, 256, 10, 1)

unet = UNetDynamic(backbone, (256, 256, 3, 1); fdownscalk_out = 10)
Flux.outputsize(unet, (256, 256, 3, 1)) == (256, 256, 10, 1)
</code></pre></div><h2 id=methods >Methods</h2># 1 method for generic function <b>UNetDynamic</b>:<ul><li> UNetDynamic(backbone, inputsize, k_out::<b>Int64</b>; <i>final, fdownscale, kwargs...</i>) in FastAI.Vision.Models at <a href="https://github.com/FluxML/FastAI.jl/tree/294f367a5600dcab6f9c6626f85109b1ab7b1c3e//src/Vision/models/unet.jl#L37" target="_blank">/home/runner/work/FastAI.jl/FastAI.jl/src/Vision/models/unet.jl:37</a></li> </ul></div></article></article><footer class=book-footer ></footer></div><aside class=book-toc ><nav id=toc class=book-toc-content ><ul><li><a href=#fastaivisionmodelsunetdynamic >FastAI.Vision.Models.UNetDynamic</a><ul></ul></li></ul></nav></aside></main></body></HTML>