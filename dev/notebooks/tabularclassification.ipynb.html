<HTML><head><title>Tabular Classification</title><script src=../template/highlight.min.js ></script><script src=../template/julia.min.js ></script><script src=../template/loadhighlightjs.js ></script><link href=../template/ansi.css rel=stylesheet ></link><link href=../template/hugobook.css rel=stylesheet ></link><meta content=Type=text/html; charset=utf-8 http-equiv=Content-Type ></meta><meta name=viewport content=width=device-width, initial-scale=1 ></meta></head><body><input onclick=toggleMenu() id=menu-control class=hidden toggle type=checkbox ></input><input id=toc-control type=checkbox class=hidden toggle ></input><main class=container flex ><aside id=menu-container class=book-menu ><nav class=book-menu-content ><h2 id=title >FastAI.jl</h2><div id=sidebar ><div class=doctree ><body><ul><li><p><a href=../README.md.html title= >README</a></p></li><li><p><a href=../docs/setup.md.html title= >Setup</a></p></li><li><p><a href=quickstart.ipynb.html title= >Quickstart</a></p></li><li><p>Tutorials</p><ul><li><p>Beginner</p><ul><li><p><a href=../docs/introduction.md.html title= >Introduction</a></p></li><li><p><a href=../docs/discovery.md.html title= >Discovery</a></p></li></ul></li><li><p>Intermediate</p><ul><li><p><a href=imagesegmentation.ipynb.html title= >Image segmentation</a></p></li><li><p><a href=keypointregression.ipynb.html title= >Keypoint regression</a></p></li><li><p><a href=tabularclassification.ipynb.html title= >Tabular classification</a></p></li><li><p><a href=../docs/data_containers.md.html title= >Data containers</a></p></li><li><p><a href=serialization.ipynb.html title= >Saving and loading models</a></p></li></ul></li><li><p>Advanced</p><ul><li><p><a href=presizing.ipynb.html title= >Presizing vision datasets</a></p></li><li><p><a href=../docs/learning_methods.md.html title= >Custom Learning methods</a></p></li></ul></li></ul></li><li><p>How To</p><ul><li><p><a href=training.ipynb.html title= >Train your model</a></p></li><li><p><a href=../docs/howto/augmentvision.md.html title= >Augment vision data</a></p></li><li><p><a href=how_to_visualize.ipynb.html title= >Visualize data</a></p></li><li><p><a href=../docs/howto/logtensorboard.md.html title= >Log to TensorBoard</a></p></li></ul></li><li><p>Reference</p><ul><li><p><a href=../REFERENCE.html title= >Docstrings</a></p></li><li><p><a href=../docs/fastai_api_comparison.md.html title= >fastai API comparison</a></p></li><li><p><a href=../docs/interfaces.md.html title= >Extension APIs</a></p></li><li><p><a href=../docs/glossary.md.html title= >Glossary</a></p></li></ul></li><li><p>Background</p><ul><li><p><a href=../docs/background/blocksencodings.md.html title= >Blocks and encodings</a></p></li><li><p><a href=../docs/background/datapipelines.md.html title= >Performant data pipelines</a></p></li></ul></li></ul></body></div></div></nav></aside><div class=book-page ><header class=book-header ></header><article><h1 id=tabular-classification >Tabular Classification</h1><p>Tabular Classification involves having a categorical column as the target. Here, weâ€™ll use the adult sample dataset from fastai and try to predict whether the salary is above 50K or not, making this a binary classification task.</p><pre lang=julia ><code>using Flux
using FastAI
using Tables
using Statistics
using FluxTraining
import DataAugmentation</code></pre><p>We can quickly download and get the path of any dataset from fastai by using <code>datasetpath</code>. Once we have the path, weâ€™ll load the data in a <code>TableContainer</code>. By default, if we pass in just the path to <code>TableContainer</code>, the data is loaded in a <code>DataFrame</code>, but we can use any package for accessing our data, and pass an object satisfying the Tables.jl interface to it.</p><pre lang=julia ><code>data = TableDataset(joinpath(datasetpath(&quot;adult_sample&quot;), &quot;adult.csv&quot;))</code></pre><pre class=coderesult ><code>TableDataset{DataFrames.DataFrame}([1m32561Ã—15 DataFrame[0m
[1m   Row [0mâ”‚[1m age   [0m[1m workclass         [0m[1m fnlwgt [0m[1m education     [0m[1m education-num [0m[1m marit[0m â‹¯
[1m       [0mâ”‚[90m Int64 [0m[90m String            [0m[90m Int64  [0m[90m String        [0m[90m Float64?      [0m[90m Strin[0m â‹¯
â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
     1 â”‚    49   Private           101320   Assoc-acdm             12.0   Marr â‹¯
     2 â”‚    44   Private           236746   Masters                14.0   Divo
     3 â”‚    38   Private            96185   HS-grad      [90m     missing   [0m  Divo
     4 â”‚    38   Self-emp-inc      112847   Prof-school            15.0   Marr
     5 â”‚    42   Self-emp-not-inc   82297   7th-8th      [90m     missing   [0m  Marr â‹¯
     6 â”‚    20   Private            63210   HS-grad                 9.0   Neve
     7 â”‚    49   Private            44434   Some-college           10.0   Divo
     8 â”‚    37   Private           138940   11th                    7.0   Marr
     9 â”‚    46   Private           328216   HS-grad                 9.0   Marr â‹¯
    10 â”‚    36   Self-emp-inc      216711   HS-grad      [90m     missing   [0m  Marr
    11 â”‚    23   Private           529223   Bachelors              13.0   Neve
   â‹®   â”‚   â‹®            â‹®            â‹®           â‹®              â‹®              â‹±
 32552 â”‚    60   Private           230545   7th-8th                 4.0   Divo
 32553 â”‚    39   Private           139743   HS-grad                 9.0   Sepa â‹¯
 32554 â”‚    35   Self-emp-inc      135436   Prof-school            15.0   Marr
 32555 â”‚    53   Private            35102   Some-college           10.0   Divo
 32556 â”‚    48   Private           355320   Bachelors              13.0   Marr
 32557 â”‚    36   Private           297449   Bachelors              13.0   Divo â‹¯
 32558 â”‚    23   ?                 123983   Bachelors              13.0   Neve
 32559 â”‚    53   Private           157069   Assoc-acdm             12.0   Marr
 32560 â”‚    32   Local-gov         217296   HS-grad                 9.0   Marr
 32561 â”‚    26   Private           182308   Some-college           10.0   Marr â‹¯
[36m                                               10 columns and 32540 rows omitted[0m)</code></pre><p>In case our data was present in a different format for eg. parquet, it could be loaded in a TableContainer as shown below.</p><pre lang=julia ><code>
using Parquet

TableDataset(read_parquet(parquet_path));

</code></pre><p><code>mapobs</code> is used here to split our target column from the rest of the row in a lazy manner.</p><pre lang=julia ><code>splitdata = mapobs(row -&gt; (row, row[:salary]), data);</code></pre><p>To create a learning method for tabular classification task, we need an input block, an output block, and the encodings to be performed on the data.</p><p>The input block here is a <code>TableRow</code> which contains information about the nature of the columns (ie. categorical or continuous) along with an indexable collection mapping categorical column names to a collection with distinct classes in that column. We can get this mapping by using the <code>gettransformationdict</code> method with <code>DataAugmentation.Categorify</code>.</p><p>The outblock block used is <code>Label</code> for single column classification and the unique classes have to passed to it.</p><p>This is followed by the encodings which needs to be applied on our input and output blocks. For the input block, we have used the <code>gettransforms</code> function here to get a standard bunch of transformations to apply, but this can be easily customized by passing in any tabular transformation from DataAugmentation.jl or a composition of those, to <code>TabularPreprocessings</code>. In addition to this, we have just one-hot encoded the outblock.</p><pre lang=julia ><code>cat, cont = FastAI.getcoltypes(data)
target = :salary
cat = filter(!isequal(target), cat)
catdict = FastAI.gettransformdict(data, DataAugmentation.Categorify, cat);</code></pre><pre lang=julia ><code>inputblock = TableRow(cat, cont, catdict)
targetblock = Label(unique(data.table[:, target]))

method = BlockMethod(
    (inputblock, targetblock),
    (
        setup(TabularPreprocessing, inputblock, data),
        FastAI.OneHot()
    )
)</code></pre><pre class=codeoutput ><code>â”Œ Warning: There is a missing value present for category &#39;occupation&#39; which will be removed from Categorify dict
â”” @ DataAugmentation /home/lorenz/.julia/dev/DataAugmentation/src/rowtransforms.jl:108
</code></pre><pre class=coderesult ><code>BlockMethod(TableRow{8, 6, Dict{Any, Any}} -> Label{String})</code></pre><p>In case our initial problem wasnâ€™t a classification task, and we had a continuous target column, we would need to perform tabular regression. To create a learning method suitable for regression, we use a <code>Continuous</code> block for representing our target column. This can be done even with multiple continuous target columns by just passing the number of columns in <code>Continuous</code>. For example, the method here could be used for 3 targets.</p><pre lang=julia ><code>
method2 = BlockMethod(

    (

        TableRow(cat, cont, catdict), 

        Continuous(3)

    ),

    ((FastAI.TabularPreprocessing(data),)),

    outputblock = Continuous(3)

)

</code></pre><p>To get an overview of the learning method created, and as a sanity test, we can use the <code>describemethod</code> function. This shows us what encodings will be applied to which blocks, and how the predicted Å· values are decoded.</p><pre lang=julia ><code>describemethod(method)</code></pre><pre class=coderesult ><code>[1m  [36mLearningMethod[39m summary[22m
[1m  ------------------------[22m

    â€¢  Task: [36mTableRow{8, 6, Dict{Any, Any}} -> Label{String}[39m

    â€¢  Model blocks: [36mFastAI.EncodedTableRow{8, 6, Dict{Any, Any}} ->
       FastAI.OneHotTensor{0, String}[39m

  Encoding a sample ([36mencode(method, context, sample)[39m)

              Encoding            Name                             [36mmethod.blocks[1][39m               [36mmethod.blocks[2][39m
  â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“ â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“ â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“ â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“
                       [36m(input, target)[39m               [36mTableRow{8, 6, Dict{Any, Any}}[39m                  [36mLabel{String}[39m
  [36mTabularPreprocessing[39m                 [1m[36mFastAI.EncodedTableRow{8, 6, Dict{Any, Any}}[39m[22m                  [36mLabel{String}[39m
                [36mOneHot[39m          [36m(x, y)[39m [36mFastAI.EncodedTableRow{8, 6, Dict{Any, Any}}[39m [1m[36mFastAI.OneHotTensor{0, String}[39m[22m

  Decoding a model output ([36mdecode(method, context, yÌ‚)[39m)

              Decoding        Name             [36mmethod.outputblock[39m
  â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“ â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“ â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“
                                [36myÌ‚[39m [36mFastAI.OneHotTensor{0, String}[39m
                [36mOneHot[39m                              [1m[36mLabel{String}[39m[22m
  [36mTabularPreprocessing[39m [36mtarget_pred[39m                  [36mLabel{String}[39m</code></pre><p><code>getobs</code> gets us a row of data from the <code>TableContainer</code>, which we encode here. This gives us a tuple with the input and target. The input here is again a tuple, containing the categorical values (which have been label encoded or â€œcategorifiedâ€) and the continuous values (which have been normalized and any missing values have been filled).</p><pre lang=julia ><code>getobs(splitdata, 1000)</code></pre><pre class=coderesult ><code>([1mDataFrameRow[0m
[1m  Row [0mâ”‚[1m age   [0m[1m workclass  [0m[1m fnlwgt [0m[1m education [0m[1m education-num [0m[1m marital-status   [0m â‹¯
[1m      [0mâ”‚[90m Int64 [0m[90m String     [0m[90m Int64  [0m[90m String    [0m[90m Float64?      [0m[90m String           [0m â‹¯
â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 1000 â”‚    61   State-gov  162678   5th-6th             3.0   Married-civ-spou â‹¯
[36m                                                              10 columns omitted[0m, "<50k")</code></pre><pre lang=julia ><code>x = encode(method, Training(), getobs(splitdata, 1000))</code></pre><pre class=coderesult ><code>(([5, 16, 2, 10, 5, 2, 3, 2], [1.6435221651965317, -0.2567538819371021, -2.751580937680526, -0.14591824281680102, -0.21665620002803673, -0.035428902921319616]), Float32[0.0, 1.0])</code></pre><p>To quickly get a model suitable for our learning method, we can use the <code>methodmodel</code> function.</p><pre lang=julia ><code>model = methodmodel(method)</code></pre><pre class=coderesult ><code>Chain(
  Parallel(
    vcat,
    Chain(
      FastAI.Models.var"#41#43"(),
      Parallel(
        vcat,
        Embedding(10, 6),               [90m# 60 parameters[39m
        Embedding(17, 8),               [90m# 136 parameters[39m
        Embedding(8, 5),                [90m# 40 parameters[39m
        Embedding(17, 8),               [90m# 136 parameters[39m
        Embedding(7, 5),                [90m# 35 parameters[39m
        Embedding(6, 4),                [90m# 24 parameters[39m
        Embedding(3, 3),                [90m# 9 parameters[39m
        Embedding(43, 13),              [90m# 559 parameters[39m
      ),
      identity,
    ),
    BatchNorm(6),                       [90m# 12 parameters[39m[90m, plus 12[39m
  ),
  Chain(
    Dense(58, 200, relu; bias=false),   [90m# 11_600 parameters[39m
    BatchNorm(200),                     [90m# 400 parameters[39m[90m, plus 400[39m
    identity,
  ),
  Chain(
    Dense(200, 100, relu; bias=false),  [90m# 20_000 parameters[39m
    BatchNorm(100),                     [90m# 200 parameters[39m[90m, plus 200[39m
    identity,
  ),
  Dense(100, 2),                        [90m# 202 parameters[39m
)[90m                   # Total: 18 arrays, [39m33_413 parameters, 130.172 KiB.</code></pre><p>It is really simple to create a custom backbone using the functions present in <code>FastAI.Models</code>.</p><pre lang=julia ><code>cardinalities = collect(map(col -&gt; length(catdict[col]), cat))

ovdict = Dict(:workclass =&gt; 10, :education =&gt; 12, Symbol(&quot;native-country&quot;) =&gt; 16)
overrides = collect(map(col -&gt; col in keys(ovdict) ? ovdict[col] : nothing, cat))

embedszs = FastAI.Models.get_emb_sz(cardinalities, overrides)
catback = FastAI.Models.tabular_embedding_backbone(embedszs, 0.2);</code></pre><p>We can then pass a named tuple <code>(categorical = ..., continuous = ...)</code> to <code>methodmodel</code> to replace the default backbone.</p><pre lang=julia ><code>backbone = (categorical = catback, continuous =  BatchNorm(length(cont)))
model = methodmodel(method, backbone)</code></pre><pre class=coderesult ><code>Chain(
  Parallel(
    vcat,
    Chain(
      FastAI.Models.var"#41#43"(),
      Parallel(
        vcat,
        Embedding(10, 10),              [90m# 100 parameters[39m
        Embedding(17, 12),              [90m# 204 parameters[39m
        Embedding(8, 5),                [90m# 40 parameters[39m
        Embedding(17, 8),               [90m# 136 parameters[39m
        Embedding(7, 5),                [90m# 35 parameters[39m
        Embedding(6, 4),                [90m# 24 parameters[39m
        Embedding(3, 3),                [90m# 9 parameters[39m
        Embedding(43, 16),              [90m# 688 parameters[39m
      ),
      Dropout(0.2),
    ),
    BatchNorm(6),                       [90m# 12 parameters[39m[90m, plus 12[39m
  ),
  Chain(
    Dense(69, 200, relu; bias=false),   [90m# 13_800 parameters[39m
    BatchNorm(200),                     [90m# 400 parameters[39m[90m, plus 400[39m
    identity,
  ),
  Chain(
    Dense(200, 100, relu; bias=false),  [90m# 20_000 parameters[39m
    BatchNorm(100),                     [90m# 200 parameters[39m[90m, plus 200[39m
    identity,
  ),
  Dense(100, 2),                        [90m# 202 parameters[39m
)[90m                   # Total: 18 arrays, [39m35_850 parameters, 138.828 KiB.</code></pre><p>To directly get a <code>Learner</code> suitable for our method and data, we can use the <code>methodlearner</code> function.</p><pre lang=julia ><code>learner = methodlearner(method, splitdata;
    backbone=backbone, callbacks=[Metrics(accuracy)],
    batchsize=128, buffered=false)</code></pre><pre class=coderesult ><code>Learner()</code></pre><p>Once we have our learner, we can just call <a href=../REFERENCE/FastAI.fitonecycle!.html ><code>fitonecycle!</code></a> on it to train it for the desired number of epochs.</p><pre lang=julia ><code>fitonecycle!(learner, 3, 0.2)</code></pre><pre class=codeoutput ><code><span class="sgr32">Epoch 1 TrainingPhase(): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:01:00</span>
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚<span class="sgr1">         Phase </span>â”‚<span class="sgr1"> Epoch </span>â”‚<span class="sgr1">    Loss </span>â”‚<span class="sgr1"> Accuracy </span>â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ TrainingPhase â”‚   1.0 â”‚ 0.37405 â”‚  0.82753 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
<span class="sgr32">Epoch 1 ValidationPhase(): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:02</span>
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚<span class="sgr1">           Phase </span>â”‚<span class="sgr1"> Epoch </span>â”‚<span class="sgr1">    Loss </span>â”‚<span class="sgr1"> Accuracy </span>â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ValidationPhase â”‚   1.0 â”‚ 0.39243 â”‚  0.81782 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
<span class="sgr32">Epoch 2 TrainingPhase(): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:04</span>
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚<span class="sgr1">         Phase </span>â”‚<span class="sgr1"> Epoch </span>â”‚<span class="sgr1">    Loss </span>â”‚<span class="sgr1"> Accuracy </span>â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ TrainingPhase â”‚   2.0 â”‚ 0.35332 â”‚  0.83909 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
<span class="sgr32">Epoch 2 ValidationPhase(): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:00</span>
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚<span class="sgr1">           Phase </span>â”‚<span class="sgr1"> Epoch </span>â”‚<span class="sgr1">    Loss </span>â”‚<span class="sgr1"> Accuracy </span>â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ValidationPhase â”‚   2.0 â”‚ 0.33674 â”‚  0.84259 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
<span class="sgr32">Epoch 3 TrainingPhase(): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:04</span>
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚<span class="sgr1">         Phase </span>â”‚<span class="sgr1"> Epoch </span>â”‚<span class="sgr1">    Loss </span>â”‚<span class="sgr1"> Accuracy </span>â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ TrainingPhase â”‚   3.0 â”‚ 0.32081 â”‚  0.85238 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
<span class="sgr32">Epoch 3 ValidationPhase(): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:00</span>
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚<span class="sgr1">           Phase </span>â”‚<span class="sgr1"> Epoch </span>â”‚<span class="sgr1">    Loss </span>â”‚<span class="sgr1"> Accuracy </span>â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ValidationPhase â”‚   3.0 â”‚ 0.31522 â”‚  0.85259 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre></article><footer class=book-footer ></footer></div><aside class=book-toc ><nav id=toc class=book-toc-content ><ul><li><a href=#tabular-classification >Tabular Classification</a><ul></ul></li></ul></nav></aside></main></body></HTML>