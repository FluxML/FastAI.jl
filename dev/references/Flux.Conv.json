{"attributes":{"kind":"struct","backlinks":[{"tag":"sourcefile","title":"FastVision/src/models/xresnet.jl","docid":"sourcefiles/FastVision/src/models/xresnet.jl"},{"tag":"sourcefile","title":"Flux/src/Flux.jl","docid":"sourcefiles/Flux/src/Flux.jl"},{"tag":"sourcefile","title":"Flux/src/layers/show.jl","docid":"sourcefiles/Flux/src/layers/show.jl"},{"tag":"sourcefile","title":"FastVision/src/models/blocks.jl","docid":"sourcefiles/FastVision/src/models/blocks.jl"},{"tag":"sourcefile","title":"Flux/src/layers/conv.jl","docid":"sourcefiles/Flux/src/layers/conv.jl"},{"tag":"sourcefile","title":"FastVision/src/models/layers.jl","docid":"sourcefiles/FastVision/src/models/layers.jl"}],"methods":[{"line":141,"file":"/home/runner/.julia/packages/Flux/js6mP/src/layers/conv.jl","method_id":"Flux.Conv_1","symbol_id":"Flux.Conv","filedoc":"sourcefiles/Flux/src/layers/conv.jl","signature":"Conv(k::Tuple{Vararg{Integer, N}}, ch::Pair{<:Integer, <:Integer})"},{"line":141,"file":"/home/runner/.julia/packages/Flux/js6mP/src/layers/conv.jl","method_id":"Flux.Conv_2","symbol_id":"Flux.Conv","filedoc":"sourcefiles/Flux/src/layers/conv.jl","signature":"Conv(k::Tuple{Vararg{Integer, N}}, ch::Pair{<:Integer, <:Integer}, σ; init, stride, pad, dilation, groups, bias)"},{"line":130,"file":"/home/runner/.julia/packages/Flux/js6mP/src/layers/conv.jl","method_id":"Flux.Conv_3","symbol_id":"Flux.Conv","filedoc":"sourcefiles/Flux/src/layers/conv.jl","signature":"Conv(w::AbstractArray{T, N})"},{"line":130,"file":"/home/runner/.julia/packages/Flux/js6mP/src/layers/conv.jl","method_id":"Flux.Conv_4","symbol_id":"Flux.Conv","filedoc":"sourcefiles/Flux/src/layers/conv.jl","signature":"Conv(w::AbstractArray{T, N}, b)"},{"line":130,"file":"/home/runner/.julia/packages/Flux/js6mP/src/layers/conv.jl","method_id":"Flux.Conv_5","symbol_id":"Flux.Conv","filedoc":"sourcefiles/Flux/src/layers/conv.jl","signature":"Conv(w::AbstractArray{T, N}, b, σ; stride, pad, dilation, groups)"},{"line":98,"file":"/home/runner/.julia/packages/Flux/js6mP/src/layers/conv.jl","method_id":"Flux.Conv_6","symbol_id":"Flux.Conv","filedoc":"sourcefiles/Flux/src/layers/conv.jl","signature":"Conv(σ::F, weight::A, bias::V, stride::Tuple{Vararg{Int64, N}}, pad::Tuple{Vararg{Int64, M}}, dilation::Tuple{Vararg{Int64, N}}, groups::Int64)"}],"name":"Conv","title":"Conv","symbol_id":"Flux.Conv","public":true,"module_id":"Flux"},"tag":"documentation","children":[{"attributes":{},"tag":"md","children":[{"attributes":{"lang":""},"tag":"codeblock","children":["Conv(filter, in => out, σ = identity;\n     stride = 1, pad = 0, dilation = 1, groups = 1, [bias, init])\n"],"type":"node"},{"attributes":{},"tag":"p","children":["Standard convolutional layer. ",{"attributes":{},"tag":"code","children":["filter"],"type":"node"}," is a tuple of integers specifying the size of the convolutional kernel; ",{"attributes":{},"tag":"code","children":["in"],"type":"node"}," and ",{"attributes":{},"tag":"code","children":["out"],"type":"node"}," specify the number of input and output channels."],"type":"node"},{"attributes":{},"tag":"p","children":["Image data should be stored in WHCN order (width, height, channels, batch). In other words, a 100×100 RGB image would be a ",{"attributes":{},"tag":"code","children":["100×100×3×1"],"type":"node"}," array, and a batch of 50 would be a ",{"attributes":{},"tag":"code","children":["100×100×3×50"],"type":"node"}," array. This has ",{"attributes":{},"tag":"code","children":["N = 2"],"type":"node"}," spatial dimensions, and needs a kernel size like ",{"attributes":{},"tag":"code","children":["(5,5)"],"type":"node"},", a 2-tuple of integers."],"type":"node"},{"attributes":{},"tag":"p","children":["To take convolutions along ",{"attributes":{},"tag":"code","children":["N"],"type":"node"}," feature dimensions, this layer expects as input an array with ",{"attributes":{},"tag":"code","children":["ndims(x) == N+2"],"type":"node"},", where ",{"attributes":{},"tag":"code","children":["size(x, N+1) == in"],"type":"node"}," is the number of input channels, and ",{"attributes":{},"tag":"code","children":["size(x, ndims(x))"],"type":"node"}," is (as always) the number of observations in a batch. Then:"],"type":"node"},{"attributes":{},"tag":"ul","children":[{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["filter"],"type":"node"}," should be a tuple of ",{"attributes":{},"tag":"code","children":["N"],"type":"node"}," integers."],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":["Keywords ",{"attributes":{},"tag":"code","children":["stride"],"type":"node"}," and ",{"attributes":{},"tag":"code","children":["dilation"],"type":"node"}," should each be either single integer, or a tuple with ",{"attributes":{},"tag":"code","children":["N"],"type":"node"}," integers."],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":["Keyword ",{"attributes":{},"tag":"code","children":["pad"],"type":"node"}," specifies the number of elements added to the borders of the data array. It can be"],"type":"node"},{"attributes":{},"tag":"ul","children":[{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":["a single integer for equal padding all around,"],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":["a tuple of ",{"attributes":{},"tag":"code","children":["N"],"type":"node"}," integers, to apply the same padding at begin/end of each spatial dimension,"],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":["a tuple of ",{"attributes":{},"tag":"code","children":["2*N"],"type":"node"}," integers, for asymmetric padding, or"],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":["the singleton ",{"attributes":{},"tag":"code","children":["SamePad()"],"type":"node"},", to calculate padding such that ",{"attributes":{},"tag":"code","children":["size(output,d) == size(x,d) / stride"],"type":"node"}," (possibly rounded) for each spatial dimension."],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":["Keyword ",{"attributes":{},"tag":"code","children":["groups"],"type":"node"}," is expected to be an ",{"attributes":{},"tag":"code","children":["Int"],"type":"node"},". It specifies the number of groups to divide a convolution into."],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"p","children":["Keywords to control initialization of the layer:"],"type":"node"},{"attributes":{},"tag":"ul","children":[{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["init"],"type":"node"}," - Function used to generate initial weights. Defaults to ",{"attributes":{},"tag":"code","children":["glorot_uniform"],"type":"node"},"."],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["bias"],"type":"node"}," - The initial bias vector is all zero by default. Trainable bias can be disabled entirely by setting this to ",{"attributes":{},"tag":"code","children":["false"],"type":"node"},", or another vector can be provided such as ",{"attributes":{},"tag":"code","children":["bias = randn(Float32, out)"],"type":"node"},"."],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"p","children":["See also ",{"attributes":{"reftype":"document","href":"@ref","title":"","document_id":"references/@ref"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["ConvTranspose"],"type":"node"}],"type":"node"},", ",{"attributes":{"reftype":"document","href":"@ref","title":"","document_id":"references/@ref"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["DepthwiseConv"],"type":"node"}],"type":"node"},", ",{"attributes":{"reftype":"document","href":"@ref","title":"","document_id":"references/@ref"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["CrossCor"],"type":"node"}],"type":"node"},"."],"type":"node"},{"attributes":{},"tag":"h1","children":["Examples"],"type":"node"},{"attributes":{"lang":"jldoctest"},"tag":"codeblock","children":["julia> xs = rand(Float32, 100, 100, 3, 50); # a batch of images\n\njulia> layer = Conv((5,5), 3 => 7, relu; bias = false)\nConv((5, 5), 3 => 7, relu, bias=false)  # 525 parameters\n\njulia> layer(xs) |> size\n(96, 96, 7, 50)\n\njulia> Conv((5,5), 3 => 7; stride = 2)(xs) |> size\n(48, 48, 7, 50)\n\njulia> Conv((5,5), 3 => 7; stride = 2, pad = SamePad())(xs) |> size\n(50, 50, 7, 50)\n\njulia> Conv((1,1), 3 => 7; pad = (20,10,0,0))(xs) |> size\n(130, 100, 7, 50)\n\njulia> Conv((5,5), 3 => 7; stride = 2, dilation = 4)(xs) |> size\n(42, 42, 7, 50)\n"],"type":"node"},{"attributes":{},"tag":"hr","children":[],"type":"node"},{"attributes":{"lang":""},"tag":"codeblock","children":["Conv(weight::AbstractArray, [bias, activation; stride, pad, dilation])\n"],"type":"node"},{"attributes":{},"tag":"p","children":["Constructs a convolutional layer with the given weight and bias. Accepts the same keywords (and has the same defaults) as the ",{"attributes":{},"tag":"code","children":["Conv((4,4), 3 => 7, relu)"],"type":"node"}," method."],"type":"node"},{"attributes":{},"tag":"h1","children":["Examples"],"type":"node"},{"attributes":{"lang":"jldoctest"},"tag":"codeblock","children":["julia> weight = rand(3, 4, 5);\n\njulia> bias = zeros(5);\n\njulia> c1 = Conv(weight, bias, sigmoid)  # expects 1 spatial dimension\nConv((3,), 4 => 5, σ)  # 65 parameters\n\njulia> c1(randn(100, 4, 64)) |> size\n(98, 5, 64)\n\njulia> Flux.params(c1) |> length\n2\n"],"type":"node"}],"type":"node"}],"type":"node"}