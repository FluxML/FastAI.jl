{"attributes":{"kind":"function","backlinks":[{"tag":"documentation","title":"Metric","docid":"references/FluxTraining.Metric"},{"tag":"document","title":"Saving and loading models for inference","docid":"documents/docs/notebooks/serialization.ipynb"},{"tag":"sourcefile","title":"FluxTraining/src/callbacks/callbacks.jl","docid":"sourcefiles/FluxTraining/src/callbacks/callbacks.jl"},{"tag":"sourcefile","title":"Flux/src/functor.jl","docid":"sourcefiles/Flux/src/functor.jl"},{"tag":"sourcefile","title":"Flux/src/Flux.jl","docid":"sourcefiles/Flux/src/Flux.jl"},{"tag":"documentation","title":"Metrics","docid":"references/FluxTraining.Metrics"},{"tag":"sourcefile","title":"Flux/src/onehot.jl","docid":"sourcefiles/Flux/src/onehot.jl"},{"tag":"document","title":"Siamese image similarity","docid":"documents/docs/notebooks/siamese.ipynb"},{"tag":"document","title":"How to visualize data","docid":"documents/docs/notebooks/how_to_visualize.ipynb"},{"tag":"document","title":"Performant data pipelines","docid":"documents/docs/background/datapipelines.md"},{"tag":"sourcefile","title":"FluxTraining/src/callbacks/sanitycheck.jl","docid":"sourcefiles/FluxTraining/src/callbacks/sanitycheck.jl"},{"tag":"sourcefile","title":"FastAI/src/FastAI.jl","docid":"sourcefiles/FastAI/src/FastAI.jl"},{"tag":"document","title":"Variational autoencoders","docid":"documents/docs/notebooks/vae.ipynb"}],"methods":[{"line":180,"file":"/home/runner/.julia/packages/Flux/js6mP/src/functor.jl","method_id":"Flux.gpu_1","symbol_id":"Flux.gpu","filedoc":"sourcefiles/Flux/src/functor.jl","signature":"gpu(x)"}],"name":"gpu","title":"gpu","symbol_id":"Flux.gpu","public":true,"module_id":"Flux"},"tag":"documentation","children":[{"attributes":{},"tag":"md","children":[{"attributes":{"lang":""},"tag":"codeblock","children":["gpu(x)\n"],"type":"node"},{"attributes":{},"tag":"p","children":["Moves ",{"attributes":{},"tag":"code","children":["m"],"type":"node"}," to the current GPU device, if available. It is a no-op otherwise. See the ",{"attributes":{"href":"https://juliagpu.github.io/CUDA.jl/stable/usage/multigpu/","title":""},"tag":"a","children":["CUDA.jl docs"],"type":"node"}," to help identify the current device."],"type":"node"},{"attributes":{},"tag":"p","children":["This works for functions, and any struct marked with ",{"attributes":{"reftype":"document","href":"@ref","title":"","document_id":"references/@ref"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["@functor"],"type":"node"}],"type":"node"},"."],"type":"node"},{"attributes":{"lang":"julia-repl"},"tag":"codeblock","children":["julia> m = Dense(1,2)\nDense(1, 2)\n\njulia> typeof(m.W)\nMatrix{Float32}\n\njulia> m_gpu = gpu(m)\nDense(1, 2)\n\njulia> typeof(m_gpu.W) # notice the type of the array changed to a CuArray\nCuArray{Float32, 2}\n"],"type":"node"}],"type":"node"}],"type":"node"}