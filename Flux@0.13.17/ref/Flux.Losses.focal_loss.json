{"attributes":{"kind":"function","backlinks":[{"tag":"documentation","title":"binary_focal_loss","docid":"Flux@0.13.17/ref/Flux.Losses.binary_focal_loss"},{"tag":"sourcefile","title":"Flux/losses/Losses.jl","docid":"Flux@0.13.17/src/losses/Losses.jl"},{"tag":"sourcefile","title":"Flux/losses/functions.jl","docid":"Flux@0.13.17/src/losses/functions.jl"}],"methods":[{"symbol_id":"Flux.Losses.focal_loss","module_id":"Flux.Losses","file":"losses/functions.jl","line":614,"signature":"(::Signature)"}],"package_id":"Flux@0.13.17","title":"focal_loss","symbol_id":"Flux.Losses.focal_loss","exported":true,"module_id":"Flux.Losses"},"tag":"documentation","children":[{"attributes":{"symbol":"Flux.Losses.focal_loss","line":580,"module":"Flux.Losses","file":"losses/functions.jl"},"tag":"docstring","children":[{"attributes":{},"tag":"md","children":[{"attributes":{"lang":""},"tag":"codeblock","children":["focal_loss(ŷ, y; dims=1, agg=mean, gamma=2, eps=eps(eltype(ŷ)))\n"],"type":"node"},{"attributes":{},"tag":"p","children":["Return the ",{"attributes":{"href":"https://arxiv.org/pdf/1708.02002.pdf","title":""},"tag":"a","children":["focal_loss"],"type":"node"}," which can be used in classification tasks with highly imbalanced classes. It down-weights well-classified examples and focuses on hard examples. The input, 'ŷ', is expected to be normalized (i.e. [softmax](",{"attributes":{"id":"ref"},"tag":"citation","children":[],"type":"node"}," Softmax) output)."],"type":"node"},{"attributes":{},"tag":"p","children":["The modulating factor, ",{"attributes":{},"tag":"code","children":["γ == gamma"],"type":"node"},", controls the down-weighting strength. For ",{"attributes":{},"tag":"code","children":["γ == 0"],"type":"node"},", the loss is mathematically equivalent to ",{"attributes":{"reftype":"symbol","href":"@ref","title":"","document_id":"Flux@0.13.17/ref/Flux.Losses.crossentropy"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["Losses.crossentropy"],"type":"node"}],"type":"node"},"."],"type":"node"},{"attributes":{},"tag":"h1","children":["Example"],"type":"node"},{"attributes":{"lang":"jldoctest"},"tag":"codeblock","children":["julia> y = [1  0  0  0  1\n            0  1  0  1  0\n            0  0  1  0  0]\n3×5 Matrix{Int64}:\n 1  0  0  0  1\n 0  1  0  1  0\n 0  0  1  0  0\n\njulia> ŷ = softmax(reshape(-7:7, 3, 5) .* 1f0)\n3×5 Matrix{Float32}:\n 0.0900306  0.0900306  0.0900306  0.0900306  0.0900306\n 0.244728   0.244728   0.244728   0.244728   0.244728\n 0.665241   0.665241   0.665241   0.665241   0.665241\n\njulia> Flux.focal_loss(ŷ, y) ≈ 1.1277571935622628\ntrue\n"],"type":"node"},{"attributes":{},"tag":"p","children":["See also: ",{"attributes":{"reftype":"symbol","href":"@ref","title":"","document_id":"Flux@0.13.17/ref/Flux.Losses.binary_focal_loss"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["Losses.binary_focal_loss"],"type":"node"}],"type":"node"}," for binary (not one-hot) labels"],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"}