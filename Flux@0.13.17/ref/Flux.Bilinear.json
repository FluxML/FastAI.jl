{"attributes":{"kind":"struct","backlinks":[{"tag":"sourcefile","title":"Flux/deprecations.jl","docid":"Flux@0.13.17/src/deprecations.jl"},{"tag":"sourcefile","title":"Flux/layers/show.jl","docid":"Flux@0.13.17/src/layers/show.jl"},{"tag":"sourcefile","title":"Flux/layers/basic.jl","docid":"Flux@0.13.17/src/layers/basic.jl"}],"methods":[{"symbol_id":"Flux.Bilinear","module_id":"Flux","file":"deprecations.jl","line":65,"signature":"(::Signature)"},{"symbol_id":"Flux.Bilinear","module_id":"Flux","file":"layers/basic.jl","line":432,"signature":"(::Signature)"},{"symbol_id":"Flux.Bilinear","module_id":"Flux","file":"layers/basic.jl","line":428,"signature":"(::Signature)"},{"symbol_id":"Flux.Bilinear","module_id":"Flux","file":"layers/basic.jl","line":419,"signature":"(::Signature)"}],"package_id":"Flux@0.13.17","title":"Bilinear","symbol_id":"Flux.Bilinear","exported":false,"module_id":"Flux"},"tag":"documentation","children":[{"attributes":{"symbol":"Flux.Bilinear","line":366,"module":"Flux","file":"layers/basic.jl"},"tag":"docstring","children":[{"attributes":{},"tag":"md","children":[{"attributes":{"lang":""},"tag":"codeblock","children":["Bilinear((in1, in2) => out, σ=identity; bias=true, init=glorot_uniform)\nBilinear(W::AbstractArray, [bias, σ])\n"],"type":"node"},{"attributes":{},"tag":"p","children":["Creates a layer which is fully connected between two inputs and the output, and otherwise similar to ",{"attributes":{"reftype":"symbol","href":"@ref","title":"","document_id":"Flux@0.13.17/ref/Flux.Dense"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["Dense"],"type":"node"}],"type":"node"},". Its output, given vectors ",{"attributes":{},"tag":"code","children":["x"],"type":"node"}," & ",{"attributes":{},"tag":"code","children":["y"],"type":"node"},", is another vector ",{"attributes":{},"tag":"code","children":["z"],"type":"node"}," with, for all ",{"attributes":{},"tag":"code","children":["i ∈ 1:out"],"type":"node"},":"],"type":"node"},{"attributes":{"lang":""},"tag":"codeblock","children":["z[i] = σ(x' * W[i,:,:] * y + bias[i])\n"],"type":"node"},{"attributes":{},"tag":"p","children":["If ",{"attributes":{},"tag":"code","children":["x"],"type":"node"}," and ",{"attributes":{},"tag":"code","children":["y"],"type":"node"}," are matrices, then each column of the output ",{"attributes":{},"tag":"code","children":["z = B(x, y)"],"type":"node"}," is of this form, with ",{"attributes":{},"tag":"code","children":["B"],"type":"node"}," the Bilinear layer."],"type":"node"},{"attributes":{},"tag":"p","children":["If the second input ",{"attributes":{},"tag":"code","children":["y"],"type":"node"}," is not given, it is taken to be equal to ",{"attributes":{},"tag":"code","children":["x"],"type":"node"},", i.e. ",{"attributes":{},"tag":"code","children":["B(x) == B(x, x)"],"type":"node"}],"type":"node"},{"attributes":{},"tag":"p","children":["The two inputs may also be provided as a tuple, ",{"attributes":{},"tag":"code","children":["B((x, y)) == B(x, y)"],"type":"node"},", which is accepted as the input to a ",{"attributes":{},"tag":"code","children":["Chain"],"type":"node"},"."],"type":"node"},{"attributes":{},"tag":"p","children":["If the two input sizes are the same, ",{"attributes":{},"tag":"code","children":["in1 == in2"],"type":"node"},", then you may write ",{"attributes":{},"tag":"code","children":["Bilinear(in => out, σ)"],"type":"node"},"."],"type":"node"},{"attributes":{},"tag":"p","children":["The initialisation works as for ",{"attributes":{"reftype":"symbol","href":"@ref","title":"","document_id":"Flux@0.13.17/ref/Flux.Dense"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["Dense"],"type":"node"}],"type":"node"}," layer, with ",{"attributes":{},"tag":"code","children":["W = init(out, in1, in2)"],"type":"node"},". By default the bias vector is ",{"attributes":{},"tag":"code","children":["zeros(Float32, out)"],"type":"node"},", option ",{"attributes":{},"tag":"code","children":["bias=false"],"type":"node"}," will switch off trainable bias. Either of these may be provided explicitly."],"type":"node"},{"attributes":{},"tag":"h1","children":["Examples"],"type":"node"},{"attributes":{"lang":"jldoctest"},"tag":"codeblock","children":["julia> x, y = randn(Float32, 5, 32), randn(Float32, 5, 32);\n\njulia> B = Flux.Bilinear((5, 5) => 7)\nBilinear(5 => 7)    # 182 parameters\n\njulia> B(x) |> size  # interactions based on one input\n(7, 32)\n\njulia> B(x,y) == B((x,y))  # two inputs, may be given as a tuple\ntrue\n\njulia> sc = SkipConnection(\n                Chain(Dense(5 => 20, tanh), Dense(20 => 9, tanh)),\n                Flux.Bilinear((9, 5) => 3, bias=false),\n            );  # used as the recombinator, with skip as the second input\n\njulia> sc(x) |> size\n(3, 32)\n\njulia> Flux.Bilinear(rand(4,8,16), false, tanh)  # first dim of weight is the output\nBilinear((8, 16) => 4, tanh; bias=false)  # 512 parameters\n"],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"}