{"attributes":{"kind":"function","backlinks":[{"tag":"documentation","title":"Metrics","docid":"FluxTraining@0.3.4/ref/FluxTraining.Metrics"},{"tag":"documentation","title":"Metric","docid":"FluxTraining@0.3.4/ref/FluxTraining.Metric"},{"tag":"document","title":"Saving and loading models for inference","docid":"FastAI@dev/doc/docs/notebooks/serialization.ipynb"},{"tag":"documentation","title":"cpu","docid":"Flux@0.13.7/ref/Flux.cpu"},{"tag":"sourcefile","title":"Flux/functor.jl","docid":"Flux@0.13.7/src/functor.jl"},{"tag":"sourcefile","title":"FastAI/FastAI.jl","docid":"FastAI@dev/src/FastAI.jl"},{"tag":"sourcefile","title":"FluxTraining/callbacks/sanitycheck.jl","docid":"FluxTraining@0.3.4/src/callbacks/sanitycheck.jl"},{"tag":"sourcefile","title":"Flux/Flux.jl","docid":"Flux@0.13.7/src/Flux.jl"},{"tag":"document","title":"How to visualize data","docid":"FastAI@dev/doc/docs/notebooks/how_to_visualize.ipynb"},{"tag":"sourcefile","title":"FluxTraining/callbacks/callbacks.jl","docid":"FluxTraining@0.3.4/src/callbacks/callbacks.jl"},{"tag":"document","title":"Siamese image similarity","docid":"FastAI@dev/doc/docs/notebooks/siamese.ipynb"},{"tag":"document","title":"Performant data pipelines","docid":"FastAI@dev/doc/docs/background/datapipelines.md"},{"tag":"document","title":"Variational autoencoders","docid":"FastAI@dev/doc/docs/notebooks/vae.ipynb"}],"methods":[{"symbol_id":"Flux.gpu","module_id":"Flux","file":"functor.jl","line":186,"signature":"(::Signature)"}],"package_id":"Flux@0.13.7","title":"gpu","symbol_id":"Flux.gpu","exported":true,"module_id":"Flux"},"tag":"documentation","children":[{"attributes":{"symbol":"Flux.gpu","line":163,"module":"Flux","file":"functor.jl"},"tag":"docstring","children":[{"attributes":{},"tag":"md","children":[{"attributes":{"lang":""},"tag":"codeblock","children":["gpu(x)\n"],"type":"node"},{"attributes":{},"tag":"p","children":["Moves ",{"attributes":{},"tag":"code","children":["m"],"type":"node"}," to the current GPU device, if available. It is a no-op otherwise. See the ",{"attributes":{"href":"https://juliagpu.github.io/CUDA.jl/stable/usage/multigpu/","title":""},"tag":"a","children":["CUDA.jl docs"],"type":"node"}," to help identify the current device."],"type":"node"},{"attributes":{},"tag":"p","children":["This works for functions, and any struct marked with ",{"attributes":{"href":"@ref","title":""},"tag":"a","children":[{"attributes":{},"tag":"code","children":["@functor"],"type":"node"}],"type":"node"},"."],"type":"node"},{"attributes":{"lang":"julia-repl"},"tag":"codeblock","children":["julia> m = Dense(1,2)\nDense(1, 2)\n\njulia> typeof(m.W)\nMatrix{Float32}\n\njulia> m_gpu = gpu(m)\nDense(1, 2)\n\njulia> typeof(m_gpu.W) # notice the type of the array changed to a CuArray\nCuArray{Float32, 2}\n"],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"}