{"attributes":{"kind":"function","backlinks":[{"tag":"sourcefile","title":"Flux/utils.jl","docid":"Flux@0.13.7/src/utils.jl"}],"methods":[{"symbol_id":"Flux.modules","module_id":"Flux","file":"utils.jl","line":629,"signature":"(::Signature)"}],"package_id":"Flux@0.13.7","title":"modules","symbol_id":"Flux.modules","exported":false,"module_id":"Flux"},"tag":"documentation","children":[{"attributes":{"symbol":"Flux.modules","line":586,"module":"Flux","file":"utils.jl"},"tag":"docstring","children":[{"attributes":{},"tag":"md","children":[{"attributes":{"lang":""},"tag":"codeblock","children":["modules(m)\n"],"type":"node"},{"attributes":{},"tag":"p","children":["Return an iterator over non-leaf objects that can be reached by recursing ",{"attributes":{},"tag":"code","children":["m"],"type":"node"}," over the children given by ",{"attributes":{"href":"@ref","title":""},"tag":"a","children":[{"attributes":{},"tag":"code","children":["functor"],"type":"node"}],"type":"node"},"."],"type":"node"},{"attributes":{},"tag":"p","children":["Useful for applying a function (e.g. a regularizer) over specific modules or subsets of the parameters (e.g. the weights but not the biases)."],"type":"node"},{"attributes":{},"tag":"h1","children":["Examples"],"type":"node"},{"attributes":{"lang":"jldoctest"},"tag":"codeblock","children":["julia> m1 = Chain(Dense(28^2, 64), BatchNorm(64, relu));\n\njulia> m2 = Chain(m1, Dense(64, 10))\nChain(\n  Chain(\n    Dense(784 => 64),                   # 50_240 parameters\n    BatchNorm(64, relu),                # 128 parameters, plus 128\n  ),\n  Dense(64 => 10),                      # 650 parameters\n)         # Total: 6 trainable arrays, 51_018 parameters,\n          # plus 2 non-trainable, 128 parameters, summarysize 200.312 KiB.\n\njulia> Flux.modules(m2)\n7-element Vector{Any}:\n Chain(Chain(Dense(784 => 64), BatchNorm(64, relu)), Dense(64 => 10))  # 51_018 parameters, plus 128 non-trainable\n (Chain(Dense(784 => 64), BatchNorm(64, relu)), Dense(64 => 10))\n Chain(Dense(784 => 64), BatchNorm(64, relu))  # 50_368 parameters, plus 128 non-trainable\n (Dense(784 => 64), BatchNorm(64, relu))\n Dense(784 => 64)    # 50_240 parameters\n BatchNorm(64, relu)  # 128 parameters, plus 128 non-trainable\n Dense(64 => 10)     # 650 parameters\n\njulia> L2(m) = sum(sum(abs2, l.weight) for l in Flux.modules(m) if l isa Dense)\nL2 (generic function with 1 method)\n\njulia> L2(m2) isa Float32\ntrue\n"],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"}