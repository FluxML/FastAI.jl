{"attributes":{"kind":"struct","backlinks":[{"tag":"sourcefile","title":"Flux/src/optimise/optimisers.jl","docid":"sourcefiles/Flux/src/optimise/optimisers.jl"},{"tag":"sourcefile","title":"Flux/src/Flux.jl","docid":"sourcefiles/Flux/src/Flux.jl"},{"tag":"sourcefile","title":"Flux/src/optimise/Optimise.jl","docid":"sourcefiles/Flux/src/optimise/Optimise.jl"}],"methods":[{"line":660,"file":"/home/runner/.julia/packages/Flux/js6mP/src/optimise/optimisers.jl","method_id":"Flux.Optimise.ExpDecay_1","symbol_id":"Flux.Optimise.ExpDecay","filedoc":"sourcefiles/Flux/src/optimise/optimisers.jl","signature":"ExpDecay()"},{"line":652,"file":"/home/runner/.julia/packages/Flux/js6mP/src/optimise/optimisers.jl","method_id":"Flux.Optimise.ExpDecay_2","symbol_id":"Flux.Optimise.ExpDecay","filedoc":"sourcefiles/Flux/src/optimise/optimisers.jl","signature":"ExpDecay(eta::Float64, decay::Float64, step::Int64, clip::Float64, start::Int64, current::IdDict)"},{"line":660,"file":"/home/runner/.julia/packages/Flux/js6mP/src/optimise/optimisers.jl","method_id":"Flux.Optimise.ExpDecay_3","symbol_id":"Flux.Optimise.ExpDecay","filedoc":"sourcefiles/Flux/src/optimise/optimisers.jl","signature":"ExpDecay(opt)"},{"line":660,"file":"/home/runner/.julia/packages/Flux/js6mP/src/optimise/optimisers.jl","method_id":"Flux.Optimise.ExpDecay_4","symbol_id":"Flux.Optimise.ExpDecay","filedoc":"sourcefiles/Flux/src/optimise/optimisers.jl","signature":"ExpDecay(opt, decay)"},{"line":660,"file":"/home/runner/.julia/packages/Flux/js6mP/src/optimise/optimisers.jl","method_id":"Flux.Optimise.ExpDecay_5","symbol_id":"Flux.Optimise.ExpDecay","filedoc":"sourcefiles/Flux/src/optimise/optimisers.jl","signature":"ExpDecay(opt, decay, decay_step)"},{"line":660,"file":"/home/runner/.julia/packages/Flux/js6mP/src/optimise/optimisers.jl","method_id":"Flux.Optimise.ExpDecay_6","symbol_id":"Flux.Optimise.ExpDecay","filedoc":"sourcefiles/Flux/src/optimise/optimisers.jl","signature":"ExpDecay(opt, decay, decay_step, clip)"},{"line":660,"file":"/home/runner/.julia/packages/Flux/js6mP/src/optimise/optimisers.jl","method_id":"Flux.Optimise.ExpDecay_7","symbol_id":"Flux.Optimise.ExpDecay","filedoc":"sourcefiles/Flux/src/optimise/optimisers.jl","signature":"ExpDecay(opt, decay, decay_step, clip, start)"},{"line":652,"file":"/home/runner/.julia/packages/Flux/js6mP/src/optimise/optimisers.jl","method_id":"Flux.Optimise.ExpDecay_8","symbol_id":"Flux.Optimise.ExpDecay","filedoc":"sourcefiles/Flux/src/optimise/optimisers.jl","signature":"ExpDecay(eta, decay, step, clip, start, current)"}],"name":"ExpDecay","title":"ExpDecay","symbol_id":"Flux.Optimise.ExpDecay","public":true,"module_id":"Flux.Optimise"},"tag":"documentation","children":[{"attributes":{},"tag":"md","children":[{"attributes":{"lang":""},"tag":"codeblock","children":["ExpDecay(η = 0.001, decay = 0.1, decay_step = 1000, clip = 1e-4, start = 1)\n"],"type":"node"},{"attributes":{},"tag":"p","children":["Discount the learning rate ",{"attributes":{},"tag":"code","children":["η"],"type":"node"}," by the factor ",{"attributes":{},"tag":"code","children":["decay"],"type":"node"}," every ",{"attributes":{},"tag":"code","children":["decay_step"],"type":"node"}," steps till a minimum of ",{"attributes":{},"tag":"code","children":["clip"],"type":"node"},"."],"type":"node"},{"attributes":{},"tag":"h1","children":["Parameters"],"type":"node"},{"attributes":{},"tag":"ul","children":[{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":["Learning rate (",{"attributes":{},"tag":"code","children":["η"],"type":"node"},"): Amount by which gradients are discounted before updating the weights."],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["decay"],"type":"node"},": Factor by which the learning rate is discounted."],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["decay_step"],"type":"node"},": Schedule decay operations by setting the number of steps between two decay operations."],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["clip"],"type":"node"},": Minimum value of learning rate."],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":["'start': Step at which the decay starts."],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"p","children":["See also the ",{"attributes":{"reftype":"document","href":"@ref","title":"","document_id":"references/@ref"},"tag":"reference","children":["Scheduling Optimisers"],"type":"node"}," section of the docs for more general scheduling techniques."],"type":"node"},{"attributes":{},"tag":"h1","children":["Examples"],"type":"node"},{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["ExpDecay"],"type":"node"}," is typically composed  with other optimizers as the last transformation of the gradient:"],"type":"node"},{"attributes":{"lang":"julia"},"tag":"codeblock","children":[{"attributes":{},"tag":"julia","children":[{"attributes":{},"tag":"EQ","children":[{"attributes":{},"tag":"IDENTIFIER","children":["opt"],"type":"node"},{"attributes":{},"tag":"WHITESPACE","children":[" "],"type":"node"},{"attributes":{},"tag":"EQ","children":["="],"type":"node"},{"attributes":{},"tag":"WHITESPACE","children":[" "],"type":"node"},{"attributes":{},"tag":"CALL","children":[{"attributes":{"reftype":"symbol","document_id":"references/Flux.Optimise.Optimiser"},"tag":"reference","children":["Optimiser"],"type":"node"},{"attributes":{},"tag":"LPAREN","children":["("],"type":"node"},{"attributes":{},"tag":"CALL","children":[{"attributes":{"reftype":"symbol","document_id":"references/Flux.Optimise.ADAM"},"tag":"reference","children":["ADAM"],"type":"node"},{"attributes":{},"tag":"LPAREN","children":["("],"type":"node"},{"attributes":{},"tag":"RPAREN","children":[")"],"type":"node"}],"type":"node"},{"attributes":{},"tag":"COMMA","children":[","],"type":"node"},{"attributes":{},"tag":"WHITESPACE","children":[" "],"type":"node"},{"attributes":{},"tag":"CALL","children":[{"attributes":{"reftype":"symbol","document_id":"references/Flux.Optimise.ExpDecay"},"tag":"reference","children":["ExpDecay"],"type":"node"},{"attributes":{},"tag":"LPAREN","children":["("],"type":"node"},{"attributes":{},"tag":"FLOAT","children":["1.0"],"type":"node"},{"attributes":{},"tag":"RPAREN","children":[")"],"type":"node"}],"type":"node"},{"attributes":{},"tag":"RPAREN","children":[")"],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"p","children":["Note: you may want to start with ",{"attributes":{},"tag":"code","children":["η=1"],"type":"node"}," in ",{"attributes":{},"tag":"code","children":["ExpDecay"],"type":"node"}," when combined with other optimizers (",{"attributes":{},"tag":"code","children":["ADAM"],"type":"node"}," in this case) that have their own learning rate."],"type":"node"}],"type":"node"}],"type":"node"}