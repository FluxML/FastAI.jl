{"attributes":{"kind":"struct","backlinks":[{"tag":"sourcefile","title":"Flux/src/layers/normalise.jl","docid":"sourcefiles/Flux/src/layers/normalise.jl"},{"tag":"sourcefile","title":"Flux/src/Flux.jl","docid":"sourcefiles/Flux/src/Flux.jl"}],"methods":[{"line":119,"file":"/home/runner/.julia/packages/Flux/js6mP/src/layers/normalise.jl","method_id":"Flux.AlphaDropout_1","symbol_id":"Flux.AlphaDropout","filedoc":"sourcefiles/Flux/src/layers/normalise.jl","signature":"AlphaDropout(p; rng)"},{"line":118,"file":"/home/runner/.julia/packages/Flux/js6mP/src/layers/normalise.jl","method_id":"Flux.AlphaDropout_2","symbol_id":"Flux.AlphaDropout","filedoc":"sourcefiles/Flux/src/layers/normalise.jl","signature":"AlphaDropout(p, active)"},{"line":113,"file":"/home/runner/.julia/packages/Flux/js6mP/src/layers/normalise.jl","method_id":"Flux.AlphaDropout_3","symbol_id":"Flux.AlphaDropout","filedoc":"sourcefiles/Flux/src/layers/normalise.jl","signature":"AlphaDropout(p, active, rng)"}],"name":"AlphaDropout","title":"AlphaDropout","symbol_id":"Flux.AlphaDropout","public":true,"module_id":"Flux"},"tag":"documentation","children":[{"attributes":{},"tag":"md","children":[{"attributes":{"lang":""},"tag":"codeblock","children":["AlphaDropout(p; rng = rng_from_array())\n"],"type":"node"},{"attributes":{},"tag":"p","children":["A dropout layer. Used in ",{"attributes":{"href":"https://arxiv.org/abs/1706.02515","title":""},"tag":"a","children":["Self-Normalizing Neural Networks"],"type":"node"},". The AlphaDropout layer ensures that mean and variance of activations remain the same as before."],"type":"node"},{"attributes":{},"tag":"p","children":["Does nothing to the input once ",{"attributes":{"reftype":"document","href":"@ref","title":"","document_id":"references/@ref"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["testmode!"],"type":"node"}],"type":"node"}," is true."],"type":"node"}],"type":"node"}],"type":"node"}