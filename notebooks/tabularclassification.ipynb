{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Tabular Classification"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tabular Classification involves having a categorical column as the target. Here, we'll use the adult sample dataset from fastai and try to predict whether the salary is above 50K or not, making this a binary classification task. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "using Flux\n",
    "using FastAI\n",
    "using FastAI.Datasets\n",
    "using Tables\n",
    "using Statistics\n",
    "using FluxTraining\n",
    "using DataAugmentation"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can quickly download and get the path of any dataset from fastai by using `datasetpath`. Once we have the path, we'll load the data in a `TableContainer`. By default if we pass in just the path to `TableContainer`, the data is loaded in a `DataFrame`, but we can use any package for accessing our data, and pass an object satisfying Tables.jl interface to it."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "path = datasetpath(\"adult_sample\") \n",
    "data = Datasets.TableDataset(joinpath(path, \"adult.csv\"))\n",
    "df = data.table"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\u001b[1m32561×15 DataFrame\u001b[0m\n",
       "\u001b[1m   Row \u001b[0m│\u001b[1m age   \u001b[0m\u001b[1m workclass         \u001b[0m\u001b[1m fnlwgt \u001b[0m\u001b[1m education     \u001b[0m\u001b[1m education-num \u001b[0m\u001b[1m marit\u001b[0m ⋯\n",
       "\u001b[1m       \u001b[0m│\u001b[90m Int64 \u001b[0m\u001b[90m String            \u001b[0m\u001b[90m Int64  \u001b[0m\u001b[90m String        \u001b[0m\u001b[90m Float64?      \u001b[0m\u001b[90m Strin\u001b[0m ⋯\n",
       "───────┼────────────────────────────────────────────────────────────────────────\n",
       "     1 │    49   Private           101320   Assoc-acdm             12.0   Marr ⋯\n",
       "     2 │    44   Private           236746   Masters                14.0   Divo\n",
       "     3 │    38   Private            96185   HS-grad      \u001b[90m     missing   \u001b[0m  Divo\n",
       "     4 │    38   Self-emp-inc      112847   Prof-school            15.0   Marr\n",
       "     5 │    42   Self-emp-not-inc   82297   7th-8th      \u001b[90m     missing   \u001b[0m  Marr ⋯\n",
       "     6 │    20   Private            63210   HS-grad                 9.0   Neve\n",
       "     7 │    49   Private            44434   Some-college           10.0   Divo\n",
       "     8 │    37   Private           138940   11th                    7.0   Marr\n",
       "     9 │    46   Private           328216   HS-grad                 9.0   Marr ⋯\n",
       "    10 │    36   Self-emp-inc      216711   HS-grad      \u001b[90m     missing   \u001b[0m  Marr\n",
       "    11 │    23   Private           529223   Bachelors              13.0   Neve\n",
       "   ⋮   │   ⋮            ⋮            ⋮           ⋮              ⋮              ⋱\n",
       " 32552 │    60   Private           230545   7th-8th                 4.0   Divo\n",
       " 32553 │    39   Private           139743   HS-grad                 9.0   Sepa ⋯\n",
       " 32554 │    35   Self-emp-inc      135436   Prof-school            15.0   Marr\n",
       " 32555 │    53   Private            35102   Some-college           10.0   Divo\n",
       " 32556 │    48   Private           355320   Bachelors              13.0   Marr\n",
       " 32557 │    36   Private           297449   Bachelors              13.0   Divo ⋯\n",
       " 32558 │    23   ?                 123983   Bachelors              13.0   Neve\n",
       " 32559 │    53   Private           157069   Assoc-acdm             12.0   Marr\n",
       " 32560 │    32   Local-gov         217296   HS-grad                 9.0   Marr\n",
       " 32561 │    26   Private           182308   Some-college           10.0   Marr ⋯\n",
       "\u001b[36m                                               10 columns and 32540 rows omitted\u001b[0m"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& age & workclass & fnlwgt & education & education-num & marital-status & \\\\\n",
       "\t\\hline\n",
       "\t& Int64 & String & Int64 & String & Float64? & String & \\\\\n",
       "\t\\hline\n",
       "\t1 & 49 &  Private & 101320 &  Assoc-acdm & 12.0 &  Married-civ-spouse & $\\dots$ \\\\\n",
       "\t2 & 44 &  Private & 236746 &  Masters & 14.0 &  Divorced & $\\dots$ \\\\\n",
       "\t3 & 38 &  Private & 96185 &  HS-grad & \\emph{missing} &  Divorced & $\\dots$ \\\\\n",
       "\t4 & 38 &  Self-emp-inc & 112847 &  Prof-school & 15.0 &  Married-civ-spouse & $\\dots$ \\\\\n",
       "\t5 & 42 &  Self-emp-not-inc & 82297 &  7th-8th & \\emph{missing} &  Married-civ-spouse & $\\dots$ \\\\\n",
       "\t6 & 20 &  Private & 63210 &  HS-grad & 9.0 &  Never-married & $\\dots$ \\\\\n",
       "\t7 & 49 &  Private & 44434 &  Some-college & 10.0 &  Divorced & $\\dots$ \\\\\n",
       "\t8 & 37 &  Private & 138940 &  11th & 7.0 &  Married-civ-spouse & $\\dots$ \\\\\n",
       "\t9 & 46 &  Private & 328216 &  HS-grad & 9.0 &  Married-civ-spouse & $\\dots$ \\\\\n",
       "\t10 & 36 &  Self-emp-inc & 216711 &  HS-grad & \\emph{missing} &  Married-civ-spouse & $\\dots$ \\\\\n",
       "\t11 & 23 &  Private & 529223 &  Bachelors & 13.0 &  Never-married & $\\dots$ \\\\\n",
       "\t12 & 18 &  Private & 216284 &  11th & \\emph{missing} &  Never-married & $\\dots$ \\\\\n",
       "\t13 & 30 &  Private & 151989 &  Assoc-voc & \\emph{missing} &  Married-civ-spouse & $\\dots$ \\\\\n",
       "\t14 & 30 &  Private & 55291 &  Bachelors & \\emph{missing} &  Married-civ-spouse & $\\dots$ \\\\\n",
       "\t15 & 43 &  Private & 84661 &  Assoc-voc & \\emph{missing} &  Married-civ-spouse & $\\dots$ \\\\\n",
       "\t16 & 51 &  Private & 284329 &  HS-grad & 9.0 &  Widowed & $\\dots$ \\\\\n",
       "\t17 & 38 &  Private & 170174 &  10th & \\emph{missing} &  Married-civ-spouse & $\\dots$ \\\\\n",
       "\t18 & 35 &  Private & 261293 &  Masters & 14.0 &  Never-married & $\\dots$ \\\\\n",
       "\t19 & 56 &  State-gov & 274111 &  Masters & 14.0 &  Divorced & $\\dots$ \\\\\n",
       "\t20 & 45 &  Private & 267967 &  Bachelors & \\emph{missing} &  Married-civ-spouse & $\\dots$ \\\\\n",
       "\t21 & 40 &  Private & 188942 &  Some-college & \\emph{missing} &  Married-civ-spouse & $\\dots$ \\\\\n",
       "\t22 & 26 &  Private & 746432 &  HS-grad & 9.0 &  Never-married & $\\dots$ \\\\\n",
       "\t23 & 46 &  Private & 117605 &  9th & \\emph{missing} &  Divorced & $\\dots$ \\\\\n",
       "\t24 & 29 &  Private & 1268339 &  HS-grad & \\emph{missing} &  Married-spouse-absent & $\\dots$ \\\\\n",
       "\t25 & 49 &  Private & 247294 &  HS-grad & 9.0 &  Married-civ-spouse & $\\dots$ \\\\\n",
       "\t26 & 55 &  Self-emp-inc & 222615 &  Masters & 14.0 &  Married-civ-spouse & $\\dots$ \\\\\n",
       "\t27 & 47 &  Self-emp-not-inc & 213745 &  Some-college & \\emph{missing} &  Divorced & $\\dots$ \\\\\n",
       "\t28 & 41 &  Self-emp-inc & 151089 &  Some-college & \\emph{missing} &  Married-civ-spouse & $\\dots$ \\\\\n",
       "\t29 & 27 &  Private & 153078 &  Prof-school & \\emph{missing} &  Never-married & $\\dots$ \\\\\n",
       "\t30 & 42 &  Private & 70055 &  11th & 7.0 &  Married-civ-spouse & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/html": [
       "<div class=\"data-frame\"><p>32,561 rows × 15 columns (omitted printing of 9 columns)</p><table class=\"data-frame\"><thead><tr><th></th><th>age</th><th>workclass</th><th>fnlwgt</th><th>education</th><th>education-num</th><th>marital-status</th></tr><tr><th></th><th title=\"Int64\">Int64</th><th title=\"String\">String</th><th title=\"Int64\">Int64</th><th title=\"String\">String</th><th title=\"Union{Missing, Float64}\">Float64?</th><th title=\"String\">String</th></tr></thead><tbody><tr><th>1</th><td>49</td><td> Private</td><td>101320</td><td> Assoc-acdm</td><td>12.0</td><td> Married-civ-spouse</td></tr><tr><th>2</th><td>44</td><td> Private</td><td>236746</td><td> Masters</td><td>14.0</td><td> Divorced</td></tr><tr><th>3</th><td>38</td><td> Private</td><td>96185</td><td> HS-grad</td><td><em>missing</em></td><td> Divorced</td></tr><tr><th>4</th><td>38</td><td> Self-emp-inc</td><td>112847</td><td> Prof-school</td><td>15.0</td><td> Married-civ-spouse</td></tr><tr><th>5</th><td>42</td><td> Self-emp-not-inc</td><td>82297</td><td> 7th-8th</td><td><em>missing</em></td><td> Married-civ-spouse</td></tr><tr><th>6</th><td>20</td><td> Private</td><td>63210</td><td> HS-grad</td><td>9.0</td><td> Never-married</td></tr><tr><th>7</th><td>49</td><td> Private</td><td>44434</td><td> Some-college</td><td>10.0</td><td> Divorced</td></tr><tr><th>8</th><td>37</td><td> Private</td><td>138940</td><td> 11th</td><td>7.0</td><td> Married-civ-spouse</td></tr><tr><th>9</th><td>46</td><td> Private</td><td>328216</td><td> HS-grad</td><td>9.0</td><td> Married-civ-spouse</td></tr><tr><th>10</th><td>36</td><td> Self-emp-inc</td><td>216711</td><td> HS-grad</td><td><em>missing</em></td><td> Married-civ-spouse</td></tr><tr><th>11</th><td>23</td><td> Private</td><td>529223</td><td> Bachelors</td><td>13.0</td><td> Never-married</td></tr><tr><th>12</th><td>18</td><td> Private</td><td>216284</td><td> 11th</td><td><em>missing</em></td><td> Never-married</td></tr><tr><th>13</th><td>30</td><td> Private</td><td>151989</td><td> Assoc-voc</td><td><em>missing</em></td><td> Married-civ-spouse</td></tr><tr><th>14</th><td>30</td><td> Private</td><td>55291</td><td> Bachelors</td><td><em>missing</em></td><td> Married-civ-spouse</td></tr><tr><th>15</th><td>43</td><td> Private</td><td>84661</td><td> Assoc-voc</td><td><em>missing</em></td><td> Married-civ-spouse</td></tr><tr><th>16</th><td>51</td><td> Private</td><td>284329</td><td> HS-grad</td><td>9.0</td><td> Widowed</td></tr><tr><th>17</th><td>38</td><td> Private</td><td>170174</td><td> 10th</td><td><em>missing</em></td><td> Married-civ-spouse</td></tr><tr><th>18</th><td>35</td><td> Private</td><td>261293</td><td> Masters</td><td>14.0</td><td> Never-married</td></tr><tr><th>19</th><td>56</td><td> State-gov</td><td>274111</td><td> Masters</td><td>14.0</td><td> Divorced</td></tr><tr><th>20</th><td>45</td><td> Private</td><td>267967</td><td> Bachelors</td><td><em>missing</em></td><td> Married-civ-spouse</td></tr><tr><th>21</th><td>40</td><td> Private</td><td>188942</td><td> Some-college</td><td><em>missing</em></td><td> Married-civ-spouse</td></tr><tr><th>22</th><td>26</td><td> Private</td><td>746432</td><td> HS-grad</td><td>9.0</td><td> Never-married</td></tr><tr><th>23</th><td>46</td><td> Private</td><td>117605</td><td> 9th</td><td><em>missing</em></td><td> Divorced</td></tr><tr><th>24</th><td>29</td><td> Private</td><td>1268339</td><td> HS-grad</td><td><em>missing</em></td><td> Married-spouse-absent</td></tr><tr><th>25</th><td>49</td><td> Private</td><td>247294</td><td> HS-grad</td><td>9.0</td><td> Married-civ-spouse</td></tr><tr><th>26</th><td>55</td><td> Self-emp-inc</td><td>222615</td><td> Masters</td><td>14.0</td><td> Married-civ-spouse</td></tr><tr><th>27</th><td>47</td><td> Self-emp-not-inc</td><td>213745</td><td> Some-college</td><td><em>missing</em></td><td> Divorced</td></tr><tr><th>28</th><td>41</td><td> Self-emp-inc</td><td>151089</td><td> Some-college</td><td><em>missing</em></td><td> Married-civ-spouse</td></tr><tr><th>29</th><td>27</td><td> Private</td><td>153078</td><td> Prof-school</td><td><em>missing</em></td><td> Never-married</td></tr><tr><th>30</th><td>42</td><td> Private</td><td>70055</td><td> 11th</td><td>7.0</td><td> Married-civ-spouse</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We then create a tuple with the continuous and categorical column names which will be used later on."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "cont = (:age, :fnlwgt, Symbol(\"education-num\"), Symbol(\"capital-loss\"), Symbol(\"hours-per-week\"));\n",
    "cat = (Symbol(\"workclass\"), Symbol(\"education\"), Symbol(\"marital-status\"), Symbol(\"occupation\"), Symbol(\"relationship\"), Symbol(\"race\"), Symbol(\"sex\"), Symbol(\"native-country\"));"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, to perform the required preprocessing, we'll use the tabular transforms from DataAugmentation.jl. For this we'll create dictionaries containing the required information using the `gettransformationdict` helper function. More information about this can be found in the DataAugmentation.jl docs. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "normstats = FastAI.gettransformationdict(data, DataAugmentation.NormalizeRow, cont)\n",
    "fmvals = FastAI.gettransformationdict(data, DataAugmentation.FillMissing, cont)\n",
    "catdict = FastAI.gettransformationdict(data, DataAugmentation.Categorify, cat)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Dict{Any, Any} with 8 entries:\n",
       "  :education               => [\" Assoc-acdm\", \" Masters\", \" HS-grad\", \" Prof-sc…\n",
       "  :race                    => [\" White\", \" Black\", \" Asian-Pac-Islander\", \" Ame…\n",
       "  :sex                     => [\" Female\", \" Male\"]\n",
       "  :workclass               => [\" Private\", \" Self-emp-inc\", \" Self-emp-not-inc\"…\n",
       "  :occupation              => Union{Missing, String}[missing, \" Exec-managerial…\n",
       "  :relationship            => [\" Wife\", \" Not-in-family\", \" Unmarried\", \" Husba…\n",
       "  Symbol(\"native-country\") => [\" United-States\", \" ?\", \" Puerto-Rico\", \" Mexico…\n",
       "  Symbol(\"marital-status\") => [\" Married-civ-spouse\", \" Divorced\", \" Never-marr…"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "normalize = DataAugmentation.NormalizeRow(normstats, cont)\n",
    "categorify = DataAugmentation.Categorify(catdict, cat)\n",
    "fm = DataAugmentation.FillMissing(fmvals, cont)\n",
    "columns = Tables.columnnames(data.table);"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "┌ Warning: There is a missing value present for category 'occupation' which will be removed from Categorify dict\n",
      "└ @ DataAugmentation /Users/manikyabardhan/.julia/dev/DataAugmentation/src/rowtransforms.jl:108\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that we have our transforms, we'll create a `LearningMethod` for tabular classification, which contains all the information needed for encoding the data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "method = FastAI.TabularClassification(\n",
    "    FastAI.TabularTransforms(fm|>normalize|>categorify, columns),\n",
    "    contcols=cont,\n",
    "    catcols=cat,\n",
    "    targetcol=:salary,\n",
    "    columns=columns,\n",
    "    categorydict = catdict,\n",
    "    targetclasses = unique(df[:, :salary])\n",
    ");"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "`getobs` gets us a row of data from the `TableContainer`, which now has been encoded, giving us a tuple with the input and target. The input here is just a tuple of the categorical and continuous values. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "encode(method, Training(), getobs(data, 1))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((Int32[2, 2, 2, 1, 2, 2, 2, 2], [0.7637846676602542, -0.8380709161872286, 0.7462826288318035, 4.5034127099423245, -0.035428902921319616]), Bool[1, 0])"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can use `methoddataloaders` to quickly get a training and validation dataloader by passing in the `TableContainer`, method and batchsize. `pctgval` decided the percentage of data used for validation."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "traindl, valdl = methoddataloaders(data, method, 128; pctgval = 0.2, shuffle = true, buffered=false)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(DataLoaders.GetObsParallel{DataLoaders.BatchViewCollated{DLPipelines.MethodDataset{TabularClassification}}}(batchviewcollated() with 204 batches of size 128, false), DataLoaders.GetObsParallel{DataLoaders.BatchViewCollated{DLPipelines.MethodDataset{TabularClassification}}}(batchviewcollated() with 26 batches of size 256, false))"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "`methodlossfn` can help us quickly get a loss function compatible with the method."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "optim = Flux.ADAM()\n",
    "lossfn = methodlossfn(method)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "logitcrossentropy (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "function emb_sz_rule(n_cat)\n",
    " \tmin(600, round(1.6 * n_cat^0.56))\n",
    " end\n",
    "\n",
    " function _one_emb_sz(catdict, catcol::Symbol, sz_dict=nothing)\n",
    " \tsz_dict = isnothing(sz_dict) ? Dict() : sz_dict\n",
    " \tn_cat = length(catdict[catcol])\n",
    " \tsz = catcol in keys(sz_dict) ? sz_dict[catcol] : emb_sz_rule(n_cat)\n",
    " \tInt64(n_cat)+1, Int64(sz)\n",
    " end\n",
    "\n",
    " function get_emb_sz(catdict, cols; sz_dict=nothing)\n",
    " \t[_one_emb_sz(catdict, catcol, sz_dict) for catcol in cols]\n",
    " end\n",
    "\n",
    "function linbndrop(h_in, h_out; use_bn=true, p=0., act=identity, lin_first=false)\n",
    "    bn = BatchNorm(lin_first ? h_out : h_in)\n",
    "    dropout = p == 0 ? identity : Dropout(p)\n",
    "    dense = Dense(h_in, h_out, act; bias=!use_bn)\n",
    "    if lin_first\n",
    "        return Chain(dense, bn, dropout)\n",
    "    else\n",
    "        return Chain(bn, dropout, dense)\n",
    "    end\n",
    "end\n",
    "\n",
    "function sigmoidrange(x, low, high)\n",
    "    @. Flux.sigmoid(x) * (high - low) + low\n",
    "end\n",
    "\n",
    "function embeddingbackbone(embedding_sizes, dropoutprob=0.)\n",
    "    embedslist = [Embedding(ni => nf) for (ni, nf) in embedding_sizes]\n",
    "    emb_drop = dropoutprob==0. ? identity : Dropout(dropoutprob)\n",
    "    Chain(\n",
    "        x -> tuple(eachrow(x)...), \n",
    "        Parallel(vcat, embedslist), \n",
    "        emb_drop\n",
    "    )\n",
    "end\n",
    "\n",
    "function continuousbackbone(n_cont)\n",
    "    n_cont > 0 ? BatchNorm(n_cont) : identity\n",
    "end\n",
    "\n",
    "function TabularModel(\n",
    "        catbackbone,\n",
    "        contbackbone,    \n",
    "        layers; \n",
    "        n_cat,\n",
    "        n_cont,\n",
    "        out_sz,\n",
    "        ps=0,\n",
    "        use_bn=true,\n",
    "        bn_final=false,\n",
    "        act_cls=Flux.relu,\n",
    "        lin_first=true,\n",
    "        final_activation=identity\n",
    "    )\n",
    "\n",
    "    tabularbackbone = Parallel(vcat, catbackbone, contbackbone)\n",
    "    \n",
    "    catoutsize = first(Flux.outputsize(catbackbone, (n_cat, 1)))\n",
    "    ps = Iterators.cycle(ps)\n",
    "    classifiers = []\n",
    "\n",
    "    first_ps, ps = Iterators.peel(ps)\n",
    "    push!(classifiers, linbndrop(catoutsize+n_cont, first(layers); use_bn=use_bn, p=first_ps, lin_first=lin_first, act=act_cls))\n",
    "    \n",
    "    for (isize, osize, p) in zip(layers[1:(end-1)], layers[2:(end)], ps)\n",
    "        layer = linbndrop(isize, osize; use_bn=use_bn, p=p, act=act_cls, lin_first=lin_first)\n",
    "        push!(classifiers, layer)\n",
    "    end\n",
    "    \n",
    "    push!(classifiers, linbndrop(last(layers), out_sz; use_bn=bn_final, lin_first=lin_first))\n",
    "    \n",
    "    layers = Chain(\n",
    "        tabularbackbone,\n",
    "        classifiers...,\n",
    "        final_activation\n",
    "    )\n",
    "end"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TabularModel (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To create the model, we'll to create a categorical backbone (which will handle the categorical values), continuous backbone (where the continuous values will go), and finally pass them to `TabularModel` which could contain a bunch of linear layers after the backbones."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "embszs = get_emb_sz(catdict, cat)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "8-element Vector{Tuple{Int64, Int64}}:\n",
       " (10, 5)\n",
       " (17, 8)\n",
       " (8, 5)\n",
       " (16, 7)\n",
       " (7, 4)\n",
       " (6, 4)\n",
       " (3, 2)\n",
       " (43, 13)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "embedbackbone = embeddingbackbone(embszs)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Chain(\n",
       "  var\"#6#8\"(),\n",
       "  Parallel(\n",
       "    vcat,\n",
       "    Embedding(10 => 5),                 \u001b[90m# 50 parameters\u001b[39m\n",
       "    Embedding(17 => 8),                 \u001b[90m# 136 parameters\u001b[39m\n",
       "    Embedding(8 => 5),                  \u001b[90m# 40 parameters\u001b[39m\n",
       "    Embedding(16 => 7),                 \u001b[90m# 112 parameters\u001b[39m\n",
       "    Embedding(7 => 4),                  \u001b[90m# 28 parameters\u001b[39m\n",
       "    Embedding(6 => 4),                  \u001b[90m# 24 parameters\u001b[39m\n",
       "    Embedding(3 => 2),                  \u001b[90m# 6 parameters\u001b[39m\n",
       "    Embedding(43 => 13),                \u001b[90m# 559 parameters\u001b[39m\n",
       "  ),\n",
       "  identity,\n",
       ")\u001b[90m                   # Total: 8 arrays, \u001b[39m955 parameters, 128 bytes."
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "contbackbone = continuousbackbone(5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "BatchNorm(5)        \u001b[90m# 10 parameters\u001b[39m\u001b[90m, plus 10 non-trainable\u001b[39m"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, we'll create the model and create a `Learner` which will hold the model along with the data and everything required for training."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "model = TabularModel(embedbackbone, contbackbone, [200, 100], n_cat=8, n_cont=5, out_sz=2)\n",
    "learner = Learner(model, (traindl, valdl), optim, lossfn, Metrics(accuracy))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Learner()"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can use `fitonecycle` method to use the one-cycle strategy for training. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "fitonecycle!(learner, 1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32mEpoch 1 TrainingPhase(): 100%|██████████████████████████| Time: 0:01:03\u001b[39m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "┌───────────────┬───────┬─────────┬──────────┐\n",
      "│\u001b[1m         Phase \u001b[0m│\u001b[1m Epoch \u001b[0m│\u001b[1m    Loss \u001b[0m│\u001b[1m Accuracy \u001b[0m│\n",
      "├───────────────┼───────┼─────────┼──────────┤\n",
      "│ TrainingPhase │   1.0 │ 0.37584 │  0.82569 │\n",
      "└───────────────┴───────┴─────────┴──────────┘\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32mEpoch 1 ValidationPhase(): 100%|████████████████████████| Time: 0:00:02\u001b[39m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "┌─────────────────┬───────┬─────────┬──────────┐\n",
      "│\u001b[1m           Phase \u001b[0m│\u001b[1m Epoch \u001b[0m│\u001b[1m    Loss \u001b[0m│\u001b[1m Accuracy \u001b[0m│\n",
      "├─────────────────┼───────┼─────────┼──────────┤\n",
      "│ ValidationPhase │   1.0 │ 0.34106 │  0.84285 │\n",
      "└─────────────────┴───────┴─────────┴──────────┘\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.1",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}