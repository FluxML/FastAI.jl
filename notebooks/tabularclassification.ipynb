{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "860c72f9",
   "metadata": {},
   "source": [
    "# Tabular Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2433a412",
   "metadata": {},
   "source": [
    "Tabular Classification involves having a categorical column as the target. Here, we'll use the adult sample dataset from fastai and try to predict whether the salary is above 50K or not, making this a binary classification task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc1f44bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "using FastAI\n",
    "using Tables\n",
    "using Statistics\n",
    "using FluxTraining\n",
    "import DataAugmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f9ec64",
   "metadata": {},
   "source": [
    "We can quickly download and get the path of any dataset from fastai by using [`datasetpath`](#). Once we have the path, we'll load the data in a [`TableDataset`](#). By default, if we pass in just the path to [`TableDataset`](#), the data is loaded in a `DataFrame`, but we can use any package for accessing our data, and pass an object satisfying the [Tables.jl](https://github.com/JuliaData/Tables.jl) interface to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc82faca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TableDataset{DataFrames.DataFrame}(\u001b[1m32561×15 DataFrame\u001b[0m\n",
       "\u001b[1m   Row \u001b[0m│\u001b[1m age   \u001b[0m\u001b[1m workclass         \u001b[0m\u001b[1m fnlwgt \u001b[0m\u001b[1m education     \u001b[0m\u001b[1m education-num \u001b[0m\u001b[1m marit\u001b[0m ⋯\n",
       "\u001b[1m       \u001b[0m│\u001b[90m Int64 \u001b[0m\u001b[90m String            \u001b[0m\u001b[90m Int64  \u001b[0m\u001b[90m String        \u001b[0m\u001b[90m Float64?      \u001b[0m\u001b[90m Strin\u001b[0m ⋯\n",
       "───────┼────────────────────────────────────────────────────────────────────────\n",
       "     1 │    49   Private           101320   Assoc-acdm             12.0   Marr ⋯\n",
       "     2 │    44   Private           236746   Masters                14.0   Divo\n",
       "     3 │    38   Private            96185   HS-grad      \u001b[90m     missing   \u001b[0m  Divo\n",
       "     4 │    38   Self-emp-inc      112847   Prof-school            15.0   Marr\n",
       "     5 │    42   Self-emp-not-inc   82297   7th-8th      \u001b[90m     missing   \u001b[0m  Marr ⋯\n",
       "     6 │    20   Private            63210   HS-grad                 9.0   Neve\n",
       "     7 │    49   Private            44434   Some-college           10.0   Divo\n",
       "     8 │    37   Private           138940   11th                    7.0   Marr\n",
       "     9 │    46   Private           328216   HS-grad                 9.0   Marr ⋯\n",
       "    10 │    36   Self-emp-inc      216711   HS-grad      \u001b[90m     missing   \u001b[0m  Marr\n",
       "    11 │    23   Private           529223   Bachelors              13.0   Neve\n",
       "   ⋮   │   ⋮            ⋮            ⋮           ⋮              ⋮              ⋱\n",
       " 32552 │    60   Private           230545   7th-8th                 4.0   Divo\n",
       " 32553 │    39   Private           139743   HS-grad                 9.0   Sepa ⋯\n",
       " 32554 │    35   Self-emp-inc      135436   Prof-school            15.0   Marr\n",
       " 32555 │    53   Private            35102   Some-college           10.0   Divo\n",
       " 32556 │    48   Private           355320   Bachelors              13.0   Marr\n",
       " 32557 │    36   Private           297449   Bachelors              13.0   Divo ⋯\n",
       " 32558 │    23   ?                 123983   Bachelors              13.0   Neve\n",
       " 32559 │    53   Private           157069   Assoc-acdm             12.0   Marr\n",
       " 32560 │    32   Local-gov         217296   HS-grad                 9.0   Marr\n",
       " 32561 │    26   Private           182308   Some-college           10.0   Marr ⋯\n",
       "\u001b[36m                                               10 columns and 32540 rows omitted\u001b[0m)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = TableDataset(joinpath(datasetpath(\"adult_sample\"), \"adult.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd63b82d",
   "metadata": {},
   "source": [
    "In case our data was present in a different format for eg. parquet, it could be loaded into a data container as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759237b4-6397-40fc-8ec5-eb1188c9906d",
   "metadata": {},
   "source": [
    "```julia\n",
    "using Parquet\n",
    "TableDataset(read_parquet(parquet_path));\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77c191c",
   "metadata": {},
   "source": [
    "[`mapobs`](#) is used here to split our target column from the rest of the row in a lazy manner, so that each observation consists of a row of inputs and a target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d4b1c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitdata = mapobs(row -> (row, row[:salary]), data);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8ccc2d",
   "metadata": {},
   "source": [
    "To create a learning task for tabular classification task, we need an input block, an output block, and the encodings to be performed on the data.\n",
    "\n",
    "The input block here is a [`TableRow`](#) which contains information about the nature of the columns (ie. categorical or continuous) along with an indexable collection mapping categorical column names to a collection with distinct classes in that column. We can get this mapping by using the `gettransformationdict` task with [`DataAugmentation.Categorify`](#).\n",
    "\n",
    "The outblock block used is [`Label`](#) for single column classification and the unique classes have to passed to it.\n",
    "\n",
    "This is followed by the encodings which needs to be applied on our input and output blocks. For the input block, we have used the `gettransforms` function here to get a standard bunch of transformations to apply, but this can be easily customized by passing in any tabular transformation from DataAugmentation.jl or a composition of those, to [`TabularPreprocessing`](#). In addition to this, we have just one-hot encoded the outblock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc67d139",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat, cont = FastAI.getcoltypes(data)\n",
    "target = :salary\n",
    "cat = filter(!isequal(target), cat)\n",
    "catdict = FastAI.gettransformdict(data, DataAugmentation.Categorify, cat);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "574fb149",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: There is a missing value present for category 'occupation' which will be removed from Categorify dict\n",
      "└ @ DataAugmentation /home/lorenz/.julia/dev/DataAugmentation/src/rowtransforms.jl:108\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BlockTask(TableRow{8, 6, Dict{Any, Any}} -> Label{String})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputblock = TableRow(cat, cont, catdict)\n",
    "targetblock = Label(unique(data.table[:, target]))\n",
    "\n",
    "task = BlockTask(\n",
    "    (inputblock, targetblock),\n",
    "    (\n",
    "        setup(TabularPreprocessing, inputblock, data),\n",
    "        FastAI.OneHot()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad69519e",
   "metadata": {},
   "source": [
    "In case our initial problem wasn't a classification task, and we had a continuous target column, we would need to perform tabular regression. To create a learning task suitable for regression, we use a [`Continuous`](#) block for representing our target column. This can be done even with multiple continuous target columns by just passing the number of columns in `Continuous`. For example, the task here could be used for 3 targets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ec8b56-7aab-47a2-859d-c7ec0ceefff4",
   "metadata": {},
   "source": [
    "```julia\n",
    "task2 = BlockTask(\n",
    "    (\n",
    "        TableRow(cat, cont, catdict), \n",
    "        Continuous(3)\n",
    "    ),\n",
    "    ((FastAI.TabularPreprocessing(data),)),\n",
    "    outputblock = Continuous(3)\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1d9474",
   "metadata": {},
   "source": [
    "To get an overview of the learning task created, and as a sanity test, we can use [`describetask`](#). This shows us what encodings will be applied to which blocks, and how the predicted ŷ values are decoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2630c9d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\paragraph{\\texttt{LearningTask} summary}\n",
       "\\begin{itemize}\n",
       "\\item Task: \\texttt{TableRow\\{8, 6, Dict\\{Any, Any\\}\\} -> Label\\{String\\}}\n",
       "\n",
       "\n",
       "\\item Model blocks: \\texttt{FastAI.EncodedTableRow\\{8, 6, Dict\\{Any, Any\\}\\} -> FastAI.OneHotTensor\\{0, String\\}}\n",
       "\n",
       "\\end{itemize}\n",
       "Encoding a sample (\\texttt{encodesample(task, context, sample)})\n",
       "\n",
       "\\begin{tabular}\n",
       "{r | r | r | r}\n",
       "Encoding & Name & \\texttt{task.blocks[1]} & \\texttt{task.blocks[2]} \\\\\n",
       "\\hline\n",
       " & \\texttt{(input, target)} & \\texttt{TableRow\\{8, 6, Dict\\{Any, Any\\}\\}} & \\texttt{Label\\{String\\}} \\\\\n",
       "\\texttt{TabularPreprocessing} &  & \\textbf{\\texttt{FastAI.EncodedTableRow\\{8, 6, Dict\\{Any, Any\\}\\}}} & \\texttt{Label\\{String\\}} \\\\\n",
       "\\texttt{OneHot} & \\texttt{(x, y)} & \\texttt{FastAI.EncodedTableRow\\{8, 6, Dict\\{Any, Any\\}\\}} & \\textbf{\\texttt{FastAI.OneHotTensor\\{0, String\\}}} \\\\\n",
       "\\end{tabular}\n",
       "Decoding a model output (\\texttt{decode(task, context, ŷ)})\n",
       "\n",
       "\\begin{tabular}\n",
       "{r | r | r}\n",
       "Decoding & Name & \\texttt{task.outputblock} \\\\\n",
       "\\hline\n",
       " & \\texttt{ŷ} & \\texttt{FastAI.OneHotTensor\\{0, String\\}} \\\\\n",
       "\\texttt{OneHot} &  & \\textbf{\\texttt{Label\\{String\\}}} \\\\\n",
       "\\texttt{TabularPreprocessing} & \\texttt{target\\_pred} & \\texttt{Label\\{String\\}} \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "#### `LearningTask` summary\n",
       "\n",
       "  * Task: `TableRow{8, 6, Dict{Any, Any}} -> Label{String}`\n",
       "  * Model blocks: `FastAI.EncodedTableRow{8, 6, Dict{Any, Any}} -> FastAI.OneHotTensor{0, String}`\n",
       "\n",
       "Encoding a sample (`encodesample(task, context, sample)`)\n",
       "\n",
       "|               Encoding |              Name |                                 `task.blocks[1]` |                   `task.blocks[2]` |\n",
       "| ----------------------:| -----------------:| --------------------------------------------------:| ------------------------------------:|\n",
       "|                        | `(input, target)` |                   `TableRow{8, 6, Dict{Any, Any}}` |                      `Label{String}` |\n",
       "| `TabularPreprocessing` |                   | **`FastAI.EncodedTableRow{8, 6, Dict{Any, Any}}`** |                      `Label{String}` |\n",
       "|               `OneHot` |          `(x, y)` |     `FastAI.EncodedTableRow{8, 6, Dict{Any, Any}}` | **`FastAI.OneHotTensor{0, String}`** |\n",
       "\n",
       "Decoding a model output (`decode(task, context, ŷ)`)\n",
       "\n",
       "|               Decoding |          Name |             `task.outputblock` |\n",
       "| ----------------------:| -------------:| --------------------------------:|\n",
       "|                        |          `ŷ` | `FastAI.OneHotTensor{0, String}` |\n",
       "|               `OneHot` |               |              **`Label{String}`** |\n",
       "| `TabularPreprocessing` | `target_pred` |                  `Label{String}` |\n"
      ],
      "text/plain": [
       "\u001b[1m  \u001b[36mLearningTask\u001b[39m summary\u001b[22m\n",
       "\u001b[1m  ------------------------\u001b[22m\n",
       "\n",
       "    •  Task: \u001b[36mTableRow{8, 6, Dict{Any, Any}} -> Label{String}\u001b[39m\n",
       "\n",
       "    •  Model blocks: \u001b[36mFastAI.EncodedTableRow{8, 6, Dict{Any, Any}} ->\n",
       "       FastAI.OneHotTensor{0, String}\u001b[39m\n",
       "\n",
       "  Encoding a sample (\u001b[36mencodesample(task, context, sample)\u001b[39m)\n",
       "\n",
       "              Encoding            Name                             \u001b[36mtask.blocks[1]\u001b[39m               \u001b[36mtask.blocks[2]\u001b[39m\n",
       "  –––––––––––––––––––– ––––––––––––––– –––––––––––––––––––––––––––––––––––––––––––– ––––––––––––––––––––––––––––––\n",
       "                       \u001b[36m(input, target)\u001b[39m               \u001b[36mTableRow{8, 6, Dict{Any, Any}}\u001b[39m                  \u001b[36mLabel{String}\u001b[39m\n",
       "  \u001b[36mTabularPreprocessing\u001b[39m                 \u001b[1m\u001b[36mFastAI.EncodedTableRow{8, 6, Dict{Any, Any}}\u001b[39m\u001b[22m                  \u001b[36mLabel{String}\u001b[39m\n",
       "                \u001b[36mOneHot\u001b[39m          \u001b[36m(x, y)\u001b[39m \u001b[36mFastAI.EncodedTableRow{8, 6, Dict{Any, Any}}\u001b[39m \u001b[1m\u001b[36mFastAI.OneHotTensor{0, String}\u001b[39m\u001b[22m\n",
       "\n",
       "  Decoding a model output (\u001b[36mdecode(task, context, ŷ)\u001b[39m)\n",
       "\n",
       "              Decoding        Name             \u001b[36mtask.outputblock\u001b[39m\n",
       "  –––––––––––––––––––– ––––––––––– ––––––––––––––––––––––––––––––\n",
       "                                \u001b[36mŷ\u001b[39m \u001b[36mFastAI.OneHotTensor{0, String}\u001b[39m\n",
       "                \u001b[36mOneHot\u001b[39m                              \u001b[1m\u001b[36mLabel{String}\u001b[39m\u001b[22m\n",
       "  \u001b[36mTabularPreprocessing\u001b[39m \u001b[36mtarget_pred\u001b[39m                  \u001b[36mLabel{String}\u001b[39m"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describetask(task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9da109",
   "metadata": {},
   "source": [
    "`getobs` gets us a row of data from the `TableDataset`, which we encode here. This gives us a tuple with the input and target. The input here is again a tuple, containing the categorical values (which have been label encoded or \"categorified\") and the continuous values (which have been normalized and any missing values have been filled). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e306b703-e47e-450e-83e7-34ff1aae86b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\u001b[1mDataFrameRow\u001b[0m\n",
       "\u001b[1m  Row \u001b[0m│\u001b[1m age   \u001b[0m\u001b[1m workclass  \u001b[0m\u001b[1m fnlwgt \u001b[0m\u001b[1m education \u001b[0m\u001b[1m education-num \u001b[0m\u001b[1m marital-status   \u001b[0m ⋯\n",
       "\u001b[1m      \u001b[0m│\u001b[90m Int64 \u001b[0m\u001b[90m String     \u001b[0m\u001b[90m Int64  \u001b[0m\u001b[90m String    \u001b[0m\u001b[90m Float64?      \u001b[0m\u001b[90m String           \u001b[0m ⋯\n",
       "──────┼─────────────────────────────────────────────────────────────────────────\n",
       " 1000 │    61   State-gov  162678   5th-6th             3.0   Married-civ-spou ⋯\n",
       "\u001b[36m                                                              10 columns omitted\u001b[0m, \"<50k\")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getobs(splitdata, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "924c717f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(([5, 16, 2, 10, 5, 2, 3, 2], [1.6435221651965317, -0.2567538819371021, -2.751580937680526, -0.14591824281680102, -0.21665620002803673, -0.035428902921319616]), Float32[0.0, 1.0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = encodesample(task, Training(), getobs(splitdata, 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7105af7",
   "metadata": {},
   "source": [
    "To get a model suitable for our learning task, we can use [`taskmodel`](#) which constructs a suitable model based on the target block. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bdff3ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Parallel(\n",
       "    vcat,\n",
       "    Chain(\n",
       "      FastAI.Models.var\"#41#43\"(),\n",
       "      Parallel(\n",
       "        vcat,\n",
       "        Embedding(10, 6),               \u001b[90m# 60 parameters\u001b[39m\n",
       "        Embedding(17, 8),               \u001b[90m# 136 parameters\u001b[39m\n",
       "        Embedding(8, 5),                \u001b[90m# 40 parameters\u001b[39m\n",
       "        Embedding(17, 8),               \u001b[90m# 136 parameters\u001b[39m\n",
       "        Embedding(7, 5),                \u001b[90m# 35 parameters\u001b[39m\n",
       "        Embedding(6, 4),                \u001b[90m# 24 parameters\u001b[39m\n",
       "        Embedding(3, 3),                \u001b[90m# 9 parameters\u001b[39m\n",
       "        Embedding(43, 13),              \u001b[90m# 559 parameters\u001b[39m\n",
       "      ),\n",
       "      identity,\n",
       "    ),\n",
       "    BatchNorm(6),                       \u001b[90m# 12 parameters\u001b[39m\u001b[90m, plus 12\u001b[39m\n",
       "  ),\n",
       "  Chain(\n",
       "    Dense(58, 200, relu; bias=false),   \u001b[90m# 11_600 parameters\u001b[39m\n",
       "    BatchNorm(200),                     \u001b[90m# 400 parameters\u001b[39m\u001b[90m, plus 400\u001b[39m\n",
       "    identity,\n",
       "  ),\n",
       "  Chain(\n",
       "    Dense(200, 100, relu; bias=false),  \u001b[90m# 20_000 parameters\u001b[39m\n",
       "    BatchNorm(100),                     \u001b[90m# 200 parameters\u001b[39m\u001b[90m, plus 200\u001b[39m\n",
       "    identity,\n",
       "  ),\n",
       "  Dense(100, 2),                        \u001b[90m# 202 parameters\u001b[39m\n",
       ")\u001b[90m                   # Total: 18 arrays, \u001b[39m33_413 parameters, 130.172 KiB."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = taskmodel(task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb73fd4",
   "metadata": {},
   "source": [
    "Of course you can also create a custom backbone using the functions present in `FastAI.Models`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "895aa501",
   "metadata": {},
   "outputs": [],
   "source": [
    "cardinalities = collect(map(col -> length(catdict[col]), cat))\n",
    "\n",
    "ovdict = Dict(:workclass => 10, :education => 12, Symbol(\"native-country\") => 16)\n",
    "overrides = collect(map(col -> col in keys(ovdict) ? ovdict[col] : nothing, cat))\n",
    "\n",
    "embedszs = FastAI.Models.get_emb_sz(cardinalities, overrides)\n",
    "catback = FastAI.Models.tabular_embedding_backbone(embedszs, 0.2);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55e062d",
   "metadata": {},
   "source": [
    "We can then pass a named tuple `(categorical = ..., continuous = ...)` to `taskmodel` to replace the default backbone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36dc2f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Parallel(\n",
       "    vcat,\n",
       "    Chain(\n",
       "      FastAI.Models.var\"#41#43\"(),\n",
       "      Parallel(\n",
       "        vcat,\n",
       "        Embedding(10, 10),              \u001b[90m# 100 parameters\u001b[39m\n",
       "        Embedding(17, 12),              \u001b[90m# 204 parameters\u001b[39m\n",
       "        Embedding(8, 5),                \u001b[90m# 40 parameters\u001b[39m\n",
       "        Embedding(17, 8),               \u001b[90m# 136 parameters\u001b[39m\n",
       "        Embedding(7, 5),                \u001b[90m# 35 parameters\u001b[39m\n",
       "        Embedding(6, 4),                \u001b[90m# 24 parameters\u001b[39m\n",
       "        Embedding(3, 3),                \u001b[90m# 9 parameters\u001b[39m\n",
       "        Embedding(43, 16),              \u001b[90m# 688 parameters\u001b[39m\n",
       "      ),\n",
       "      Dropout(0.2),\n",
       "    ),\n",
       "    BatchNorm(6),                       \u001b[90m# 12 parameters\u001b[39m\u001b[90m, plus 12\u001b[39m\n",
       "  ),\n",
       "  Chain(\n",
       "    Dense(69, 200, relu; bias=false),   \u001b[90m# 13_800 parameters\u001b[39m\n",
       "    BatchNorm(200),                     \u001b[90m# 400 parameters\u001b[39m\u001b[90m, plus 400\u001b[39m\n",
       "    identity,\n",
       "  ),\n",
       "  Chain(\n",
       "    Dense(200, 100, relu; bias=false),  \u001b[90m# 20_000 parameters\u001b[39m\n",
       "    BatchNorm(100),                     \u001b[90m# 200 parameters\u001b[39m\u001b[90m, plus 200\u001b[39m\n",
       "    identity,\n",
       "  ),\n",
       "  Dense(100, 2),                        \u001b[90m# 202 parameters\u001b[39m\n",
       ")\u001b[90m                   # Total: 18 arrays, \u001b[39m35_850 parameters, 138.828 KiB."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone = (categorical = catback, continuous =  BatchNorm(length(cont)))\n",
    "model = taskmodel(task, backbone)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22eb6dc7",
   "metadata": {},
   "source": [
    "To directly get a [`Learner`](#) suitable for our task and data, we can use the [`tasklearner`](#) function. This creates both batched data loaders and a model for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64c2b78e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Learner()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner = tasklearner(task, splitdata;\n",
    "    backbone=backbone, callbacks=[Metrics(accuracy)],\n",
    "    batchsize=128, buffered=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b4b0be",
   "metadata": {},
   "source": [
    "Once we have a `Learner`, we can call [`fitonecycle!`](#) on it to train it for the desired number of epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4eaf21ae-93c8-4d8a-ae98-105b35f5f09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch 1 TrainingPhase(): 100%|██████████████████████████| Time: 0:01:00\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌───────────────┬───────┬─────────┬──────────┐\n",
      "│\u001b[1m         Phase \u001b[0m│\u001b[1m Epoch \u001b[0m│\u001b[1m    Loss \u001b[0m│\u001b[1m Accuracy \u001b[0m│\n",
      "├───────────────┼───────┼─────────┼──────────┤\n",
      "│ TrainingPhase │   1.0 │ 0.37405 │  0.82753 │\n",
      "└───────────────┴───────┴─────────┴──────────┘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch 1 ValidationPhase(): 100%|████████████████████████| Time: 0:00:02\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌─────────────────┬───────┬─────────┬──────────┐\n",
      "│\u001b[1m           Phase \u001b[0m│\u001b[1m Epoch \u001b[0m│\u001b[1m    Loss \u001b[0m│\u001b[1m Accuracy \u001b[0m│\n",
      "├─────────────────┼───────┼─────────┼──────────┤\n",
      "│ ValidationPhase │   1.0 │ 0.39243 │  0.81782 │\n",
      "└─────────────────┴───────┴─────────┴──────────┘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch 2 TrainingPhase(): 100%|██████████████████████████| Time: 0:00:04\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌───────────────┬───────┬─────────┬──────────┐\n",
      "│\u001b[1m         Phase \u001b[0m│\u001b[1m Epoch \u001b[0m│\u001b[1m    Loss \u001b[0m│\u001b[1m Accuracy \u001b[0m│\n",
      "├───────────────┼───────┼─────────┼──────────┤\n",
      "│ TrainingPhase │   2.0 │ 0.35332 │  0.83909 │\n",
      "└───────────────┴───────┴─────────┴──────────┘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch 2 ValidationPhase(): 100%|████████████████████████| Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌─────────────────┬───────┬─────────┬──────────┐\n",
      "│\u001b[1m           Phase \u001b[0m│\u001b[1m Epoch \u001b[0m│\u001b[1m    Loss \u001b[0m│\u001b[1m Accuracy \u001b[0m│\n",
      "├─────────────────┼───────┼─────────┼──────────┤\n",
      "│ ValidationPhase │   2.0 │ 0.33674 │  0.84259 │\n",
      "└─────────────────┴───────┴─────────┴──────────┘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch 3 TrainingPhase(): 100%|██████████████████████████| Time: 0:00:04\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌───────────────┬───────┬─────────┬──────────┐\n",
      "│\u001b[1m         Phase \u001b[0m│\u001b[1m Epoch \u001b[0m│\u001b[1m    Loss \u001b[0m│\u001b[1m Accuracy \u001b[0m│\n",
      "├───────────────┼───────┼─────────┼──────────┤\n",
      "│ TrainingPhase │   3.0 │ 0.32081 │  0.85238 │\n",
      "└───────────────┴───────┴─────────┴──────────┘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch 3 ValidationPhase(): 100%|████████████████████████| Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌─────────────────┬───────┬─────────┬──────────┐\n",
      "│\u001b[1m           Phase \u001b[0m│\u001b[1m Epoch \u001b[0m│\u001b[1m    Loss \u001b[0m│\u001b[1m Accuracy \u001b[0m│\n",
      "├─────────────────┼───────┼─────────┼──────────┤\n",
      "│ ValidationPhase │   3.0 │ 0.31522 │  0.85259 │\n",
      "└─────────────────┴───────┴─────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "fitonecycle!(learner, 3, 0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.2",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
