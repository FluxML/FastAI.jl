{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "using Pkg\n",
    "Pkg.activate(\"/Users/manikyabardhan/.julia/dev/FastAI\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tabular Classification"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tabular Classification involves having a categorical column as the target. Here, we'll use the adult sample dataset from fastai and try to predict whether the salary is above 50K or not, making this a binary classification task. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "using Flux\n",
    "using FastAI\n",
    "using FastAI.Datasets\n",
    "using Tables\n",
    "using Statistics\n",
    "using FluxTraining\n",
    "using DataAugmentation"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "┌ Info: Precompiling FastAI [5d0beca9-ade8-49ae-ad0b-a3cf890e669f]\n",
      "└ @ Base loading.jl:1317\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can quickly download and get the path of any dataset from fastai by using `datasetpath`. Once we have the path, we'll load the data in a `TableContainer`. By default, if we pass in just the path to `TableContainer`, the data is loaded in a `DataFrame`, but we can use any package for accessing our data, and pass an object satisfying the Tables.jl interface to it."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "data = Datasets.TableDataset(joinpath(datasetpath(\"adult_sample\"), \"adult.csv\"))\n",
    "cont = [:age, :fnlwgt, Symbol(\"education-num\"), Symbol(\"capital-loss\"), Symbol(\"hours-per-week\")]\n",
    "cat = [Symbol(\"workclass\"), Symbol(\"education\"), Symbol(\"marital-status\"), Symbol(\"occupation\"), Symbol(\"relationship\"), Symbol(\"race\"), Symbol(\"sex\"), Symbol(\"native-country\")];"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "`mapobs` is used here to split our target column from the rest of the row in a lazy manner."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, to perform the required preprocessing, we'll use the tabular transforms from DataAugmentation.jl. For this we'll create dictionaries containing the required information using the `gettransformationdict` helper function. More information about this can be found in the DataAugmentation.jl docs. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "splitdata = mapobs(row -> (row, row[:salary]), data);"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "normstats = FastAI.gettransformationdict(data, DataAugmentation.NormalizeRow, cont)\n",
    "fmvals = FastAI.gettransformationdict(data, DataAugmentation.FillMissing, cont)\n",
    "catdict = FastAI.gettransformationdict(data, DataAugmentation.Categorify, cat)\n",
    "\n",
    "normalize = DataAugmentation.NormalizeRow(normstats, cont)\n",
    "categorify = DataAugmentation.Categorify(catdict, cat)\n",
    "fm = DataAugmentation.FillMissing(fmvals, cont)\n",
    "columns = Tables.columnnames(data.table);"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "┌ Warning: There is a missing value present for category 'occupation' which will be removed from Categorify dict\n",
      "└ @ DataAugmentation /Users/manikyabardhan/.julia/dev/DataAugmentation/src/rowtransforms.jl:108\n"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, we can create a learning method for the tabular classification task. \n",
    "\n",
    "The input block here is a `TableRow` which contains information about the nature of the columns (ie. categorical or continuous) along with an indexable collection mapping categorical column names to a collection with distinct classes in that column.\n",
    "\n",
    "The outblock block used is `Label` for single column classification and the unique classes have been passed to it.\n",
    "\n",
    "This is followed by the encodings which needs to be applied on our input and output blocks. For the input block, we use the transformations created in the last cell, and just one-hot encode the output block."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "method = BlockMethod(\n",
    "    (\n",
    "        TableRow(cat, cont, catdict), \n",
    "        Label(unique(data.table[:, :salary]))\n",
    "    ),\n",
    "    ((FastAI.TabularTransform(fm|>normalize|>categorify)), FastAI.OneHot())\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "BlockMethod(TableRow{8, 5} -> Label{String})"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In case our initial problem wasn't a classification task, and we had a continuous target column, we would need to perform tabular regression. To create a learning method suitable for regression, we need to use `Continuous` block for representing our target column. This can be done even with multiple continuous target columns by just passing the no. of columns in `Continuous`. For example, the method here could be used for 3 targets."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "method2 = BlockMethod(\n",
    "    (\n",
    "        TableRow(cat, cont, catdict), \n",
    "        Continuous(3)\n",
    "    ),\n",
    "    ((FastAI.TabularTransform(fm|>normalize|>categorify),)),\n",
    "            outputblock = Continuous(3)\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "BlockMethod(TableRow{8, 5} -> Continuous)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "describemethod(method)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\u001b[1m  \u001b[36mLearningMethod\u001b[39m summary\u001b[22m\n",
       "\u001b[1m  ------------------------\u001b[22m\n",
       "\n",
       "    •  Task: \u001b[36mTableRow{8, 5} -> Label{String}\u001b[39m\n",
       "\n",
       "    •  Model blocks: \u001b[36mFastAI.EncodedTableRow{8, 5} ->\n",
       "       FastAI.OneHotTensor{0, String}\u001b[39m\n",
       "\n",
       "  Encoding a sample (\u001b[36mencode(method, context, sample)\u001b[39m)\n",
       "\n",
       "          Encoding            Name             \u001b[36mmethod.blocks[1]\u001b[39m               \u001b[36mmethod.blocks[2]\u001b[39m\n",
       "  –––––––––––––––– ––––––––––––––– –––––––––––––––––––––––––––– ––––––––––––––––––––––––––––––\n",
       "                   \u001b[36m(input, target)\u001b[39m               \u001b[36mTableRow{8, 5}\u001b[39m                  \u001b[36mLabel{String}\u001b[39m\n",
       "  \u001b[36mTabularTransform\u001b[39m                 \u001b[1m\u001b[36mFastAI.EncodedTableRow{8, 5}\u001b[39m\u001b[22m                  \u001b[36mLabel{String}\u001b[39m\n",
       "            \u001b[36mOneHot\u001b[39m          \u001b[36m(x, y)\u001b[39m \u001b[36mFastAI.EncodedTableRow{8, 5}\u001b[39m \u001b[1m\u001b[36mFastAI.OneHotTensor{0, String}\u001b[39m\u001b[22m\n",
       "\n",
       "  Decoding a model output (\u001b[36mdecode(method, context, ŷ)\u001b[39m)\n",
       "\n",
       "          Decoding        Name             \u001b[36mmethod.outputblock\u001b[39m\n",
       "  –––––––––––––––– ––––––––––– ––––––––––––––––––––––––––––––\n",
       "                            \u001b[36mŷ\u001b[39m \u001b[36mFastAI.OneHotTensor{0, String}\u001b[39m\n",
       "            \u001b[36mOneHot\u001b[39m                              \u001b[1m\u001b[36mLabel{String}\u001b[39m\u001b[22m\n",
       "  \u001b[36mTabularTransform\u001b[39m \u001b[36mtarget_pred\u001b[39m                  \u001b[36mLabel{String}\u001b[39m"
      ],
      "text/markdown": [
       "#### `LearningMethod` summary\n",
       "\n",
       "  * Task: `TableRow{8, 5} -> Label{String}`\n",
       "  * Model blocks: `FastAI.EncodedTableRow{8, 5} -> FastAI.OneHotTensor{0, String}`\n",
       "\n",
       "Encoding a sample (`encode(method, context, sample)`)\n",
       "\n",
       "|           Encoding |              Name |                 `method.blocks[1]` |                   `method.blocks[2]` |\n",
       "| ------------------:| -----------------:| ----------------------------------:| ------------------------------------:|\n",
       "|                    | `(input, target)` |                   `TableRow{8, 5}` |                      `Label{String}` |\n",
       "| `TabularTransform` |                   | **`FastAI.EncodedTableRow{8, 5}`** |                      `Label{String}` |\n",
       "|           `OneHot` |          `(x, y)` |     `FastAI.EncodedTableRow{8, 5}` | **`FastAI.OneHotTensor{0, String}`** |\n",
       "\n",
       "Decoding a model output (`decode(method, context, ŷ)`)\n",
       "\n",
       "|           Decoding |          Name |             `method.outputblock` |\n",
       "| ------------------:| -------------:| --------------------------------:|\n",
       "|                    |          `ŷ` | `FastAI.OneHotTensor{0, String}` |\n",
       "|           `OneHot` |               |              **`Label{String}`** |\n",
       "| `TabularTransform` | `target_pred` |                  `Label{String}` |\n"
      ],
      "text/latex": [
       "\\paragraph{\\texttt{LearningMethod} summary}\n",
       "\\begin{itemize}\n",
       "\\item Task: \\texttt{TableRow\\{8, 5\\} -> Label\\{String\\}}\n",
       "\n",
       "\n",
       "\\item Model blocks: \\texttt{FastAI.EncodedTableRow\\{8, 5\\} -> FastAI.OneHotTensor\\{0, String\\}}\n",
       "\n",
       "\\end{itemize}\n",
       "Encoding a sample (\\texttt{encode(method, context, sample)})\n",
       "\n",
       "\\begin{tabular}\n",
       "{r | r | r | r}\n",
       "Encoding & Name & \\texttt{method.blocks[1]} & \\texttt{method.blocks[2]} \\\\\n",
       "\\hline\n",
       " & \\texttt{(input, target)} & \\texttt{TableRow\\{8, 5\\}} & \\texttt{Label\\{String\\}} \\\\\n",
       "\\texttt{TabularTransform} &  & \\textbf{\\texttt{FastAI.EncodedTableRow\\{8, 5\\}}} & \\texttt{Label\\{String\\}} \\\\\n",
       "\\texttt{OneHot} & \\texttt{(x, y)} & \\texttt{FastAI.EncodedTableRow\\{8, 5\\}} & \\textbf{\\texttt{FastAI.OneHotTensor\\{0, String\\}}} \\\\\n",
       "\\end{tabular}\n",
       "Decoding a model output (\\texttt{decode(method, context, ŷ)})\n",
       "\n",
       "\\begin{tabular}\n",
       "{r | r | r}\n",
       "Decoding & Name & \\texttt{method.outputblock} \\\\\n",
       "\\hline\n",
       " & \\texttt{ŷ} & \\texttt{FastAI.OneHotTensor\\{0, String\\}} \\\\\n",
       "\\texttt{OneHot} &  & \\textbf{\\texttt{Label\\{String\\}}} \\\\\n",
       "\\texttt{TabularTransform} & \\texttt{target\\_pred} & \\texttt{Label\\{String\\}} \\\\\n",
       "\\end{tabular}\n"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "`getobs` gets us a row of data from the `TableContainer`, which now has been encoded, giving us a tuple with the input and target. The input here is just a tuple of the categorical values (which have been label encoded or \"categorified\") and continuous values (which have been normalized and any missing values have been filled). "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "encode(method, Training(), getobs(splitdata, 1000))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(([5, 16, 2, 10, 5, 2, 3, 2], [1.6435221651965317, -0.2567538819371021, -2.751580937680526, -0.21665620002803673, -0.035428902921319616]), Float32[0.0, 1.0])"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To quickly get a model suitable for our learning method, we can use the `methodmodel` function. The second argument here is a Dict which can be used to pass in any custom backbones if needed."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "model = methodmodel(method, Dict())"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Parallel(\n",
       "    vcat,\n",
       "    Chain(\n",
       "      FastAI.Models.var\"#42#44\"(),\n",
       "      Parallel(\n",
       "        vcat,\n",
       "        Embedding(10, 5),               \u001b[90m# 50 parameters\u001b[39m\n",
       "        Embedding(17, 8),               \u001b[90m# 136 parameters\u001b[39m\n",
       "        Embedding(8, 5),                \u001b[90m# 40 parameters\u001b[39m\n",
       "        Embedding(16, 7),               \u001b[90m# 112 parameters\u001b[39m\n",
       "        Embedding(7, 4),                \u001b[90m# 28 parameters\u001b[39m\n",
       "        Embedding(6, 4),                \u001b[90m# 24 parameters\u001b[39m\n",
       "        Embedding(3, 2),                \u001b[90m# 6 parameters\u001b[39m\n",
       "        Embedding(43, 13),              \u001b[90m# 559 parameters\u001b[39m\n",
       "      ),\n",
       "      identity,\n",
       "    ),\n",
       "    BatchNorm(5),                       \u001b[90m# 10 parameters\u001b[39m\u001b[90m, plus 10\u001b[39m\n",
       "  ),\n",
       "  Chain(\n",
       "    Dense(53, 200, relu; bias=false),   \u001b[90m# 10_600 parameters\u001b[39m\n",
       "    BatchNorm(200),                     \u001b[90m# 400 parameters\u001b[39m\u001b[90m, plus 400\u001b[39m\n",
       "    identity,\n",
       "  ),\n",
       "  Chain(\n",
       "    Dense(200, 100, relu; bias=false),  \u001b[90m# 20_000 parameters\u001b[39m\n",
       "    BatchNorm(100),                     \u001b[90m# 200 parameters\u001b[39m\u001b[90m, plus 200\u001b[39m\n",
       "    identity,\n",
       "  ),\n",
       "  Dense(100, 2),                        \u001b[90m# 202 parameters\u001b[39m\n",
       ")\u001b[90m                   # Total: 18 arrays, \u001b[39m32_367 parameters, 126.250 KiB."
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We'll quickly see how simple it is to pass in a custom backbone created using functions present in `FastAI.Models`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "cardict = Dict(col => length(classes) for (col, classes) in collect(catdict))\n",
    "embedszs = FastAI.Models.get_emb_sz(cardict, cat)\n",
    "catback = FastAI.Models.tabular_embedding_backbone(embedszs, 0.2);"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The backbone Dict can take three kinds of backbones-\n",
    "- :categoricalbackbone\n",
    "- :continuousbackbone\n",
    "- :finalclassifier\n",
    "\n",
    "We can choose to pass in any combination of these in the `methodmodel` function."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "backbone = Dict(:categoricalbackbone => catback)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Dict{Symbol, Chain{Tuple{FastAI.Models.var\"#42#44\", Parallel{typeof(vcat), Vector{Flux.Embedding{Matrix{Float32}}}}, Dropout{Float64, Colon}}}} with 1 entry:\n",
       "  :categoricalbackbone => Chain(#42, Parallel(vcat, Embedding(10, 5), Embedding…"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "model = methodmodel(method, backbone)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Parallel(\n",
       "    vcat,\n",
       "    Chain(\n",
       "      FastAI.Models.var\"#42#44\"(),\n",
       "      Parallel(\n",
       "        vcat,\n",
       "        Embedding(10, 5),               \u001b[90m# 50 parameters\u001b[39m\n",
       "        Embedding(17, 8),               \u001b[90m# 136 parameters\u001b[39m\n",
       "        Embedding(8, 5),                \u001b[90m# 40 parameters\u001b[39m\n",
       "        Embedding(16, 7),               \u001b[90m# 112 parameters\u001b[39m\n",
       "        Embedding(7, 4),                \u001b[90m# 28 parameters\u001b[39m\n",
       "        Embedding(6, 4),                \u001b[90m# 24 parameters\u001b[39m\n",
       "        Embedding(3, 2),                \u001b[90m# 6 parameters\u001b[39m\n",
       "        Embedding(43, 13),              \u001b[90m# 559 parameters\u001b[39m\n",
       "      ),\n",
       "      Dropout(0.2),\n",
       "    ),\n",
       "    BatchNorm(5),                       \u001b[90m# 10 parameters\u001b[39m\u001b[90m, plus 10\u001b[39m\n",
       "  ),\n",
       "  Chain(\n",
       "    Dense(53, 200, relu; bias=false),   \u001b[90m# 10_600 parameters\u001b[39m\n",
       "    BatchNorm(200),                     \u001b[90m# 400 parameters\u001b[39m\u001b[90m, plus 400\u001b[39m\n",
       "    identity,\n",
       "  ),\n",
       "  Chain(\n",
       "    Dense(200, 100, relu; bias=false),  \u001b[90m# 20_000 parameters\u001b[39m\n",
       "    BatchNorm(100),                     \u001b[90m# 200 parameters\u001b[39m\u001b[90m, plus 200\u001b[39m\n",
       "    identity,\n",
       "  ),\n",
       "  Dense(100, 2),                        \u001b[90m# 202 parameters\u001b[39m\n",
       ")\u001b[90m                   # Total: 18 arrays, \u001b[39m32_367 parameters, 126.312 KiB."
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To directly get a `Learner` suitable for our method and data, we can use the `methodlearner` function. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "learner = methodlearner(method, splitdata, backbone, Metrics(accuracy), batchsize=128, dlkwargs=NamedTuple(zip([:buffered], [false])))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Learner()"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that we have our learner, to train it we can just call `FluxTraining.fit!` on it for the required number of epochs."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "FluxTraining.fit!(learner, 1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32mEpoch 1 TrainingPhase(): 100%|██████████████████████████| Time: 0:00:08\u001b[39m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "┌───────────────┬───────┬─────────┬──────────┐\n",
      "│\u001b[1m         Phase \u001b[0m│\u001b[1m Epoch \u001b[0m│\u001b[1m    Loss \u001b[0m│\u001b[1m Accuracy \u001b[0m│\n",
      "├───────────────┼───────┼─────────┼──────────┤\n",
      "│ TrainingPhase │   1.0 │ 0.45015 │   0.7913 │\n",
      "└───────────────┴───────┴─────────┴──────────┘\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32mEpoch 1 ValidationPhase(): 100%|████████████████████████| Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "┌─────────────────┬───────┬─────────┬──────────┐\n",
      "│\u001b[1m           Phase \u001b[0m│\u001b[1m Epoch \u001b[0m│\u001b[1m    Loss \u001b[0m│\u001b[1m Accuracy \u001b[0m│\n",
      "├─────────────────┼───────┼─────────┼──────────┤\n",
      "│ ValidationPhase │   1.0 │ 0.35919 │  0.83366 │\n",
      "└─────────────────┴───────┴─────────┴──────────┘\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.1",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}