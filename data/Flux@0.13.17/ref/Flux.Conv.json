{"attributes":{"kind":"struct","backlinks":[{"tag":"documentation","title":"SamePad","docid":"Flux@0.13.17/ref/Flux.SamePad"},{"tag":"sourcefile","title":"Flux/Flux.jl","docid":"Flux@0.13.17/src/Flux.jl"},{"tag":"sourcefile","title":"FastVision/models/xresnet.jl","docid":"FastVision@0.1.1/src/models/xresnet.jl"},{"tag":"sourcefile","title":"FastVision/models/layers.jl","docid":"FastVision@0.1.1/src/models/layers.jl"},{"tag":"documentation","title":"CrossCor","docid":"Flux@0.13.17/ref/Flux.CrossCor"},{"tag":"documentation","title":"MaxPool","docid":"Flux@0.13.17/ref/Flux.MaxPool"},{"tag":"sourcefile","title":"FastVision/models/blocks.jl","docid":"FastVision@0.1.1/src/models/blocks.jl"},{"tag":"documentation","title":"convfilter","docid":"Flux@0.13.17/ref/Flux.convfilter"},{"tag":"documentation","title":"MeanPool","docid":"Flux@0.13.17/ref/Flux.MeanPool"},{"tag":"documentation","title":"ConvTranspose","docid":"Flux@0.13.17/ref/Flux.ConvTranspose"},{"tag":"sourcefile","title":"Flux/layers/show.jl","docid":"Flux@0.13.17/src/layers/show.jl"},{"tag":"sourcefile","title":"Flux/layers/conv.jl","docid":"Flux@0.13.17/src/layers/conv.jl"},{"tag":"documentation","title":"DepthwiseConv","docid":"Flux@0.13.17/ref/Flux.DepthwiseConv"}],"methods":[{"symbol_id":"Flux.Conv","module_id":"Flux","file":"layers/conv.jl","line":163,"signature":"(::Signature)"},{"symbol_id":"Flux.Conv","module_id":"Flux","file":"layers/conv.jl","line":152,"signature":"(::Signature)"},{"symbol_id":"Flux.Conv","module_id":"Flux","file":"layers/conv.jl","line":121,"signature":"(::Signature)"}],"package_id":"Flux@0.13.17","title":"Conv","symbol_id":"Flux.Conv","exported":true,"module_id":"Flux"},"tag":"documentation","children":[{"attributes":{"symbol":"Flux.Conv","line":60,"module":"Flux","file":"layers/conv.jl"},"tag":"docstring","children":[{"attributes":{},"tag":"md","children":[{"attributes":{"lang":""},"tag":"codeblock","children":["Conv(filter, in => out, σ = identity;\n     stride = 1, pad = 0, dilation = 1, groups = 1, [bias, init])\n"],"type":"node"},{"attributes":{},"tag":"p","children":["Standard convolutional layer. ",{"attributes":{},"tag":"code","children":["filter"],"type":"node"}," is a tuple of integers specifying the size of the convolutional kernel; ",{"attributes":{},"tag":"code","children":["in"],"type":"node"}," and ",{"attributes":{},"tag":"code","children":["out"],"type":"node"}," specify the number of input and output channels."],"type":"node"},{"attributes":{},"tag":"p","children":["Image data should be stored in WHCN order (width, height, channels, batch). In other words, a 100×100 RGB image would be a ",{"attributes":{},"tag":"code","children":["100×100×3×1"],"type":"node"}," array, and a batch of 50 would be a ",{"attributes":{},"tag":"code","children":["100×100×3×50"],"type":"node"}," array. This has ",{"attributes":{},"tag":"code","children":["N = 2"],"type":"node"}," spatial dimensions, and needs a kernel size like ",{"attributes":{},"tag":"code","children":["(5,5)"],"type":"node"},", a 2-tuple of integers."],"type":"node"},{"attributes":{},"tag":"p","children":["To take convolutions along ",{"attributes":{},"tag":"code","children":["N"],"type":"node"}," feature dimensions, this layer expects as input an array with ",{"attributes":{},"tag":"code","children":["ndims(x) == N+2"],"type":"node"},", where ",{"attributes":{},"tag":"code","children":["size(x, N+1) == in"],"type":"node"}," is the number of input channels, and ",{"attributes":{},"tag":"code","children":["size(x, ndims(x))"],"type":"node"}," is (as always) the number of observations in a batch. Then:"],"type":"node"},{"attributes":{},"tag":"ul","children":[{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["filter"],"type":"node"}," should be a tuple of ",{"attributes":{},"tag":"code","children":["N"],"type":"node"}," integers."],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":["Keywords ",{"attributes":{},"tag":"code","children":["stride"],"type":"node"}," and ",{"attributes":{},"tag":"code","children":["dilation"],"type":"node"}," should each be either single integer, or a tuple with ",{"attributes":{},"tag":"code","children":["N"],"type":"node"}," integers."],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":["Keyword ",{"attributes":{},"tag":"code","children":["pad"],"type":"node"}," specifies the number of elements added to the borders of the data array. It can be"],"type":"node"},{"attributes":{},"tag":"ul","children":[{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":["a single integer for equal padding all around,"],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":["a tuple of ",{"attributes":{},"tag":"code","children":["N"],"type":"node"}," integers, to apply the same padding at begin/end of each spatial dimension,"],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":["a tuple of ",{"attributes":{},"tag":"code","children":["2*N"],"type":"node"}," integers, for asymmetric padding, or"],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":["the singleton ",{"attributes":{},"tag":"code","children":["SamePad()"],"type":"node"},", to calculate padding such that ",{"attributes":{},"tag":"code","children":["size(output,d) == size(x,d) / stride"],"type":"node"}," (possibly rounded) for each spatial dimension."],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":["Keyword ",{"attributes":{},"tag":"code","children":["groups"],"type":"node"}," is expected to be an ",{"attributes":{},"tag":"code","children":["Int"],"type":"node"},". It specifies the number of groups to divide a convolution into."],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"p","children":["Keywords to control initialization of the layer:"],"type":"node"},{"attributes":{},"tag":"ul","children":[{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["init"],"type":"node"}," - Function used to generate initial weights. Defaults to ",{"attributes":{},"tag":"code","children":["glorot_uniform"],"type":"node"},"."],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["bias"],"type":"node"}," - The initial bias vector is all zero by default. Trainable bias can be disabled entirely by setting this to ",{"attributes":{},"tag":"code","children":["false"],"type":"node"},", or another vector can be provided such as ",{"attributes":{},"tag":"code","children":["bias = randn(Float32, out)"],"type":"node"},"."],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"p","children":["See also ",{"attributes":{"reftype":"symbol","href":"@ref","title":"","document_id":"Flux@0.13.17/ref/Flux.ConvTranspose"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["ConvTranspose"],"type":"node"}],"type":"node"},", ",{"attributes":{"reftype":"symbol","href":"@ref","title":"","document_id":"Flux@0.13.17/ref/Flux.DepthwiseConv"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["DepthwiseConv"],"type":"node"}],"type":"node"},", ",{"attributes":{"reftype":"symbol","href":"@ref","title":"","document_id":"Flux@0.13.17/ref/Flux.CrossCor"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["CrossCor"],"type":"node"}],"type":"node"},"."],"type":"node"},{"attributes":{},"tag":"h1","children":["Examples"],"type":"node"},{"attributes":{"lang":"jldoctest"},"tag":"codeblock","children":["julia> xs = rand32(100, 100, 3, 50); # a batch of 50 RGB images\n\njulia> layer = Conv((5,5), 3 => 7, relu; bias = false)\nConv((5, 5), 3 => 7, relu, bias=false)  # 525 parameters\n\njulia> layer(xs) |> size\n(96, 96, 7, 50)\n\njulia> Conv((5,5), 3 => 7; stride = 2)(xs) |> size\n(48, 48, 7, 50)\n\njulia> Conv((5,5), 3 => 7; stride = 2, pad = SamePad())(xs) |> size\n(50, 50, 7, 50)\n\njulia> Conv((1,1), 3 => 7; pad = (20,10,0,0))(xs) |> size\n(130, 100, 7, 50)\n\njulia> Conv((5,5), 3 => 7; stride = 2, dilation = 4)(xs) |> size\n(42, 42, 7, 50)\n"],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{"symbol":"Flux.Conv","line":130,"module":"Flux","file":"layers/conv.jl"},"tag":"docstring","children":[{"attributes":{},"tag":"md","children":[{"attributes":{"lang":""},"tag":"codeblock","children":["Conv(weight::AbstractArray, [bias, activation; stride, pad, dilation])\n"],"type":"node"},{"attributes":{},"tag":"p","children":["Constructs a convolutional layer with the given weight and bias. Accepts the same keywords and has the same defaults as [",{"attributes":{},"tag":"code","children":["Conv(k::NTuple{N,Integer}, ch::Pair{<:Integer,<:Integer}, σ; ...)"],"type":"node"},"](",{"attributes":{"id":"ref"},"tag":"citation","children":[],"type":"node"}," Conv)."],"type":"node"},{"attributes":{"lang":"jldoctest"},"tag":"codeblock","children":["julia> weight = rand(3, 4, 5);\n\njulia> bias = zeros(5);\n\njulia> layer = Conv(weight, bias, sigmoid)  # expects 1 spatial dimension\nConv((3,), 4 => 5, σ)  # 65 parameters\n\njulia> layer(randn(100, 4, 64)) |> size\n(98, 5, 64)\n\njulia> Flux.params(layer) |> length\n2\n"],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"}