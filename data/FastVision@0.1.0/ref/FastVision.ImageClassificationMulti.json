{"attributes":{"kind":"function","backlinks":[{"tag":"sourcefile","title":"FastVision/tasks/classification.jl","docid":"FastVision@0.1.0/src/tasks/classification.jl"},{"tag":"documentation","title":"ImageClassificationSingle","docid":"FastVision@0.1.0/ref/FastVision.ImageClassificationSingle"},{"tag":"sourcefile","title":"FastVision/FastVision.jl","docid":"FastVision@0.1.0/src/FastVision.jl"}],"methods":[{"symbol_id":"FastVision.ImageClassificationMulti","module_id":"FastVision","file":"tasks/classification.jl","line":55,"signature":"(::Signature)"},{"symbol_id":"FastVision.ImageClassificationMulti","module_id":"FastVision","file":"tasks/classification.jl","line":88,"signature":"(::Signature)"}],"package_id":"FastVision@0.1.0","title":"ImageClassificationMulti","symbol_id":"FastVision.ImageClassificationMulti","exported":true,"module_id":"FastVision"},"tag":"documentation","children":[{"attributes":{"symbol":"FastVision.ImageClassificationMulti","line":69,"module":"FastVision","file":"tasks/classification.jl"},"tag":"docstring","children":[{"attributes":{},"tag":"md","children":[{"attributes":{"lang":""},"tag":"codeblock","children":["ImageClassificationMulti(size, classes; kwargs...)\n"],"type":"node"},{"attributes":{},"tag":"p","children":["Learning task for multi-label image classification. Images are resized to ",{"attributes":{},"tag":"code","children":["size"],"type":"node"}," and classified into multiple of ",{"attributes":{},"tag":"code","children":["classes"],"type":"node"},"."],"type":"node"},{"attributes":{},"tag":"p","children":["Use ",{"attributes":{"reftype":"symbol","href":"#","title":"","document_id":"FastVision@0.1.0/ref/FastVision.ImageClassificationSingle"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["ImageClassificationSingle"],"type":"node"}],"type":"node"}," for the single-class setting."],"type":"node"},{"attributes":{},"tag":"h2","children":["Keyword arguments"],"type":"node"},{"attributes":{},"tag":"ul","children":[{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["computestats = false"],"type":"node"},": Whether to compute image statistics on dataset ",{"attributes":{},"tag":"code","children":["data"],"type":"node"}," or use default ImageNet stats."],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["aug_projections = "],"type":"node"},{"attributes":{"reftype":"symbol","href":"#","title":"","document_id":"DataAugmentation@0.2.10/ref/DataAugmentation.Identity"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["DataAugmentation.Identity"],"type":"node"}],"type":"node"},": augmentation to apply during ",{"attributes":{"reftype":"symbol","href":"#","title":"","document_id":"FastVision@0.1.0/ref/FastVision.ProjectiveTransforms"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["ProjectiveTransforms"],"type":"node"}],"type":"node"}," (resizing and cropping)"],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["aug_image = "],"type":"node"},{"attributes":{"reftype":"symbol","href":"#","title":"","document_id":"DataAugmentation@0.2.10/ref/DataAugmentation.Identity"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["DataAugmentation.Identity"],"type":"node"}],"type":"node"},": pixel-level augmentation to apply during ",{"attributes":{"reftype":"symbol","href":"#","title":"","document_id":"FastVision@0.1.0/ref/FastVision.ImagePreprocessing"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["ImagePreprocessing"],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["C = RGB{N0f8}"],"type":"node"},": Color type images are converted to before further processing. Use ",{"attributes":{},"tag":"code","children":["Gray{N0f8}"],"type":"node"}," for grayscale images."],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"}