{"attributes":{"kind":"function","backlinks":[{"tag":"document","title":"New visualization tools for FastAI.jl","docid":"FastAI@dev/doc/docs/notebooks/10_26_showblock.ipynb"},{"tag":"sourcefile","title":"FastVision/tasks/segmentation.jl","docid":"FastVision@0.1.0/src/tasks/segmentation.jl"},{"tag":"document","title":"fastai API comparison","docid":"FastAI@dev/doc/docs/fastai_api_comparison.md"},{"tag":"document","title":"Discovery","docid":"FastAI@dev/doc/docs/discovery.md"},{"tag":"document","title":"Quickstart","docid":"FastAI@dev/doc/docs/notebooks/quickstart.ipynb"},{"tag":"sourcefile","title":"FastVision/FastVision.jl","docid":"FastVision@0.1.0/src/FastVision.jl"}],"methods":[{"symbol_id":"FastVision.ImageSegmentation","module_id":"FastVision","file":"tasks/segmentation.jl","line":2,"signature":"(::Signature)"},{"symbol_id":"FastVision.ImageSegmentation","module_id":"FastVision","file":"tasks/segmentation.jl","line":33,"signature":"(::Signature)"}],"package_id":"FastVision@0.1.0","title":"ImageSegmentation","symbol_id":"FastVision.ImageSegmentation","exported":true,"module_id":"FastVision"},"tag":"documentation","children":[{"attributes":{"symbol":"FastVision.ImageSegmentation","line":16,"module":"FastVision","file":"tasks/segmentation.jl"},"tag":"docstring","children":[{"attributes":{},"tag":"md","children":[{"attributes":{"lang":""},"tag":"codeblock","children":["ImageSegmentation(size, classes; kwargs...)\n"],"type":"node"},{"attributes":{},"tag":"p","children":["Learning task for image segmentation. Images are resized to ",{"attributes":{},"tag":"code","children":["size"],"type":"node"}," and a class is predicted for every pixel."],"type":"node"},{"attributes":{},"tag":"h2","children":["Keyword arguments"],"type":"node"},{"attributes":{},"tag":"ul","children":[{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["computestats = false"],"type":"node"},": Whether to compute image statistics on dataset ",{"attributes":{},"tag":"code","children":["data"],"type":"node"}," or use default ImageNet stats."],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["aug_projections = "],"type":"node"},{"attributes":{"reftype":"symbol","href":"#","title":"","document_id":"DataAugmentation@0.2.10/ref/DataAugmentation.Identity"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["DataAugmentation.Identity"],"type":"node"}],"type":"node"},": augmentation to apply during ",{"attributes":{"reftype":"symbol","href":"#","title":"","document_id":"FastVision@0.1.0/ref/FastVision.ProjectiveTransforms"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["ProjectiveTransforms"],"type":"node"}],"type":"node"}," (resizing and cropping)"],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["aug_image = "],"type":"node"},{"attributes":{"reftype":"symbol","href":"#","title":"","document_id":"DataAugmentation@0.2.10/ref/DataAugmentation.Identity"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["DataAugmentation.Identity"],"type":"node"}],"type":"node"},": pixel-level augmentation to apply during ",{"attributes":{"reftype":"symbol","href":"#","title":"","document_id":"FastVision@0.1.0/ref/FastVision.ImagePreprocessing"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["ImagePreprocessing"],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["C = RGB{N0f8}"],"type":"node"},": Color type images are converted to before further processing. Use ",{"attributes":{},"tag":"code","children":["Gray{N0f8}"],"type":"node"}," for grayscale images."],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"}