{"attributes":{"kind":"function","backlinks":[{"tag":"sourcefile","title":"Flux/losses/functions.jl","docid":"Flux@0.13.11/src/losses/functions.jl"},{"tag":"sourcefile","title":"Flux/losses/Losses.jl","docid":"Flux@0.13.11/src/losses/Losses.jl"}],"methods":[{"symbol_id":"Flux.Losses.label_smoothing","module_id":"Flux.Losses","file":"losses/functions.jl","line":155,"signature":"(::Signature)"}],"package_id":"Flux@0.13.11","title":"label_smoothing","symbol_id":"Flux.Losses.label_smoothing","exported":true,"module_id":"Flux.Losses"},"tag":"documentation","children":[{"attributes":{"symbol":"Flux.Losses.label_smoothing","line":104,"module":"Flux.Losses","file":"losses/functions.jl"},"tag":"docstring","children":[{"attributes":{},"tag":"md","children":[{"attributes":{"lang":""},"tag":"codeblock","children":["label_smoothing(y::Union{Number, AbstractArray}, α; dims::Int=1)\n"],"type":"node"},{"attributes":{},"tag":"p","children":["Returns smoothed labels, meaning the confidence on label values are relaxed."],"type":"node"},{"attributes":{},"tag":"p","children":["When ",{"attributes":{},"tag":"code","children":["y"],"type":"node"}," is given as one-hot vector or batch of one-hot, its calculated as"],"type":"node"},{"attributes":{"lang":""},"tag":"codeblock","children":["y .* (1 - α) .+ α / size(y, dims)\n"],"type":"node"},{"attributes":{},"tag":"p","children":["when ",{"attributes":{},"tag":"code","children":["y"],"type":"node"}," is given as a number or batch of numbers for binary classification, its calculated as"],"type":"node"},{"attributes":{"lang":""},"tag":"codeblock","children":["y .* (1 - α) .+ α / 2\n"],"type":"node"},{"attributes":{},"tag":"p","children":["in which case the labels are squeezed towards ",{"attributes":{},"tag":"code","children":["0.5"],"type":"node"},"."],"type":"node"},{"attributes":{},"tag":"p","children":["α is a number in interval (0, 1) called the smoothing factor. Higher the value of α larger the smoothing of ",{"attributes":{},"tag":"code","children":["y"],"type":"node"},"."],"type":"node"},{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["dims"],"type":"node"}," denotes the one-hot dimension, unless ",{"attributes":{},"tag":"code","children":["dims=0"],"type":"node"}," which denotes the application of label smoothing to binary distributions encoded in a single number."],"type":"node"},{"attributes":{},"tag":"h1","children":["Example"],"type":"node"},{"attributes":{"lang":"jldoctest"},"tag":"codeblock","children":["julia> y = Flux.onehotbatch([1, 1, 1, 0, 1, 0], 0:1)\n2×6 OneHotMatrix(::Vector{UInt32}) with eltype Bool:\n ⋅  ⋅  ⋅  1  ⋅  1\n 1  1  1  ⋅  1  ⋅\n\njulia> y_smoothed = Flux.label_smoothing(y, 0.2f0)\n2×6 Matrix{Float32}:\n 0.1  0.1  0.1  0.9  0.1  0.9\n 0.9  0.9  0.9  0.1  0.9  0.1\n\njulia> y_sim = softmax(y .* log(2f0))\n2×6 Matrix{Float32}:\n 0.333333  0.333333  0.333333  0.666667  0.333333  0.666667\n 0.666667  0.666667  0.666667  0.333333  0.666667  0.333333\n\njulia> y_dis = vcat(y_sim[2,:]', y_sim[1,:]')\n2×6 Matrix{Float32}:\n 0.666667  0.666667  0.666667  0.333333  0.666667  0.333333\n 0.333333  0.333333  0.333333  0.666667  0.333333  0.666667\n\njulia> Flux.crossentropy(y_sim, y) < Flux.crossentropy(y_sim, y_smoothed)\ntrue\n\njulia> Flux.crossentropy(y_dis, y) > Flux.crossentropy(y_dis, y_smoothed)\ntrue\n"],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"}