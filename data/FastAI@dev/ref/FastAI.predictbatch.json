{"attributes":{"kind":"function","backlinks":[{"tag":"document","title":"Saving and loading models for inference","docid":"FastAI@dev/doc/docs/notebooks/serialization.ipynb"},{"tag":"sourcefile","title":"FastAI/FastAI.jl","docid":"FastAI@dev/src/FastAI.jl"},{"tag":"sourcefile","title":"FastAI/tasks/predict.jl","docid":"FastAI@dev/src/tasks/predict.jl"},{"tag":"document","title":"Custom learning tasks","docid":"FastAI@dev/doc/docs/learning_methods.md"}],"methods":[{"symbol_id":"FastAI.predictbatch","module_id":"FastAI","file":"tasks/predict.jl","line":30,"signature":"(::Signature)"}],"package_id":"FastAI@dev","title":"predictbatch","symbol_id":"FastAI.predictbatch","exported":true,"module_id":"FastAI"},"tag":"documentation","children":[{"attributes":{"symbol":"FastAI.predictbatch","line":23,"module":"FastAI","file":"tasks/predict.jl"},"tag":"docstring","children":[{"attributes":{},"tag":"md","children":[{"attributes":{"lang":""},"tag":"codeblock","children":["predictbatch(task, model, inputs[; device, context])\n"],"type":"node"},{"attributes":{},"tag":"p","children":["Predict ",{"attributes":{},"tag":"code","children":["targets"],"type":"node"}," from a vector of ",{"attributes":{},"tag":"code","children":["inputs"],"type":"node"}," using ",{"attributes":{},"tag":"code","children":["model"],"type":"node"}," by batching them. Optionally apply function ",{"attributes":{},"tag":"code","children":["device"],"type":"node"}," to batch before passing to ",{"attributes":{},"tag":"code","children":["model"],"type":"node"}," and use ",{"attributes":{},"tag":"code","children":["context"],"type":"node"}," instead of the default ",{"attributes":{"reftype":"symbol","href":"#","title":"","document_id":"FastAI@dev/ref/FastAI.Inference"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["Inference"],"type":"node"}],"type":"node"},"."],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"}