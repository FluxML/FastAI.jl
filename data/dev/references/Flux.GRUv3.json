{"attributes":{"kind":"function","backlinks":[{"tag":"sourcefile","title":"Flux/src/Flux.jl","docid":"sourcefiles/Flux/src/Flux.jl"},{"tag":"sourcefile","title":"Flux/src/layers/recurrent.jl","docid":"sourcefiles/Flux/src/layers/recurrent.jl"}],"methods":[{"line":477,"file":"/home/runner/.julia/packages/Flux/KkC79/src/layers/recurrent.jl","method_id":"Flux.GRUv3_1","symbol_id":"Flux.GRUv3","filedoc":"sourcefiles/Flux/src/layers/recurrent.jl","signature":"GRUv3(a...; ka...)"}],"name":"GRUv3","title":"GRUv3","symbol_id":"Flux.GRUv3","public":true,"module_id":"Flux"},"tag":"documentation","children":[{"attributes":{},"tag":"md","children":[{"attributes":{"lang":""},"tag":"codeblock","children":["GRUv3(in => out)\n"],"type":"node"},{"attributes":{},"tag":"p","children":[{"attributes":{"href":"https://arxiv.org/abs/1406.1078v3","title":""},"tag":"a","children":["Gated Recurrent Unit"],"type":"node"}," layer. Behaves like an RNN but generally exhibits a longer memory span over sequences. This implements the variant proposed in v3 of the referenced paper."],"type":"node"},{"attributes":{},"tag":"p","children":["The arguments ",{"attributes":{},"tag":"code","children":["in"],"type":"node"}," and ",{"attributes":{},"tag":"code","children":["out"],"type":"node"}," describe the size of the feature vectors passed as input and as output. That is, it accepts a vector of length ",{"attributes":{},"tag":"code","children":["in"],"type":"node"}," or a batch of vectors represented as a ",{"attributes":{},"tag":"code","children":["in x B"],"type":"node"}," matrix and outputs a vector of length ",{"attributes":{},"tag":"code","children":["out"],"type":"node"}," or a batch of vectors of size ",{"attributes":{},"tag":"code","children":["out x B"],"type":"node"},"."],"type":"node"},{"attributes":{},"tag":"p","children":["This constructor is syntactic sugar for ",{"attributes":{},"tag":"code","children":["Recur(GRUv3Cell(a...))"],"type":"node"},", and so GRUv3s are stateful. Note that the state shape can change depending on the inputs, and so it is good to ",{"attributes":{},"tag":"code","children":["reset!"],"type":"node"}," the model between inference calls if the batch size changes. See the examples below."],"type":"node"},{"attributes":{},"tag":"p","children":["See ",{"attributes":{"href":"https://colah.github.io/posts/2015-08-Understanding-LSTMs/","title":""},"tag":"a","children":["this article"],"type":"node"}," for a good overview of the internals."],"type":"node"},{"attributes":{},"tag":"h1","children":["Examples"],"type":"node"},{"attributes":{"lang":"jldoctest"},"tag":"codeblock","children":["julia> g = GRUv3(3 => 5)\nRecur(\n  GRUv3Cell(3 => 5),                    # 140 parameters\n)         # Total: 5 trainable arrays, 140 parameters,\n          # plus 1 non-trainable, 5 parameters, summarysize 848 bytes.\n\njulia> g(rand(Float32, 3)) |> size\n(5,)\n\njulia> Flux.reset!(g);\n\njulia> g(rand(Float32, 3, 10)) |> size # batch size of 10\n(5, 10)\n"],"type":"node"},{"attributes":{"class":"warning"},"tag":"admonition","children":[{"attributes":{},"tag":"admonitiontitle","children":["Batch size changes"],"type":"node"},{"attributes":{},"tag":"admonitionbody","children":[{"attributes":{},"tag":"p","children":["Failing to call ",{"attributes":{},"tag":"code","children":["reset!"],"type":"node"}," when the input batch size changes can lead to unexpected behavior. See the example in ",{"attributes":{"reftype":"document","href":"@ref","title":"","document_id":"references/@ref"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["RNN"],"type":"node"}],"type":"node"},"."],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"}