{"attributes":{"kind":"struct","backlinks":[{"tag":"sourcefile","title":"Flux/src/optimise/optimisers.jl","docid":"sourcefiles/Flux/src/optimise/optimisers.jl"},{"tag":"sourcefile","title":"Flux/src/deprecations.jl","docid":"sourcefiles/Flux/src/deprecations.jl"},{"tag":"sourcefile","title":"Flux/src/Flux.jl","docid":"sourcefiles/Flux/src/Flux.jl"},{"tag":"sourcefile","title":"Flux/src/optimise/Optimise.jl","docid":"sourcefiles/Flux/src/optimise/Optimise.jl"}],"methods":[{"line":351,"file":"/home/runner/.julia/packages/Flux/KkC79/src/optimise/optimisers.jl","method_id":"Flux.Optimise.AdaGrad_1","symbol_id":"Flux.Optimise.AdaGrad","filedoc":"sourcefiles/Flux/src/optimise/optimisers.jl","signature":"AdaGrad()"},{"line":347,"file":"/home/runner/.julia/packages/Flux/KkC79/src/optimise/optimisers.jl","method_id":"Flux.Optimise.AdaGrad_2","symbol_id":"Flux.Optimise.AdaGrad","filedoc":"sourcefiles/Flux/src/optimise/optimisers.jl","signature":"AdaGrad(eta::Float64, epsilon::Float64, acc::IdDict)"},{"line":351,"file":"/home/runner/.julia/packages/Flux/KkC79/src/optimise/optimisers.jl","method_id":"Flux.Optimise.AdaGrad_3","symbol_id":"Flux.Optimise.AdaGrad","filedoc":"sourcefiles/Flux/src/optimise/optimisers.jl","signature":"AdaGrad(η::Real)"},{"line":352,"file":"/home/runner/.julia/packages/Flux/KkC79/src/optimise/optimisers.jl","method_id":"Flux.Optimise.AdaGrad_4","symbol_id":"Flux.Optimise.AdaGrad","filedoc":"sourcefiles/Flux/src/optimise/optimisers.jl","signature":"AdaGrad(η::Real, state::IdDict)"},{"line":351,"file":"/home/runner/.julia/packages/Flux/KkC79/src/optimise/optimisers.jl","method_id":"Flux.Optimise.AdaGrad_5","symbol_id":"Flux.Optimise.AdaGrad","filedoc":"sourcefiles/Flux/src/optimise/optimisers.jl","signature":"AdaGrad(η::Real, ϵ::Real)"},{"line":347,"file":"/home/runner/.julia/packages/Flux/KkC79/src/optimise/optimisers.jl","method_id":"Flux.Optimise.AdaGrad_6","symbol_id":"Flux.Optimise.AdaGrad","filedoc":"sourcefiles/Flux/src/optimise/optimisers.jl","signature":"AdaGrad(eta, epsilon, acc)"}],"name":"AdaGrad","title":"AdaGrad","symbol_id":"Flux.Optimise.AdaGrad","public":true,"module_id":"Flux.Optimise"},"tag":"documentation","children":[{"attributes":{},"tag":"md","children":[{"attributes":{"lang":""},"tag":"codeblock","children":["AdaGrad(η = 0.1, ϵ = 1.0e-8)\n"],"type":"node"},{"attributes":{},"tag":"p","children":[{"attributes":{"href":"http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf","title":""},"tag":"a","children":["AdaGrad"],"type":"node"}," optimizer. It has parameter specific learning rates based on how frequently it is updated. Parameters don't need tuning."],"type":"node"},{"attributes":{},"tag":"h1","children":["Parameters"],"type":"node"},{"attributes":{},"tag":"ul","children":[{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":["Learning rate (",{"attributes":{},"tag":"code","children":["η"],"type":"node"},"): Amount by which gradients are discounted before updating the weights."],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"h1","children":["Examples"],"type":"node"},{"attributes":{"lang":"julia"},"tag":"codeblock","children":[{"attributes":{},"tag":"julia","children":[{"attributes":{},"tag":"EQ","children":[{"attributes":{},"tag":"IDENTIFIER","children":["opt"],"type":"node"},{"attributes":{},"tag":"WHITESPACE","children":[" "],"type":"node"},{"attributes":{},"tag":"EQ","children":["="],"type":"node"},{"attributes":{},"tag":"WHITESPACE","children":[" "],"type":"node"},{"attributes":{},"tag":"CALL","children":[{"attributes":{"reftype":"symbol","document_id":"references/Flux.Optimise.AdaGrad"},"tag":"reference","children":["AdaGrad"],"type":"node"},{"attributes":{},"tag":"LPAREN","children":["("],"type":"node"},{"attributes":{},"tag":"RPAREN","children":[")"],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"NEWLINE_WS","children":["\n"],"type":"node"},{"attributes":{},"tag":"NEWLINE_WS","children":["\n"],"type":"node"},{"attributes":{},"tag":"EQ","children":[{"attributes":{},"tag":"IDENTIFIER","children":["opt"],"type":"node"},{"attributes":{},"tag":"WHITESPACE","children":[" "],"type":"node"},{"attributes":{},"tag":"EQ","children":["="],"type":"node"},{"attributes":{},"tag":"WHITESPACE","children":[" "],"type":"node"},{"attributes":{},"tag":"CALL","children":[{"attributes":{"reftype":"symbol","document_id":"references/Flux.Optimise.AdaGrad"},"tag":"reference","children":["AdaGrad"],"type":"node"},{"attributes":{},"tag":"LPAREN","children":["("],"type":"node"},{"attributes":{},"tag":"FLOAT","children":["0.001"],"type":"node"},{"attributes":{},"tag":"RPAREN","children":[")"],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"}