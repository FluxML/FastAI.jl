{"attributes":{"kind":"module","backlinks":[{"tag":"document","title":"Image segmentation","docid":"documents/docs/notebooks/imagesegmentation.ipynb"},{"tag":"document","title":"How to augment vision data","docid":"documents/docs/howto/augmentvision.md"},{"tag":"documentation","title":"DimSize","docid":"references/FastVision.DimSize"},{"tag":"documentation","title":"RECIPES","docid":"references/FastVision.RECIPES"},{"tag":"document","title":"Blocks and encodings","docid":"documents/docs/background/blocksencodings.md"},{"tag":"documentation","title":"IMAGENET_STDS","docid":"references/FastVision.IMAGENET_STDS"},{"tag":"document","title":"Discovery","docid":"documents/docs/discovery.md"},{"tag":"document","title":"Quickstart","docid":"documents/docs/notebooks/quickstart.ipynb"},{"tag":"document","title":"Saving and loading models for inference","docid":"documents/docs/notebooks/serialization.ipynb"},{"tag":"sourcefile","title":"FastVision/src/FastVision.jl","docid":"sourcefiles/FastVision/src/FastVision.jl"},{"tag":"documentation","title":"RE_IMAGEFILE","docid":"references/FastVision.RE_IMAGEFILE"},{"tag":"document","title":"How to find functionality","docid":"documents/docs/howto/findfunctionality.md"},{"tag":"documentation","title":"AbstractBlockTask","docid":"references/FastAI.AbstractBlockTask"},{"tag":"documentation","title":"Image","docid":"references/FastVision.Image"},{"tag":"document","title":"How to train a model","docid":"documents/docs/notebooks/training.ipynb"},{"tag":"document","title":"fastai API comparison","docid":"documents/docs/fastai_api_comparison.md"},{"tag":"documentation","title":"setup","docid":"references/FastAI.setup"},{"tag":"documentation","title":"IMAGENET_MEANS","docid":"references/FastVision.IMAGENET_MEANS"},{"tag":"document","title":"Data containers","docid":"documents/docs/data_containers.md"},{"tag":"document","title":"Keypoint regression","docid":"documents/docs/notebooks/keypointregression.ipynb"},{"tag":"document","title":"Custom learning tasks","docid":"documents/docs/learning_methods.md"},{"tag":"document","title":"Variational autoencoders","docid":"documents/docs/notebooks/vae.ipynb"},{"tag":"documentation","title":"learningtasks","docid":"references/FastAI.Registries.learningtasks"}],"name":"FastVision","symbols":[{"kind":"struct","name":"Bounded","symbol_id":"FastVision.Bounded","public":true},{"kind":"const","name":"DimSize","symbol_id":"FastVision.DimSize","public":false},{"kind":"const","name":"IMAGENET_MEANS","symbol_id":"FastVision.IMAGENET_MEANS","public":false},{"kind":"const","name":"IMAGENET_STDS","symbol_id":"FastVision.IMAGENET_STDS","public":false},{"kind":"struct","name":"Image","symbol_id":"FastVision.Image","public":true},{"kind":"function","name":"ImageClassificationMulti","symbol_id":"FastVision.ImageClassificationMulti","public":true},{"kind":"function","name":"ImageClassificationSingle","symbol_id":"FastVision.ImageClassificationSingle","public":true},{"kind":"struct","name":"ImageFolders","symbol_id":"FastVision.ImageFolders","public":false},{"kind":"function","name":"ImageKeypointRegression","symbol_id":"FastVision.ImageKeypointRegression","public":true},{"kind":"struct","name":"ImagePreprocessing","symbol_id":"FastVision.ImagePreprocessing","public":true},{"kind":"function","name":"ImageSegmentation","symbol_id":"FastVision.ImageSegmentation","public":true},{"kind":"struct","name":"ImageSegmentationFolders","symbol_id":"FastVision.ImageSegmentationFolders","public":false},{"kind":"struct","name":"ImageTableMultiLabel","symbol_id":"FastVision.ImageTableMultiLabel","public":false},{"kind":"struct","name":"ImageTensor","symbol_id":"FastVision.ImageTensor","public":false},{"kind":"struct","name":"KeypointPreprocessing","symbol_id":"FastVision.KeypointPreprocessing","public":true},{"kind":"struct","name":"KeypointTensor","symbol_id":"FastVision.KeypointTensor","public":false},{"kind":"struct","name":"Keypoints","symbol_id":"FastVision.Keypoints","public":true},{"kind":"struct","name":"Mask","symbol_id":"FastVision.Mask","public":true},{"kind":"module","name":"Models","symbol_id":"FastVision.Models","public":false},{"kind":"struct","name":"ProjectiveTransforms","symbol_id":"FastVision.ProjectiveTransforms","public":true},{"kind":"const","name":"RECIPES","symbol_id":"FastVision.RECIPES","public":false},{"kind":"const","name":"RE_IMAGEFILE","symbol_id":"FastVision.RE_IMAGEFILE","public":false},{"kind":"function","name":"augs_lighting","symbol_id":"FastVision.augs_lighting","public":true},{"kind":"function","name":"augs_projection","symbol_id":"FastVision.augs_projection","public":true},{"kind":"function","name":"blockitemtype","symbol_id":"FastVision.blockitemtype","public":false},{"kind":"function","name":"checksize","symbol_id":"FastVision.checksize","public":false},{"kind":"function","name":"colorchannels","symbol_id":"FastVision.colorchannels","public":false},{"kind":"function","name":"getimagepreprocessing","symbol_id":"FastVision.getimagepreprocessing","public":false},{"kind":"function","name":"getsamplebounds","symbol_id":"FastVision.getsamplebounds","public":false},{"kind":"function","name":"grabbounds","symbol_id":"FastVision.grabbounds","public":false},{"kind":"function","name":"imagedatasetstats","symbol_id":"FastVision.imagedatasetstats","public":false},{"kind":"function","name":"imagestats","symbol_id":"FastVision.imagestats","public":false},{"kind":"function","name":"isimagefile","symbol_id":"FastVision.isimagefile","public":false},{"kind":"function","name":"loadmask","symbol_id":"FastVision.loadmask","public":false},{"kind":"function","name":"maskfromimage","symbol_id":"FastVision.maskfromimage","public":false},{"kind":"function","name":"mockarray","symbol_id":"FastVision.mockarray","public":false},{"kind":"function","name":"plotimage","symbol_id":"FastVision.plotimage","public":true},{"kind":"function","name":"plotimage!","symbol_id":"FastVision.plotimage!","public":true},{"kind":"function","name":"plotmask","symbol_id":"FastVision.plotmask","public":true},{"kind":"function","name":"plotmask!","symbol_id":"FastVision.plotmask!","public":true}],"title":"FastVision","files":["/home/runner/work/FastAI.jl/FastAI.jl/FastVision/src/FastVision.jl","/home/runner/work/FastAI.jl/FastAI.jl/FastVision/src/blocks/bounded.jl","/home/runner/work/FastAI.jl/FastAI.jl/FastVision/src/blocks/image.jl","/home/runner/work/FastAI.jl/FastAI.jl/FastVision/src/blocks/mask.jl","/home/runner/work/FastAI.jl/FastAI.jl/FastVision/src/blocks/keypoints.jl","/home/runner/work/FastAI.jl/FastAI.jl/FastVision/src/encodings/onehot.jl","/home/runner/work/FastAI.jl/FastAI.jl/FastVision/src/encodings/imagepreprocessing.jl","/home/runner/work/FastAI.jl/FastAI.jl/FastVision/src/encodings/keypointpreprocessing.jl","/home/runner/work/FastAI.jl/FastAI.jl/FastVision/src/encodings/projective.jl","/home/runner/work/FastAI.jl/FastAI.jl/FastVision/src/models/Models.jl","/home/runner/work/FastAI.jl/FastAI.jl/FastVision/src/models/layers.jl","/home/runner/work/FastAI.jl/FastAI.jl/FastVision/src/models/blocks.jl","/home/runner/work/FastAI.jl/FastAI.jl/FastVision/src/models/xresnet.jl","/home/runner/work/FastAI.jl/FastAI.jl/FastVision/src/models/unet.jl","/home/runner/work/FastAI.jl/FastAI.jl/FastVision/src/models.jl","/home/runner/work/FastAI.jl/FastAI.jl/FastVision/src/tasks/utils.jl","/home/runner/work/FastAI.jl/FastAI.jl/FastVision/src/tasks/classification.jl","/home/runner/work/FastAI.jl/FastAI.jl/FastVision/src/tasks/segmentation.jl","/home/runner/work/FastAI.jl/FastAI.jl/FastVision/src/tasks/keypointregression.jl","/home/runner/work/FastAI.jl/FastAI.jl/FastVision/src/datasets.jl","/home/runner/work/FastAI.jl/FastAI.jl/FastVision/src/recipes.jl","/home/runner/work/FastAI.jl/FastAI.jl/FastVision/src/makie.jl","/home/runner/work/FastAI.jl/FastAI.jl/FastVision/src/tests.jl"],"symbol_id":"FastVision","public":true,"filedocs":["sourcefiles/FastVision/src/FastVision.jl","sourcefiles/FastVision/src/blocks/bounded.jl","sourcefiles/FastVision/src/blocks/image.jl","sourcefiles/FastVision/src/blocks/mask.jl","sourcefiles/FastVision/src/blocks/keypoints.jl","sourcefiles/FastVision/src/encodings/onehot.jl","sourcefiles/FastVision/src/encodings/imagepreprocessing.jl","sourcefiles/FastVision/src/encodings/keypointpreprocessing.jl","sourcefiles/FastVision/src/encodings/projective.jl","sourcefiles/FastVision/src/models/Models.jl","sourcefiles/FastVision/src/models/layers.jl","sourcefiles/FastVision/src/models/blocks.jl","sourcefiles/FastVision/src/models/xresnet.jl","sourcefiles/FastVision/src/models/unet.jl","sourcefiles/FastVision/src/models.jl","sourcefiles/FastVision/src/tasks/utils.jl","sourcefiles/FastVision/src/tasks/classification.jl","sourcefiles/FastVision/src/tasks/segmentation.jl","sourcefiles/FastVision/src/tasks/keypointregression.jl","sourcefiles/FastVision/src/datasets.jl","sourcefiles/FastVision/src/recipes.jl","sourcefiles/FastVision/src/makie.jl","sourcefiles/FastVision/src/tests.jl"],"module_id":"FastVision"},"tag":"documentation","children":[{"attributes":{},"tag":"md","children":[{"attributes":{"lang":""},"tag":"codeblock","children":["module FastVision\n"],"type":"node"},{"attributes":{},"tag":"p","children":["Data blocks, encodings and more for computer vision."],"type":"node"},{"attributes":{},"tag":"p","children":["The most important [",{"attributes":{},"tag":"code","children":["Block"],"type":"node"},"] is ",{"attributes":{"reftype":"symbol","document_id":"references/DataAugmentation.Image"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["Image"],"type":"node"}],"type":"node"},{"attributes":{},"tag":"code","children":["{N}"],"type":"node"},"."],"type":"node"},{"attributes":{},"tag":"p","children":["Blocks:"],"type":"node"},{"attributes":{},"tag":"ul","children":[{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{"reftype":"symbol","document_id":"references/DataAugmentation.Image"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["Image"],"type":"node"}],"type":"node"},{"attributes":{},"tag":"code","children":["{N}"],"type":"node"},": an ",{"attributes":{},"tag":"code","children":["N"],"type":"node"},"-dimensional color image"],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{"reftype":"symbol","document_id":"references/FastVision.Mask"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["Mask"],"type":"node"}],"type":"node"},{"attributes":{},"tag":"code","children":["{N}"],"type":"node"},": an ",{"attributes":{},"tag":"code","children":["N"],"type":"node"},"-dimensional categorical mask"],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{"reftype":"symbol","document_id":"references/DataAugmentation.Keypoints"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["Keypoints"],"type":"node"}],"type":"node"},{"attributes":{},"tag":"code","children":["{N}"],"type":"node"},": a fixed number of ",{"attributes":{},"tag":"code","children":["N"],"type":"node"},"-dimensional keypoints"],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"p","children":["Encodings:"],"type":"node"},{"attributes":{},"tag":"ul","children":[{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{"reftype":"symbol","document_id":"references/DataAugmentation.OneHot"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["OneHot"],"type":"node"}],"type":"node"}," is implemented for ",{"attributes":{},"tag":"code","children":["Mask"],"type":"node"},"s"],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{"reftype":"symbol","document_id":"references/FastVision.ImagePreprocessing"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["ImagePreprocessing"],"type":"node"}],"type":"node"}," prepares an ",{"attributes":{},"tag":"code","children":["Image"],"type":"node"}," for training by normalizing and expanding the color channels"],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{"reftype":"symbol","document_id":"references/FastVision.KeypointPreprocessing"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["KeypointPreprocessing"],"type":"node"}],"type":"node"}," prepares ",{"attributes":{},"tag":"code","children":["Keypoints"],"type":"node"}," for training by normalizing them."],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"}