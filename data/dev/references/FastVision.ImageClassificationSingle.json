{"attributes":{"kind":"function","backlinks":[{"tag":"document","title":"Introduction","docid":"documents/docs/introduction.md"},{"tag":"document","title":"Blocks and encodings","docid":"documents/docs/background/blocksencodings.md"},{"tag":"documentation","title":"ImageClassificationMulti","docid":"references/FastVision.ImageClassificationMulti"},{"tag":"document","title":"Discovery","docid":"documents/docs/discovery.md"},{"tag":"document","title":"Quickstart","docid":"documents/docs/notebooks/quickstart.ipynb"},{"tag":"document","title":"New visualization tools for FastAI.jl","docid":"documents/docs/notebooks/10_26_showblock.ipynb"},{"tag":"sourcefile","title":"FastVision/src/tasks/classification.jl","docid":"sourcefiles/FastVision/src/tasks/classification.jl"},{"tag":"sourcefile","title":"FastVision/src/FastVision.jl","docid":"sourcefiles/FastVision/src/FastVision.jl"},{"tag":"document","title":"How to train a model","docid":"documents/docs/notebooks/training.ipynb"},{"tag":"document","title":"fastai API comparison","docid":"documents/docs/fastai_api_comparison.md"},{"tag":"documentation","title":"showsample","docid":"references/FastAI.showsample"},{"tag":"document","title":"FastAI.jl","docid":"documents/README.md"},{"tag":"document","title":"Performant data pipelines","docid":"documents/docs/background/datapipelines.md"},{"tag":"documentation","title":"showsamples","docid":"references/FastAI.showsamples"},{"tag":"documentation","title":"tasklearner","docid":"references/FastAI.tasklearner"}],"methods":[{"line":2,"file":"/home/runner/work/FastAI.jl/FastAI.jl/FastVision/src/tasks/classification.jl","method_id":"FastVision.ImageClassificationSingle_1","symbol_id":"FastVision.ImageClassificationSingle","filedoc":"sourcefiles/FastVision/src/tasks/classification.jl","signature":"ImageClassificationSingle(blocks::Tuple{Image{N}, Label})"},{"line":2,"file":"/home/runner/work/FastAI.jl/FastAI.jl/FastVision/src/tasks/classification.jl","method_id":"FastVision.ImageClassificationSingle_2","symbol_id":"FastVision.ImageClassificationSingle","filedoc":"sourcefiles/FastVision/src/tasks/classification.jl","signature":"ImageClassificationSingle(blocks::Tuple{Image{N}, Label}, data; size, aug_projections, aug_image, C, computestats)"},{"line":36,"file":"/home/runner/work/FastAI.jl/FastAI.jl/FastVision/src/tasks/classification.jl","method_id":"FastVision.ImageClassificationSingle_3","symbol_id":"FastVision.ImageClassificationSingle","filedoc":"sourcefiles/FastVision/src/tasks/classification.jl","signature":"ImageClassificationSingle(size::Tuple{Vararg{Int64, N}}, classes::AbstractVector; kwargs...)"}],"name":"ImageClassificationSingle","title":"ImageClassificationSingle","symbol_id":"FastVision.ImageClassificationSingle","public":true,"module_id":"FastVision"},"tag":"documentation","children":[{"attributes":{},"tag":"md","children":[{"attributes":{"lang":""},"tag":"codeblock","children":["ImageClassificationSingle(size, classes; kwargs...)\nImageClassificationSingle(blocks[, data]; kwargs...)\n"],"type":"node"},{"attributes":{},"tag":"p","children":["Learning task for single-label image classification. Images are resized to ",{"attributes":{},"tag":"code","children":["size"],"type":"node"}," and classified into one of ",{"attributes":{},"tag":"code","children":["classes"],"type":"node"},"."],"type":"node"},{"attributes":{},"tag":"p","children":["Use ",{"attributes":{"reftype":"symbol","document_id":"references/FastVision.ImageClassificationMulti"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["ImageClassificationMulti"],"type":"node"}],"type":"node"}," for the multi-class setting."],"type":"node"},{"attributes":{},"tag":"h2","children":["Keyword arguments"],"type":"node"},{"attributes":{},"tag":"ul","children":[{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["computestats = false"],"type":"node"},": Whether to compute image statistics on dataset ",{"attributes":{},"tag":"code","children":["data"],"type":"node"}," or use default ImageNet stats."],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["aug_projections = "],"type":"node"},{"attributes":{"reftype":"symbol","document_id":"references/DataAugmentation.Identity"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["DataAugmentation.Identity"],"type":"node"}],"type":"node"},": augmentation to apply during ",{"attributes":{"reftype":"symbol","document_id":"references/FastVision.ProjectiveTransforms"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["ProjectiveTransforms"],"type":"node"}],"type":"node"}," (resizing and cropping)"],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["aug_image = "],"type":"node"},{"attributes":{"reftype":"symbol","document_id":"references/DataAugmentation.Identity"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["DataAugmentation.Identity"],"type":"node"}],"type":"node"},": pixel-level augmentation to apply during ",{"attributes":{"reftype":"symbol","document_id":"references/FastVision.ImagePreprocessing"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["ImagePreprocessing"],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["C = RGB{N0f8}"],"type":"node"},": Color type images are converted to before further processing. Use ",{"attributes":{},"tag":"code","children":["Gray{N0f8}"],"type":"node"}," for grayscale images."],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"}