{"attributes":{"kind":"function","backlinks":[{"tag":"sourcefile","title":"Flux/src/losses/Losses.jl","docid":"sourcefiles/Flux/src/losses/Losses.jl"},{"tag":"sourcefile","title":"Flux/src/losses/functions.jl","docid":"sourcefiles/Flux/src/losses/functions.jl"}],"methods":[{"line":302,"file":"/home/runner/.julia/packages/Flux/KkC79/src/losses/functions.jl","method_id":"Flux.Losses.binarycrossentropy_1","symbol_id":"Flux.Losses.binarycrossentropy","filedoc":"sourcefiles/Flux/src/losses/functions.jl","signature":"binarycrossentropy(ŷ, y; agg, ϵ)"}],"name":"binarycrossentropy","title":"binarycrossentropy","symbol_id":"Flux.Losses.binarycrossentropy","public":true,"module_id":"Flux.Losses"},"tag":"documentation","children":[{"attributes":{},"tag":"md","children":[{"attributes":{"lang":""},"tag":"codeblock","children":["binarycrossentropy(ŷ, y; agg = mean, ϵ = eps(ŷ))\n"],"type":"node"},{"attributes":{},"tag":"p","children":["Return the binary cross-entropy loss, computed as"],"type":"node"},{"attributes":{"lang":""},"tag":"codeblock","children":["agg(@.(-y * log(ŷ + ϵ) - (1 - y) * log(1 - ŷ + ϵ)))\n"],"type":"node"},{"attributes":{},"tag":"p","children":["Where typically, the prediction ",{"attributes":{},"tag":"code","children":["ŷ"],"type":"node"}," is given by the output of a ",{"attributes":{"reftype":"document","href":"@ref","title":"","document_id":"references/@ref"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["sigmoid"],"type":"node"}],"type":"node"}," activation. The ",{"attributes":{},"tag":"code","children":["ϵ"],"type":"node"}," term is included to avoid infinity. Using ",{"attributes":{"reftype":"document","href":"@ref","title":"","document_id":"references/@ref"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["logitbinarycrossentropy"],"type":"node"}],"type":"node"}," is recomended over ",{"attributes":{},"tag":"code","children":["binarycrossentropy"],"type":"node"}," for numerical stability."],"type":"node"},{"attributes":{},"tag":"p","children":["Use ",{"attributes":{"reftype":"document","href":"@ref","title":"","document_id":"references/@ref"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["label_smoothing"],"type":"node"}],"type":"node"}," to smooth the ",{"attributes":{},"tag":"code","children":["y"],"type":"node"}," value as preprocessing before computing the loss."],"type":"node"},{"attributes":{},"tag":"p","children":["See also: ",{"attributes":{"reftype":"document","href":"@ref","title":"","document_id":"references/@ref"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["crossentropy"],"type":"node"}],"type":"node"},", ",{"attributes":{"reftype":"document","href":"@ref","title":"","document_id":"references/@ref"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["logitcrossentropy"],"type":"node"}],"type":"node"},"."],"type":"node"},{"attributes":{},"tag":"h1","children":["Examples"],"type":"node"},{"attributes":{"lang":"jldoctest"},"tag":"codeblock","children":["julia> y_bin = Bool[1,0,1]\n3-element Vector{Bool}:\n 1\n 0\n 1\n\njulia> y_prob = softmax(reshape(vcat(1:3, 3:5), 2, 3) .* 1f0)\n2×3 Matrix{Float32}:\n 0.268941  0.5  0.268941\n 0.731059  0.5  0.731059\n\njulia> Flux.binarycrossentropy(y_prob[2,:], y_bin)\n0.43989f0\n\njulia> all(p -> 0 < p < 1, y_prob[2,:])  # else DomainError\ntrue\n\njulia> y_hot = Flux.onehotbatch(y_bin, 0:1)\n2×3 OneHotMatrix(::Vector{UInt32}) with eltype Bool:\n ⋅  1  ⋅\n 1  ⋅  1\n\njulia> Flux.crossentropy(y_prob, y_hot)\n0.43989f0\n"],"type":"node"}],"type":"node"}],"type":"node"}