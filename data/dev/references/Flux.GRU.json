{"attributes":{"kind":"function","backlinks":[{"tag":"sourcefile","title":"Flux/src/Flux.jl","docid":"sourcefiles/Flux/src/Flux.jl"},{"tag":"sourcefile","title":"Flux/src/layers/recurrent.jl","docid":"sourcefiles/Flux/src/layers/recurrent.jl"}],"methods":[{"line":347,"file":"/home/runner/.julia/packages/Flux/6Q5r4/src/layers/recurrent.jl","method_id":"Flux.GRU_1","symbol_id":"Flux.GRU","signature":"GRU(a...; ka...)"}],"name":"GRU","title":"GRU","symbol_id":"Flux.GRU","public":true,"module_id":"Flux"},"tag":"documentation","children":[{"attributes":{},"tag":"md","children":[{"attributes":{"lang":""},"tag":"codeblock","children":["GRU(in => out)\n"],"type":"node"},{"attributes":{},"tag":"p","children":[{"attributes":{"href":"https://arxiv.org/abs/1406.1078v1","title":""},"tag":"a","children":["Gated Recurrent Unit"],"type":"node"}," layer. Behaves like an",{"attributes":{},"tag":"br","children":[],"type":"node"},"RNN but generally exhibits a longer memory span over sequences. This implements",{"attributes":{},"tag":"br","children":[],"type":"node"},"the variant proposed in v1 of the referenced paper."],"type":"node"},{"attributes":{},"tag":"p","children":["The integer arguments ",{"attributes":{},"tag":"code","children":["in"],"type":"node"}," and ",{"attributes":{},"tag":"code","children":["out"],"type":"node"}," describe the size of the feature vectors passed as input and as output. That is, it accepts a vector of length ",{"attributes":{},"tag":"code","children":["in"],"type":"node"}," or a batch of vectors represented as a ",{"attributes":{},"tag":"code","children":["in x B"],"type":"node"}," matrix and outputs a vector of length ",{"attributes":{},"tag":"code","children":["out"],"type":"node"}," or a batch of vectors of size ",{"attributes":{},"tag":"code","children":["out x B"],"type":"node"},"."],"type":"node"},{"attributes":{},"tag":"p","children":["This constructor is syntactic sugar for ",{"attributes":{},"tag":"code","children":["Recur(GRUCell(a...))"],"type":"node"},", and so GRUs are stateful. Note that the state shape can change depending on the inputs, and so it is good to ",{"attributes":{},"tag":"code","children":["reset!"],"type":"node"}," the model between inference calls if the batch size changes. See the examples below."],"type":"node"},{"attributes":{},"tag":"p","children":["See ",{"attributes":{"href":"https://colah.github.io/posts/2015-08-Understanding-LSTMs/","title":""},"tag":"a","children":["this article"],"type":"node"},{"attributes":{},"tag":"br","children":[],"type":"node"},"for a good overview of the internals."],"type":"node"},{"attributes":{},"tag":"h1","children":["Examples"],"type":"node"},{"attributes":{"lang":"jldoctest"},"tag":"codeblock","children":["julia> g = GRU(3 => 5)\nRecur(\n  GRUCell(3 => 5),                      # 140 parameters\n)         # Total: 4 trainable arrays, 140 parameters,\n          # plus 1 non-trainable, 5 parameters, summarysize 792 bytes.\n\njulia> g(rand(Float32, 3)) |> size\n(5,)\n\njulia> Flux.reset!(g);\n\njulia> g(rand(Float32, 3, 10)) |> size # batch size of 10\n(5, 10)\n"],"type":"node"},{"attributes":{"class":"warning"},"tag":"admonition","children":[{"attributes":{},"tag":"admonitiontitle","children":["Batch size changes"],"type":"node"},{"attributes":{},"tag":"admonitionbody","children":[{"attributes":{},"tag":"p","children":["Failing to call ",{"attributes":{},"tag":"code","children":["reset!"],"type":"node"}," when the input batch size changes can lead to unexpected behavior. See the example in ",{"attributes":{"reftype":"document","href":"@ref","title":"","document_id":"references/@ref"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["RNN"],"type":"node"}],"type":"node"},"."],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"}