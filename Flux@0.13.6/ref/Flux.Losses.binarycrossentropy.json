{"attributes":{"kind":"function","backlinks":[{"tag":"sourcefile","title":"Flux/losses/Losses.jl","docid":"Flux@0.13.6/src/losses/Losses.jl"},{"tag":"sourcefile","title":"Flux/losses/functions.jl","docid":"Flux@0.13.6/src/losses/functions.jl"},{"tag":"documentation","title":"binary_focal_loss","docid":"Flux@0.13.6/ref/Flux.Losses.binary_focal_loss"}],"methods":[{"symbol_id":"Flux.Losses.binarycrossentropy","module_id":"Flux.Losses","file":"losses/functions.jl","line":313,"signature":"(::Signature)"}],"package_id":"Flux@0.13.6","title":"binarycrossentropy","symbol_id":"Flux.Losses.binarycrossentropy","exported":true,"module_id":"Flux.Losses"},"tag":"documentation","children":[{"attributes":{"symbol":"Flux.Losses.binarycrossentropy","line":269,"module":"Flux.Losses","file":"losses/functions.jl"},"tag":"docstring","children":[{"attributes":{},"tag":"md","children":[{"attributes":{"lang":""},"tag":"codeblock","children":["binarycrossentropy(ŷ, y; agg = mean, ϵ = eps(ŷ))\n"],"type":"node"},{"attributes":{},"tag":"p","children":["Return the binary cross-entropy loss, computed as"],"type":"node"},{"attributes":{"lang":""},"tag":"codeblock","children":["agg(@.(-y * log(ŷ + ϵ) - (1 - y) * log(1 - ŷ + ϵ)))\n"],"type":"node"},{"attributes":{},"tag":"p","children":["Where typically, the prediction ",{"attributes":{},"tag":"code","children":["ŷ"],"type":"node"}," is given by the output of a [sigmoid](",{"attributes":{},"tag":"citation","children":[],"type":"node"}," Activation-Functions) activation. The ",{"attributes":{},"tag":"code","children":["ϵ"],"type":"node"}," term is included to avoid infinity. Using ",{"attributes":{"href":"@ref","title":""},"tag":"a","children":[{"attributes":{},"tag":"code","children":["logitbinarycrossentropy"],"type":"node"}],"type":"node"}," is recomended over ",{"attributes":{},"tag":"code","children":["binarycrossentropy"],"type":"node"}," for numerical stability."],"type":"node"},{"attributes":{},"tag":"p","children":["Use ",{"attributes":{"href":"@ref","title":""},"tag":"a","children":[{"attributes":{},"tag":"code","children":["label_smoothing"],"type":"node"}],"type":"node"}," to smooth the ",{"attributes":{},"tag":"code","children":["y"],"type":"node"}," value as preprocessing before computing the loss."],"type":"node"},{"attributes":{},"tag":"p","children":["See also: ",{"attributes":{"href":"@ref","title":""},"tag":"a","children":[{"attributes":{},"tag":"code","children":["crossentropy"],"type":"node"}],"type":"node"},", ",{"attributes":{"href":"@ref","title":""},"tag":"a","children":[{"attributes":{},"tag":"code","children":["logitcrossentropy"],"type":"node"}],"type":"node"},"."],"type":"node"},{"attributes":{},"tag":"h1","children":["Examples"],"type":"node"},{"attributes":{"lang":"jldoctest"},"tag":"codeblock","children":["julia> y_bin = Bool[1,0,1]\n3-element Vector{Bool}:\n 1\n 0\n 1\n\njulia> y_prob = softmax(reshape(vcat(1:3, 3:5), 2, 3) .* 1f0)\n2×3 Matrix{Float32}:\n 0.268941  0.5  0.268941\n 0.731059  0.5  0.731059\n\njulia> Flux.binarycrossentropy(y_prob[2,:], y_bin)\n0.43989f0\n\njulia> all(p -> 0 < p < 1, y_prob[2,:])  # else DomainError\ntrue\n\njulia> y_hot = Flux.onehotbatch(y_bin, 0:1)\n2×3 OneHotMatrix(::Vector{UInt32}) with eltype Bool:\n ⋅  1  ⋅\n 1  ⋅  1\n\njulia> Flux.crossentropy(y_prob, y_hot)\n0.43989f0\n"],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"}